{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano / computing gradient numerically.. (not autodiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate how well a particular set of parameter values $\\theta$ fits the behavioral data, we compute the probability of oberving the data given the model.\n",
    "\n",
    "For each trial $i$, we will compute the likelihood of seeing the data under the model assuming that trials are independent. \n",
    "\n",
    "$P(D|\\theta) = \\prod_{i}P(d_i|t_{i,R},t_{i,L},\\theta)$\n",
    "\n",
    "$t_{i,R},t_{i,L}$ : the right and left click times on trial $i$\n",
    "\n",
    "$d_i$ : the subject's decision on trial $i$\n",
    "\n",
    "The best-fit parameter values are the parameters $\\theta$ that maximize the likelihood (Maximum likelihood values)\n",
    "\n",
    "To help maximize the likelihood(or log likelihood), we will compute the derivative $\\partial P(d_i|t_{i,R},t_{i,L},\\theta) / \\partial\\theta$ for each of the parameters in the set $\\theta$.\n",
    "\n",
    "After we get these gradients of 9 model parameters, we will apply them for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "import scipy.io\n",
    "ratdata = scipy.io.loadmat('chrono_B069_rawdata.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trial index starts from 0 \n",
    "# *** rightbups, leftbups, maxT, rat_choice\n",
    "\n",
    "def trialdata(ratdata,trial):\n",
    "    if ratdata['rawdata']['pokedR'][0][trial] > 0 :\n",
    "        rat_choice = 1 # \"R\"\n",
    "    else : \n",
    "        rat_choice = -1 # \"L\"\n",
    "        \n",
    "    RClickTimes = np.require(ratdata['rawdata']['rightbups'][0][trial][0],requirements='A')\n",
    "    LClickTimes = np.require(ratdata['rawdata']['leftbups'][0][trial][0],requirements='A')\n",
    "    T1 = ratdata['rawdata']['T'][0][trial][0][0]\n",
    "    \n",
    "    if np.shape(LClickTimes)[0] == 1:\n",
    "        LClickTimes = [0, LClickTimes]\n",
    "    if np.shape(RClickTimes)[0] == 1:\n",
    "        RClickTimes = [0, RClickTimes]\n",
    "    return  RClickTimes, LClickTimes, T1, rat_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages..\n",
    "# pip install theano\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.compile.nanguardmode import NanGuardMode\n",
    "from theano.compile.debugmode import DebugMode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theano.config.mode = 'FAST_RUN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       0.19235  0.34361]\n",
      "0.350959\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "# trial index starts from 0 \n",
    "# ** data load sample\n",
    "RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata, 0) \n",
    "print LeftClickTimes\n",
    "print maxT\n",
    "print rat_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variables (Global variable, Theano shared variables = Parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a : decision variable, memory accumulator\n",
    "\n",
    "$$ da =\n",
    "  \\begin{cases}\n",
    "    0       & \\quad \\text{if, } |a| \\geq B \\\\\n",
    "    \\sigma_adW + (\\delta_{t,t_R} \\cdot \\eta C(t) - \\delta_{t,t_L} \\cdot \\eta C(t))dt + \\lambda adt  & \\quad \\text{otherwise, }\\\\\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "The impact of each click (C) is affected by sensory adaptation that depends on clicks from both right and left sides:\n",
    "\n",
    "$$ \n",
    "\\frac{\\mathrm d C}{\\mathrm d t} = \\frac{1-C}{\\tau_\\phi} + (1-\\phi)C(\\delta_{t,t_R}+\\delta_{t,t_L}) \n",
    "$$\n",
    "\n",
    "\n",
    "sigma2_a ($\\sigma_a^2$) : a diffusion constant, parameterizing noise in a.\n",
    "\n",
    "sigma2_s ($\\sigma_s^2$) : parameterizing noise when adding evidence from a right or left pulse. (incoming sensory evidence)\n",
    "\n",
    "sigma2_i ($\\sigma_i^2$) : initial condition for the dynamical equation at $t=0$\n",
    "\n",
    "lam ($\\lambda$) : consistent drift in the memory a ($\\lambda<0$ : leaky or forgetful case, $\\lambda>0$ : unstable or impulsive case)\n",
    "\n",
    "B : decision bound\n",
    "\n",
    "bias : bias parameter determines the position of the threshold in a (which a Rightward decision is made)\n",
    "\n",
    "phi ($\\phi$) : parameterize sensory adaptation (by defining the dynamics of C ($\\phi>1$ : Facilitation, $\\phi<1$ : Depression, $\\phi=1$ : absense of sensory adaptation)\n",
    "\n",
    "tau_phi ($\\tau_\\phi$) :\n",
    "\n",
    "lapse : The lapse rate parameterizes the probability of making a random response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global variables \n",
    "epsilon = 10.0**(-10) \n",
    "dx = 0.25\n",
    "dt = 0.02\n",
    "# new_global var\n",
    "ndelta = 10.0**(-4)\n",
    "total_rate = 40\n",
    "\n",
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.1;\n",
    "\n",
    "# Theano shared_variables \n",
    "sigma2_a = theano.shared(sigma_a, name=\"sigma_a\")\n",
    "sigma2_s = theano.shared(sigma_s, name=\"sigma_s\")\n",
    "sigma2_i = theano.shared(sigma_i, name=\"sigma_i\")\n",
    "lam = theano.shared(lam, name=\"lambda\")\n",
    "B = theano.shared(B, name=\"B\")\n",
    "bias = theano.shared(bias, name=\"bias\")\n",
    "phi = theano.shared(phi, name=\"phi\")\n",
    "tau_phi = theano.shared(tau_phi, name=\"tau_phi\")\n",
    "lapse = theano.shared(lapse, name=\"lapse\")\n",
    "\n",
    "params = [sigma2_a, sigma2_s, sigma2_i, lam, B, bias, phi, tau_phi, lapse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## why binning?\n",
    "\n",
    "Because of the bounds B, we can't use analytical solutions for P(a,t)\n",
    "\n",
    "Instead, we will solve the Fokker-Planck equations numerically.\n",
    "\n",
    "1. Discretize both time t and space a\n",
    "2. Start with the distribution at time t=0 : $P(a, t=0) = N(0,\\sigma_i)$\n",
    "3. Compute the probability distribution for the next time step given the probability distribution for the previous time step. (until t = maxT)\n",
    "\n",
    "*time step k, $a_k, t_k$ : at time step k\n",
    "\n",
    "*a -> a set of M contiguous bin (space), vector $\\xi$ (center of bins), $\\xi_i, \\xi_j$\n",
    "\n",
    "### Forward Markov transition matrix F\n",
    "\n",
    "$F_{ij} = P(a_k = \\xi_i | a_{k-1} = \\xi_j)$\n",
    "\n",
    "$f_k$ represents the spatially discretized version of the distribution $P(a, t_k)$\n",
    "\n",
    "$ f_k = Ff_{k-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bin_centers = make_bins(B, dx, binN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### make_bins (Theano version)\n",
    "def make_bins(B, dx, binN):\n",
    "    bins = (T.arange(binN)+1)*B\n",
    "    bins = dx*bins/B\n",
    "\n",
    "    tmp = T.scalar()\n",
    "    \n",
    "    bins = T.switch(T.eq(bins[-1],B),\n",
    "                    T.set_subtensor(bins[-1], B+dx),\n",
    "                    T.set_subtensor(bins[-1], 2*B - bins[-2]))\n",
    "    \n",
    "    bins = T.concatenate((-bins[::-1], T.zeros(1), bins))\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-4.2 , -4.  , -3.75, -3.5 , -3.25, -3.  , -2.75, -2.5 , -2.25,\n",
       "        -2.  , -1.75, -1.5 , -1.25, -1.  , -0.75, -0.5 , -0.25,  0.  ,\n",
       "         0.25,  0.5 ,  0.75,  1.  ,  1.25,  1.5 ,  1.75,  2.  ,  2.25,\n",
       "         2.5 ,  2.75,  3.  ,  3.25,  3.5 ,  3.75,  4.  ,  4.2 ]),\n",
       " array(17, dtype=int32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binN = T.cast(T.ceil(B/dx),'int32')\n",
    "bin_centers = make_bins(B, dx, binN)\n",
    "test = T.zeros_like(bin_centers)\n",
    "test2 = T.zeros((bin_centers.shape))\n",
    "\n",
    "test_func = theano.function(\n",
    "    inputs=[],\n",
    "    outputs=[bin_centers, binN,test,test2]\n",
    ")\n",
    "\n",
    "test_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F = Fmatrix([sigma, lambda, c], bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inner_loop(base_s, s, p, hp, lp, F, dFds, dFdsig2, dFdB, bin_centers,j,sigma2):\n",
    "    dd = bin_centers[hp] - bin_centers[lp]\n",
    "    \n",
    "    # ------ F\n",
    "    FF = T.inc_subtensor(F[hp,j], p*(s-bin_centers[lp])/dd)\n",
    "    FF = T.inc_subtensor(FF[lp,j], p*(bin_centers[hp]-s)/dd)\n",
    "\n",
    "    F_rest = T.switch(T.eq(dd,0),\n",
    "                      T.inc_subtensor(F[lp,j], p),\n",
    "                      FF)\n",
    "\n",
    "    F = T.switch(T.le(s,bin_centers[0]),\n",
    "                      T.inc_subtensor(F[0,j], p),\n",
    "                      F)\n",
    "    F = T.switch(T.ge(s,bin_centers[-1]),\n",
    "                      T.inc_subtensor(F[-1,j], p),\n",
    "                      F)\n",
    "    F = T.switch(T.gt(s,bin_centers[0]) & T.lt(s,bin_centers[-1]),\n",
    "                      F_rest,\n",
    "                      F)\n",
    "\n",
    "    # ------ dFds\n",
    "    \n",
    "    # hp == lp\n",
    "    dFds1 = T.inc_subtensor(dFds[lp,j], -p/(bin_centers[lp+1]-bin_centers[lp]))\n",
    "    dFds1 = T.inc_subtensor(dFds1[lp+1,j], p/(bin_centers[lp+1]-bin_centers[lp]))\n",
    "\n",
    "    # hp != lp\n",
    "    dFds2 = T.inc_subtensor(dFds[hp,j], p/dd)\n",
    "    dFds2 = T.inc_subtensor(dFds2[lp,j], -p/dd)     \n",
    "    \n",
    "    dFds_rest = T.switch(T.eq(dd,0),\n",
    "                      dFds1,\n",
    "                      dFds2)\n",
    "    \n",
    "    dFds = T.switch(T.gt(s,bin_centers[0]) & T.lt(s,bin_centers[-1]),\n",
    "                  dFds_rest,\n",
    "                  dFds)\n",
    "    \n",
    "    # ------ dFdsig2\n",
    "    # hp == lp\n",
    "    dFdsig2_1 = T.inc_subtensor(dFdsig2[lp,j], -(p/(bin_centers[lp+1]-bin_centers[lp]))*base_s/(2*sigma2))\n",
    "    dFdsig2_1 = T.inc_subtensor(dFdsig2_1[lp+1,j], (p/(bin_centers[lp+1]-bin_centers[lp]))*base_s/(2*sigma2))\n",
    "\n",
    "\n",
    "    # hp != lp\n",
    "    dFdsig2_2 = T.inc_subtensor(dFdsig2[hp,j], (p/dd)*base_s/(2*sigma2))\n",
    "    dFdsig2_2 = T.inc_subtensor(dFdsig2_2[lp,j], -(p/dd)*base_s/(2*sigma2))\n",
    "    \n",
    "    dFdsig2_rest = T.switch(T.eq(dd,0),\n",
    "                      dFdsig2_1,\n",
    "                      dFdsig2_2)\n",
    "    \n",
    "    dFdsig2 = T.switch(T.gt(s,bin_centers[0]) & T.lt(s,bin_centers[-1]),\n",
    "                  dFdsig2_rest,\n",
    "                  dFdsig2)    \n",
    "\n",
    "    # ------ dFdB\n",
    "    # hp == lp\n",
    "    # dFdB\n",
    "    \n",
    "    # hp != lp\n",
    "    #  lp == 0\n",
    "    dFdB2 = T.inc_subtensor(dFdB[lp,j], -2*p*(bin_centers[hp]-s)/dd**2)\n",
    "    dFdB2 = T.inc_subtensor(dFdB2[hp,j], -2*p*(s-bin_centers[lp]-dd)/dd**2)\n",
    "\n",
    "    dFdB_rest = T.switch(T.eq(lp,0),\n",
    "                      dFdB2,\n",
    "                      dFdB)  \n",
    "    \n",
    "    #  hp == bin_centers.shape[0]-1\n",
    "    dFdB3 = T.inc_subtensor(dFdB_rest[lp,j], 2*p*(dd-(bin_centers[hp]-s))/dd**2)\n",
    "    dFdB3 = T.inc_subtensor(dFdB3[hp,j], -2*p*(s-bin_centers[lp])/dd**2)\n",
    "    \n",
    "    dFdB_rest = T.switch(T.eq(hp,bin_centers.shape[0]-1),\n",
    "                      dFdB3,\n",
    "                      dFdB_rest)  \n",
    "    \n",
    "    dFdB = T.switch(T.eq(dd,0),\n",
    "                      dFdB,\n",
    "                      dFdB_rest)    \n",
    "\n",
    "    ## To detect NaN !!!\n",
    "    F = T.set_subtensor(F[(T.isnan(F)).nonzero()],0)\n",
    "    \n",
    "    return F, dFds, dFdsig2, dFdB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outer_loop(mu,j, F, dFds, dFdsig2, dFdB, base_sbins, ps, bin_centers,sigma2):\n",
    "    sbins = base_sbins + mu\n",
    "\n",
    "    n = bin_centers.shape[0]\n",
    "\n",
    "    hps = T.cast(T.ceil( (sbins-bin_centers[1])/dx) +1,'int32')\n",
    "    lps = T.cast(T.floor((sbins-bin_centers[1])/dx) +1,'int32')\n",
    "    \n",
    "    hps = T.set_subtensor(hps[(hps < 0).nonzero()],0)\n",
    "    lps = T.set_subtensor(lps[(lps < 0).nonzero()],0)\n",
    "\n",
    "    hps = T.set_subtensor(hps[(hps > n-2).nonzero()],n-2)\n",
    "    lps = T.set_subtensor(lps[(lps > n-2).nonzero()],n-2)\n",
    "    \n",
    "    hps = T.set_subtensor(hps[(bin_centers[-1]<sbins).nonzero()],n-2)\n",
    "    lps = T.set_subtensor(lps[(bin_centers[-1]<sbins).nonzero()],n-2)\n",
    "\n",
    "    hps = T.set_subtensor(hps[(sbins<bin_centers[0]).nonzero()],0)\n",
    "    lps = T.set_subtensor(lps[(sbins<bin_centers[0]).nonzero()],0)\n",
    "\n",
    "\n",
    "    hps = T.set_subtensor(hps[T.and_(bin_centers[0]<sbins, sbins<bin_centers[1]).nonzero()],1)\n",
    "    lps = T.set_subtensor(lps[T.and_(bin_centers[0]<sbins, sbins<bin_centers[1]).nonzero()],0)\n",
    "    \n",
    "    hps = T.set_subtensor(hps[T.and_(bin_centers[-2]<sbins, sbins<bin_centers[-1]).nonzero()],n-1)\n",
    "    lps = T.set_subtensor(lps[T.and_(bin_centers[-2]<sbins, sbins<bin_centers[-1]).nonzero()],n-2)\n",
    "\n",
    "\n",
    "    hps = T.set_subtensor(hps[(T.isnan(hps)).nonzero()],0)\n",
    "    lps = T.set_subtensor(lps[(T.isnan(lps)).nonzero()],0)    \n",
    "    \n",
    "    # sequences: sbins, ps, hps, lps // \n",
    "    # prior results: F //\n",
    "    # non-sequences: bin_centers, index j // \n",
    "    [F, dFds, dFdsig2, dFdB],_ = theano.scan(fn=inner_loop,\n",
    "                           outputs_info = [F, dFds, dFdsig2, dFdB],\n",
    "                           sequences = [base_sbins, sbins, ps, hps, lps],\n",
    "                           non_sequences = [bin_centers,j,sigma2],\n",
    "                           name = 'Fmatrix_outer_loop_scan' \n",
    "                           )\n",
    "    F = F[-1];\n",
    "    dFds = dFds[-1]; dFdsig2 = dFdsig2[-1]; dFdB = dFdB[-1]; \n",
    "\n",
    "    F = T.set_subtensor(F[(T.isnan(F)).nonzero()],0)\n",
    "    \n",
    "    return F, dFds, dFdsig2, dFdB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Fmatrix (Theano version)\n",
    "def Fmatrix_i(params, bin_centers):\n",
    "    global dt,dx\n",
    "    sigma2 = params[0]\n",
    "    lam = params[1]\n",
    "    c = params[2]\n",
    "    \n",
    "    \n",
    "#     F = T.zeros((bin_centers.shape[0],bin_centers.shape[0]),'float32')\n",
    "    \n",
    "    # for Fi (when lambda = 0)\n",
    "    mus = bin_centers*T.exp(lam*dt)\n",
    "\n",
    "#     mus = T.exp(lam*dt)*(bin_centers + c/lam) - c/lam\n",
    "        \n",
    "    tmp = T.ceil(10*T.sqrt(sigma2)/dx)\n",
    "    n_sbins = T.switch(T.ge(tmp,70),tmp,70) # ndeltas\n",
    "    \n",
    "    n_sbins = T.switch(T.eq(sigma2,0),1,n_sbins)\n",
    "    \n",
    "    swidth = 5*T.sqrt(sigma2)\n",
    "    sbins = (T.arange(n_sbins)+1)/n_sbins*swidth#np.linspace(-swidth,swidth,n_sbins*2+1)\n",
    "    sbins = T.concatenate((-sbins[::-1], T.zeros(1), sbins))\n",
    "\n",
    "    sbins = T.switch(T.eq(sigma2,0),T.zeros(1),sbins)\n",
    "    \n",
    "    ps = T.exp(-sbins**2/(2*sigma2)) \n",
    "    ps = ps/T.sum(ps)\n",
    "    \n",
    "    ps = T.set_subtensor(ps[(T.isnan(ps)).nonzero()],0)\n",
    "            \n",
    "    base_sbins = sbins\n",
    "        \n",
    "    # sequences: mus[1:], array(1:binsize) // mus, indices of the outer loop\n",
    "    # prior results: zeros(size(F)) // initialize F as zeros\n",
    "    # non-sequences: base_bins, ps, bin_centers // \n",
    "    [res, dFds, dFdsig2, dFdB],_ = theano.scan(fn = outer_loop,\n",
    "                      outputs_info = [T.zeros((bin_centers.shape[0],bin_centers.shape[0])), # F\n",
    "                                      T.zeros((bin_centers.shape[0],bin_centers.shape[0])), # dFds\n",
    "                                      T.zeros((bin_centers.shape[0],bin_centers.shape[0])), # dFdsig2\n",
    "                                      T.zeros((bin_centers.shape[0],bin_centers.shape[0]))], # dFdB\n",
    "                                      sequences = [mus[1:-1], T.arange(bin_centers.shape[0]-2)+1],\n",
    "                      non_sequences = [base_sbins, ps, bin_centers,sigma2],\n",
    "                      name = 'Fmatrix_i_scan'\n",
    "                     )\n",
    "    F = res[-1]\n",
    "    dFds = dFds[-1]; dFdsig2 = dFdsig2[-1]; dFdB = dFdB[-1];\n",
    " \n",
    "    # lambda == 0\n",
    "    # ------ dFdl\n",
    "    dFdl = T.zeros((bin_centers.shape[0],bin_centers.shape[0]))\n",
    "    \n",
    "    # ------ dFdh\n",
    "    dFdh = dFds*dt\n",
    "    \n",
    "    F = T.set_subtensor(F[:,0], 0)\n",
    "    F = T.set_subtensor(F[:,-1], 0)\n",
    "    F = T.set_subtensor(F[0,0], 1)\n",
    "    F = T.set_subtensor(F[-1,-1], 1)\n",
    "    \n",
    "    return F, dFdsig2, dFdB, dFdl, dFdh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Fmatrix (Theano version)\n",
    "def Fmatrix(params, bin_centers):\n",
    "    global dt,dx\n",
    "    sigma2 = params[0]\n",
    "    lam = params[1]\n",
    "    c = params[2]\n",
    "    \n",
    "    sigma2_sbin = sigma2\n",
    "    \n",
    "#     F = T.zeros((bin_centers.shape[0],bin_centers.shape[0]),'float32')\n",
    "    \n",
    "#     mus = T.switch(T.eq(lam,0),bin_centers*T.exp(lam*dt),T.exp(lam*dt)*(bin_centers + c/lam) - c/lam)\n",
    "    mus = T.exp(lam*dt)*(bin_centers + c/lam) - c/lam\n",
    "        \n",
    "    tmp = T.ceil(10*T.sqrt(sigma2_sbin)/dx)\n",
    "    n_sbins = T.switch(T.ge(tmp,70),tmp,70)\n",
    "    \n",
    "    # slices of a gaussian with sigma2 variance\n",
    "    sbin_ends = 5*T.sqrt(sigma2_sbin)\n",
    "    sbins = (T.arange(n_sbins)+1)/n_sbins*sbin_ends\n",
    "    sbins = T.concatenate((-sbins[::-1], T.zeros(1), sbins)) # np.linspace(-sbin_ends,sbin_ends,n_sbins*2+1)\n",
    "\n",
    "    ps = T.exp(-sbins**2/(2*sigma2)) \n",
    "    ps = ps/T.sum(ps)\n",
    "            \n",
    "    base_sbins = sbins\n",
    "              \n",
    "    # sequences: mus[1:], array(1:binsize) // mus, indices of the outer loop\n",
    "    # prior results: zeros(size(F)) // initialize F as zeros\n",
    "    # non-sequences: base_bins, ps, bin_centers // \n",
    "    [res, dFds, dFdsig2, dFdB],_ = theano.scan(fn = outer_loop,\n",
    "                      outputs_info = [T.zeros((bin_centers.shape[0],bin_centers.shape[0])), # F\n",
    "                                      T.zeros((bin_centers.shape[0],bin_centers.shape[0])), # dFds\n",
    "                                      T.zeros((bin_centers.shape[0],bin_centers.shape[0])), # dFdsig2\n",
    "                                      T.zeros((bin_centers.shape[0],bin_centers.shape[0]))], # dFdB\n",
    "                                      sequences = [mus[1:-1], T.arange(bin_centers.shape[0]-2)+1],\n",
    "                      non_sequences = [base_sbins, ps, bin_centers,sigma2],\n",
    "                      name = 'Fmatrix_scan'\n",
    "                     )\n",
    "    F = res[-1]\n",
    "    dFds = dFds[-1]; dFdsig2 = dFdsig2[-1]; dFdB = dFdB[-1];\n",
    "\n",
    "    # lambda > 0\n",
    "    # ------ dFdl\n",
    "    # gamma = T.exp(lam*dt), phi = c/lam\n",
    "    dFdl = dFds*(bin_centers + c/lam)*dt*T.exp(lam*dt) - dFds*c/(lam**2)*(T.exp(lam*dt)-1) \n",
    "    \n",
    "    # ------ dFdh\n",
    "    dFdh = dFds*(T.exp(lam*dt)-1)/lam\n",
    "    \n",
    "    F = T.set_subtensor(F[:,0], 0)\n",
    "    F = T.set_subtensor(F[:,-1], 0)\n",
    "    F = T.set_subtensor(F[0,0], 1)\n",
    "    F = T.set_subtensor(F[-1,-1], 1)\n",
    "    \n",
    "    return F, dFdsig2, dFdB, dFdl, dFdh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.        ,  0.41181999,  0.21890701, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.19714171,  0.17213129, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.18722765,  0.21792338, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.21792338,\n",
       "          0.18722765,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.17213129,\n",
       "          0.19714171,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.21890701,\n",
       "          0.41181999,  1.        ]]),\n",
       " array([[ 0.        ,  0.22658477,  0.6279845 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        , -0.46408419, -0.39048509, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        , -0.34179845, -0.47499883, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.47499883,\n",
       "         -0.34179845,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.39048509,\n",
       "         -0.46408419,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.6279845 ,\n",
       "          0.22658477,  0.        ]]),\n",
       " array([[ 0.        , -0.90633908, -0.6879084 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.90633908,  0.6879084 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.6879084 ,\n",
       "          0.90633908,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.6879084 ,\n",
       "         -0.90633908,  0.        ]]),\n",
       " array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " array([[ 0.        , -0.0164566 , -0.01459224, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        , -0.00100015, -0.00058484, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.00449887, -0.00227967, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.00227967,\n",
       "         -0.0022192 ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.00286452,\n",
       "         -0.00412911,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.01459224,\n",
       "          0.01930619,  0.        ]])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fi= Fmatrix_i([sigma2_i, 0, 0.0], bin_centers)\n",
    " \n",
    "\n",
    "test_func = theano.function(\n",
    "    inputs=[],\n",
    "    outputs=Fi\n",
    ")\n",
    "\n",
    "test_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F, dFds, dFdsig2, dFdB, dFdl, dFdh = Fmatrix([1.0000 ,0.1, 0.2], bin_centers)\n",
    " \n",
    "\n",
    "test_func = theano.function(\n",
    "    inputs=[],\n",
    "    outputs=F\n",
    ")\n",
    "\n",
    "test_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## Backwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Bmatrix(F,Fdistribm1,Fdistrib, dFdsig2, dFdB, dFdl, dFdh, net_input, Pd):\n",
    "    Bmat = F*Fdistribm1\n",
    "    Bmat = T.transpose(Bmat)/Fdistrib\n",
    "    Bmat = T.set_subtensor(Bmat[(T.isnan(Bmat)).nonzero()],0)\n",
    "    \n",
    "    # Joint Posterior probability \n",
    "    JmF = T.transpose(T.outer(Fdistribm1,Pd)/Fdistrib)\n",
    "    \n",
    "    Pd = T.dot(Bmat,Pd)\n",
    "    \n",
    "    JmF = T.set_subtensor(JmF[T.or_(T.isnan(JmF),T.isinf(JmF)).nonzero()],0)\n",
    "    JmF = T.set_subtensor(JmF[T.eq(F,0).nonzero()],0)\n",
    "\n",
    "    Deltak_l = T.sum(T.sum(JmF*dFdl))\n",
    "    Deltak_h = T.switch(T.eq(net_input,0),0,T.sum(T.sum(JmF*dFdh)))\n",
    "    Deltak_sig2 = T.sum(T.sum(JmF*dFdsig2))\n",
    "    Deltak_B = T.sum(T.sum(JmF*dFdB))\n",
    " \n",
    "    return JmF, Pd, Deltak_l, Deltak_h, Deltak_sig2, Deltak_B\n",
    "\n",
    "def backwards(Pf, Pd, Fmats, dFdsig2, dFdB, dFdl, dFdh, net_input):\n",
    "    # Pf 35x18\n",
    "    # Fs 17x35x35\n",
    "    \n",
    "    # normalize to use as initial distribution of the backwards, posterior run\n",
    "    Pd = Pd/T.sum(Pd)\n",
    "    \n",
    "    input_Fs = Fmats # for reversed sequence k-1 -> 1\n",
    "    input_f_m1 = Pf[:-1][:] # for reversed sequence k-1 -> 1\n",
    "    input_f = Pf[1:][:] # for reversed sequence k -> 2\n",
    "    \n",
    "    # sequences: Fs, forward probability(k-1), forward probability(k-1) \n",
    "    # results: Bmatrix // initial value = zeros\n",
    "    [JmFs, Pds, Deltak_l, Deltak_h, Deltak_sig2, Deltak_B], _ = theano.scan(fn = Bmatrix,\n",
    "                    outputs_info = [None, Pd, None, None, None, None],\n",
    "                    sequences = [input_Fs, input_f_m1, input_f, dFdsig2, dFdB, dFdl, dFdh, net_input],\n",
    "                    go_backwards = True                   \n",
    "                   )\n",
    "    \n",
    "    # last timestep of backwards distribution is Pd\n",
    "    Pb = T.concatenate([Pds[::-1][:], [Pd]],axis=0)\n",
    "    \n",
    "    Deltak_l = Deltak_l[::-1]\n",
    "    Deltak_h = Deltak_h[::-1]\n",
    "    Deltak_sig2 = Deltak_sig2[::-1]\n",
    "    Deltak_B = Deltak_B[::-1]\n",
    "\n",
    "    return JmFs, Pb, Deltak_l, Deltak_h, Deltak_sig2, Deltak_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LL = logLike(params, RightClickTimes, LeftClickTimes, Time_bins, rat_choice)\n",
    "\n",
    "params = [sigma_a, sigma_s, sigma_i, lambda, B, bias, phi, tau_phi, lapse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =========== Declare Theano symbolic variables =========== #\n",
    "## inputs\n",
    "RightClickTimes = T.dvector(\"RightClickTimes\") # Right Clicks\n",
    "LeftClickTimes = T.dvector(\"LeftClickTimes\") # Left Clicks\n",
    "Time_bins = T.vector(\"Time_bins\") # Time_bins\n",
    "rat_choice = T.wscalar(\"rat_choice\") # rat_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RClickTimes1, LClickTimes1, maxT1, rat_choice1 = trialdata(ratdata, 0)\n",
    "RClickTimes1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - LL : -2.53525394044, grads : [  3.43742048e-01   8.61102340e-02   1.00579392e+00   1.40499903e-01\n",
      "  -2.65807803e-13   9.82227353e-01   9.82179117e-01  -1.29679116e+00\n",
      "   5.89979726e+00]\n"
     ]
    }
   ],
   "source": [
    "# RClickTimes1, LClickTimes1, maxT1, rat_choice1 = trialdata(ratdata, 0)\n",
    "# np_Nstep = int(np.ceil(maxT1/dt))\n",
    "# np_empty_tmp = np.zeros((np_Nstep), dtype=theano.config.floatX)\n",
    "\n",
    "\n",
    "# theano.config.compute_test_value = 'warn'\n",
    "\n",
    "# RightClickTimes.tag.test_value = RClickTimes1\n",
    "# LeftClickTimes.tag.test_value = LClickTimes1\n",
    "# Time_bins.tag.test_value = np_empty_tmp\n",
    "# rat_choice.tag.test_value = rat_choice1\n",
    "\n",
    "theano.config.exception_verbosity = 'high'\n",
    "theano.config.allow_gc = False\n",
    "theano.config.optimizer = 'None'\n",
    "theano.config.NanGuardMode.action='warn'\n",
    "\n",
    "def logLike_w_manualdiff(params, RightClickTimes, LeftClickTimes, Time_bins, rat_choice):\n",
    "    \"\"\"\n",
    "    :params : arrays of parameters\n",
    "    : sigma2_a\n",
    "    : sigma2_s\n",
    "    : sigma2_i\n",
    "    : lam \n",
    "    : B\n",
    "    : bias\n",
    "    : phi\n",
    "    : tau_phi\n",
    "    : lapse\n",
    "    \"\"\"\n",
    "\n",
    "    sigma2_a = params[0]\n",
    "    sigma2_s = params[1]\n",
    "    sigma2_i = params[2]\n",
    "    lam = params[3]\n",
    "    B = params[4]\n",
    "    bias = params[5]\n",
    "    phi = params[6]\n",
    "    tau_phi = params[7]\n",
    "    lapse = params[8]\n",
    "            \n",
    "    # ==== inter-click-intervals and Make adapted clicks\n",
    "    # there's appreciable same-side adaptation\n",
    "        \n",
    "    # input : LeftClickTimes, RightClickTimes\n",
    "    # output : net_input, total_input\n",
    "    def make_click_inputs(LeftClickTimes, RightClickTimes, alpha, rho):\n",
    "        init_val = T.zeros(1)\n",
    "        \n",
    "        ici_l = T.extra_ops.diff(LeftClickTimes)\n",
    "        ici_r = T.extra_ops.diff(RightClickTimes)\n",
    "\n",
    "        # sequences: T.extra_ops.diff(LeftClickTimes) // inter-click-intervals\n",
    "        # prior results: lsame (0) // initial value\n",
    "        # non-sequences: phi, tau_phi // parameters\n",
    "        Lsame, updates = theano.scan(lambda ici, res, alpha, rho:\n",
    "                                     1-T.exp((rho*T.log(1-res*alpha)-ici)/rho),\n",
    "                                      outputs_info = init_val,\n",
    "                                      sequences=[ici_l],\n",
    "                                      non_sequences =[alpha, rho],\n",
    "                                      name = 'Lsame_scan'\n",
    "                                      )\n",
    "        Rsame, updates = theano.scan(lambda ici, res, alpha, rho:\n",
    "                                     1-T.exp((rho*T.log(1-res*alpha)-ici)/rho),\n",
    "                                      outputs_info = init_val,\n",
    "                                      sequences=[ici_r],\n",
    "                                      non_sequences =[alpha, rho],\n",
    "                                      name = 'Rsame_scan'\n",
    "                                      )\n",
    "\n",
    "        Lsame = T.concatenate([T.zeros(1, dtype=Lsame.dtype), Lsame[:,0]],axis=0)\n",
    "        Rsame = T.concatenate([T.zeros(1, dtype=Rsame.dtype), Rsame[:,0]],axis=0)\n",
    "\n",
    "        L_here =  T.cast(T.floor((LeftClickTimes+epsilon)/dt),'int32')\n",
    "        R_here =  T.cast(T.floor((RightClickTimes+epsilon)/dt),'int32')\n",
    "\n",
    "        ## ==== Collect the adapted click values\n",
    "        # index starts from 0\n",
    "        # net_input / total_input\n",
    "\n",
    "        # sequences: T.floor((LeftClickTimes+epsilon)/dt) // location\n",
    "        # prior results: zeros // initial value\n",
    "        # non-sequences: Lsame // parameters\n",
    "        net_input_l, updates = theano.scan(lambda lhere,lsame, tmp :\n",
    "                                         T.inc_subtensor(tmp[lhere],lsame),\n",
    "                                      outputs_info = T.zeros_like(Time_bins),\n",
    "                                      sequences = [L_here, Lsame],\n",
    "                                      name = 'net_input_1_scan'\n",
    "                                      )\n",
    "        net_input_r, updates = theano.scan(lambda rhere,rsame, tmp :\n",
    "                                         T.inc_subtensor(tmp[rhere],rsame),\n",
    "                                      outputs_info = T.zeros_like(Time_bins),\n",
    "                                      sequences = [R_here, Rsame],\n",
    "                                      name = 'net_input_r_scan'\n",
    "                                      )\n",
    "\n",
    "        net_input = net_input_r[-1] - net_input_l[-1]\n",
    "        total_input = net_input_r[-1] + net_input_l[-1]\n",
    "    \n",
    "        return net_input, total_input\n",
    "\n",
    "    [net_input, total_input] = make_click_inputs(LeftClickTimes, RightClickTimes, phi, tau_phi)\n",
    "    \n",
    "    [net_input_dphi, total_input_dphi] = make_click_inputs(LeftClickTimes, RightClickTimes, phi+ndelta, tau_phi)\n",
    "    net_input_dphi = (net_input_dphi-net_input)/ndelta\n",
    "    total_input_dphi = (total_input_dphi-total_input)/ndelta\n",
    "\n",
    "    [net_input_dtauphi, total_input_dtauphi] = make_click_inputs(LeftClickTimes, RightClickTimes, phi, tau_phi+ndelta)\n",
    "    net_input_dtauphi = (net_input_dtauphi-net_input)/ndelta\n",
    "    total_input_dtauphi = (total_input_dtauphi-total_input)/ndelta\n",
    "    \n",
    "    ## ==== make bins\n",
    "    binN = T.cast(T.ceil(B/dx),'int32')\n",
    "    bin_centers = make_bins(B,dx,binN)\n",
    "        \n",
    "    ## ==== make P init\n",
    "    a0 = T.zeros((bin_centers.shape))\n",
    "    a0 = T.set_subtensor(a0[binN],1-lapse)\n",
    "    a0 = T.set_subtensor(a0[0],lapse/2)\n",
    "    a0 = T.set_subtensor(a0[-1],lapse/2)\n",
    "    \n",
    "    ## ==== Fi\n",
    "    [Fi, dFdsig2_i, dFdB_i, dFdl_i, dFdh_i] = Fmatrix_i([sigma2_i, 0, 0.0], bin_centers)\n",
    "    \n",
    "    a = T.dot(Fi,a0)\n",
    "    a = T.set_subtensor(a[(T.isnan(a)).nonzero()],0)\n",
    "    \n",
    "    ai = a\n",
    "    \n",
    "    [F0, dFdsig2_0, dFdB_0, dFdl_0, dFdh_0] = Fmatrix([sigma2_a*dt, lam, 0.0], bin_centers)\n",
    "    \n",
    "    \n",
    "    def a_tracing(tot_input, net_input, a, F0, bin_centers, dFdsig2_0, dFdB_0):#, sigma2_a, sigma2_s, lam):\n",
    "        total_var = sigma2_a*dt + (sigma2_s*tot_input)/40\n",
    "        [F, dFdsig2, dFdB, dFdl, dFdh] = Fmatrix([total_var, lam, net_input/dt], bin_centers)\n",
    "        a = T.set_subtensor(a[(T.isnan(a)).nonzero()],0)\n",
    "        \n",
    "        a_rest = T.dot(F,a)\n",
    "\n",
    "        a = T.switch(T.eq(tot_input,0),\n",
    "                     T.dot(F0,a),\n",
    "                     a_rest\n",
    "                     )\n",
    "        F_res = T.switch(T.eq(tot_input,0),\n",
    "                     F0,\n",
    "                     F\n",
    "                     )\n",
    "        dFdsig2 = T.switch(T.eq(tot_input,0),\n",
    "                     dFdsig2_0,\n",
    "                     dFdsig2\n",
    "                     )        \n",
    "        dFdB = T.switch(T.eq(tot_input,0),\n",
    "                     dFdB_0,\n",
    "                     dFdB\n",
    "                     )        \n",
    "        dFdl = T.switch(T.eq(tot_input,0),\n",
    "                     dFdl_0,\n",
    "                     dFdl\n",
    "                     )             \n",
    "        dFdh = T.switch(T.eq(tot_input,0),\n",
    "                     dFdh_0,\n",
    "                     dFdh\n",
    "                     )     \n",
    "        \n",
    "        a = T.set_subtensor(a[(T.isnan(a)).nonzero()],0)\n",
    "        \n",
    "        return a, F_res, dFdsig2, dFdB, dFdl, dFdh\n",
    "        \n",
    "    total_input = T.set_subtensor(total_input[(T.isnan(total_input)).nonzero()],0)\n",
    "    net_input = T.set_subtensor(net_input[(T.isnan(net_input)).nonzero()],0)\n",
    "    \n",
    "    # sequences: T.floor((LeftClickTimes+epsilon)/dt) // location\n",
    "    # prior results: zeros // initial value\n",
    "    # non-sequences: Lsame // parameters\n",
    "    [a_res, F_res, dFdsig2, dFdB, dFdl, dFdh], _ = theano.scan(fn = a_tracing,\n",
    "                             outputs_info = [a, None,None,None,None,None],\n",
    "                             sequences = [total_input[:-1], net_input[:-1]],\n",
    "                             non_sequences = [F0,bin_centers, dFdsig2_0, dFdB_0],#,sigma2_a,sigma2_s,lam]\n",
    "                             name = 'a_tracing_Pf_scan'\n",
    "                        )\n",
    "    a = a_res[-1]\n",
    "    Pf = T.concatenate([[ai],a_res],axis=0)\n",
    "    \n",
    "    \n",
    "    def posterior_probability(a,bin_centers,bias,rat_choice):\n",
    "    \n",
    "        bias_hp = T.cast(T.ceil((bias-bin_centers[1])/dx) + 1,'int32') # top\n",
    "        bias_lp = T.cast(T.floor((bias-bin_centers[1])/dx) + 1,'int32')\n",
    "\n",
    "        dh = bin_centers[bias_hp] - bias\n",
    "        dl = bias - bin_centers[bias_lp]\n",
    "        dd = dh + dl\n",
    "\n",
    "        # Given probability distribution Pf \n",
    "        # Calculate the posterior probability \n",
    "        # Pd_r : right side posterior\n",
    "        # Pd_l : left side posterior\n",
    "\n",
    "        Pd_r = T.zeros((bin_centers.shape))\n",
    "        Pd_r = T.set_subtensor(Pd_r[-bias_hp+1:],a[-bias_hp+1:])\n",
    "\n",
    "        Pd_rest_r = T.set_subtensor(Pd_r[bias_hp],a[bias_hp]*(0.5+dh/dd/2))\n",
    "        Pd_rest_r = T.set_subtensor(Pd_rest_r[bias_lp],a[bias_lp]*(dh/dd/2))\n",
    "\n",
    "        Pd_r = T.switch(T.eq(bias_hp,bias_lp),\n",
    "                      T.set_subtensor(Pd_r[bias_lp],a[bias_lp]/2),\n",
    "                     Pd_rest_r)\n",
    "\n",
    "        Pd_l = T.zeros((bin_centers.shape))\n",
    "        Pd_l = T.set_subtensor(Pd_l[0:bias_lp],a[0:bias_lp])\n",
    "\n",
    "        Pd_rest_l = T.set_subtensor(Pd_l[bias_hp],a[bias_hp]*(dl/dd/2))\n",
    "        Pd_rest_l = T.set_subtensor(Pd_rest_l[bias_lp],a[bias_lp]*(0.5+dl/dd/2))\n",
    "\n",
    "        Pd_l = T.switch(T.eq(bias_hp,bias_lp),\n",
    "                      T.set_subtensor(Pd_l[bias_lp],a[bias_lp]/2),\n",
    "                     Pd_rest_l)\n",
    "\n",
    "        ## rat_choice > 0 : R\n",
    "        ## rat_choice < 0 : L\n",
    "\n",
    "        Pd = T.switch(T.gt(rat_choice,0),\n",
    "                        Pd_r,\n",
    "                        Pd_l)\n",
    "    \n",
    "        return Pd\n",
    "    \n",
    "    Pd = posterior_probability(a,bin_centers,bias,rat_choice)\n",
    "    likely = T.sum(Pd)\n",
    "    \n",
    "    JmFs, Pb, Deltak_l, Deltak_h, Deltak_sig2, Deltak_B = backwards(Pf, Pd, F_res, dFdsig2, dFdB, dFdl, dFdh, net_input[:-1])\n",
    "    \n",
    "    # consider initial state\n",
    "    JmF_i = T.ones((bin_centers.shape[0],bin_centers.shape[0]))*a0 / T.transpose(T.ones((bin_centers.shape[0],bin_centers.shape[0]))*Pf[0][:]) * T.transpose(T.ones((bin_centers.shape[0],bin_centers.shape[0]))*Pb[0][:])\n",
    "\n",
    "    JmF_i = T.set_subtensor(JmF_i[T.or_(T.isnan(JmF_i),T.isinf(JmF_i)).nonzero()],0)\n",
    "    JmF_i = T.set_subtensor(JmF_i[T.eq(Fi,0).nonzero()],0)\n",
    "    \n",
    "    grad_sigma2_i = T.sum(T.sum(JmF_i*dFdsig2_i))\n",
    "    gard_B = T.sum(T.sum(JmF_i*dFdB_i))+T.sum(Deltak_B)\n",
    "    \n",
    "    grad_lam = T.sum(Deltak_l)\n",
    "    grad_sigma2_a = T.sum(Deltak_sig2)*dt\n",
    "    grad_sigma2_s = T.sum(Deltak_sig2*total_input[:-1])/total_rate\n",
    "    \n",
    "    grad_phi = T.sum(Deltak_h*net_input_dphi[:-1])/dt + T.sum(Deltak_sig2*total_input_dphi[:-1])*sigma2_s/total_rate\n",
    "    grad_tauphi = T.sum(Deltak_h*net_input_dtauphi[:-1])/dt + T.sum(Deltak_sig2*total_input_dtauphi[:-1])*sigma2_s/total_rate\n",
    "        \n",
    "    LLepsilon = posterior_probability(a,bin_centers,bias+ndelta,rat_choice)\n",
    "    \n",
    "    grad_bias = (T.log(T.sum(LLepsilon)) - T.log(likely))/ndelta\n",
    "    grad_lapse = (T.log((likely-lapse/2)/(1-lapse)*(1-(lapse+ndelta))+(lapse+ndelta)/2) - T.log(likely))/ndelta\n",
    "    \n",
    "    return T.log(likely), T.stack([grad_sigma2_a, grad_sigma2_s, grad_sigma2_i, \n",
    "                                   grad_lam, gard_B, grad_bias, grad_phi, grad_tauphi, grad_lapse])\n",
    "\n",
    "#     return T.log(pright), T.stack([grad_sigma2_a, grad_sigma2_s,\n",
    "#                                    grad_sigma2_i, grad_lam, gard_B])\n",
    "\n",
    "\n",
    "\n",
    "#     return T.log(pright), T.stack([grad_sigma2_a, grad_sigma2_s, grad_sigma2_i, \n",
    "#                                    grad_lam, gard_B, gard_bias, grad_phi, grad_tauphi, grad_lapse])\n",
    "\n",
    "LL, out_grads = logLike_w_manualdiff(params, RightClickTimes, LeftClickTimes, Time_bins, rat_choice)\n",
    "\n",
    "# all_grads = theano.grad(cost, all_weights, known_grads = {W : masked_grads})\n",
    "grads = T.grad(LL,params, known_grads = {sigma2_a : out_grads[0],\n",
    "                                         sigma2_s : out_grads[1],\n",
    "                                         sigma2_i : out_grads[2],\n",
    "                                         lam : out_grads[3],\n",
    "                                         B : out_grads[4],\n",
    "                                         phi : out_grads[5],\n",
    "                                         tau_phi : out_grads[6],\n",
    "                                        })\n",
    "#[sigma2_a, sigma2_s, sigma2_i, lam, B, bias, lapse]\n",
    "# out_grads = T.grad(LL,lam)\n",
    "\n",
    "# grads = nan_to_inf(grads) \n",
    "# grads = theano.grad(LL, params, known_grads={z: grads}) \n",
    "\n",
    "out_grads = T.stack(*grads)\n",
    "\n",
    "practice_train = theano.function(\n",
    "    inputs = [RightClickTimes, LeftClickTimes, Time_bins, rat_choice],\n",
    "    outputs = [LL, out_grads],\n",
    "    on_unused_input = 'ignore'\n",
    "#     ,mode = theano.compile.MonitorMode(pre_func = inspect_inputs, post_func=detect_nan)\n",
    "#     ,mode = theano.compile.MonitorMode(pre_func = inspect_inputs, post_func=detect_nan)\n",
    "#     .excluding('local_elemwise_fusion', 'inplace')\n",
    "#     ,mode = NanGuardMode(nan_is_error=True, inf_is_error=True, big_is_error=True)\n",
    ")\n",
    "\n",
    "i = 0\n",
    "RClickTimes1, LClickTimes1, maxT1, rat_choice1 = trialdata(ratdata, i)\n",
    "np_Nstep = int(np.ceil(maxT1/dt))\n",
    "np_empty_tmp = np.zeros((np_Nstep), dtype=None)\n",
    "\n",
    "# gradi = practice_train(RClickTimes1, LClickTimes1, np_empty_tmp, rat_choice1)\n",
    "[LLi, gradi] = practice_train(RClickTimes1, LClickTimes1, np_empty_tmp, rat_choice1)\n",
    "# LLi = practice_train(RClickTimes1, LClickTimes1, np_empty_tmp, rat_choice1)\n",
    "\n",
    "# print \"grad : \" + str(gradi)\n",
    "print str(i+1)+ \" - LL : \" + str(LLi) + \", grads : \" + str(gradi) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.34374', '0.08611', '1.00579', '0.14050', '-0.00000', '0.98223', '0.98218', '-1.29679', '5.89980']\n",
      "['-0.06132', '-0.02141', '-0.18079', '0.02817', '-0.00000', '-0.35468', '-0.35469', '0.63216', '-0.40481']\n",
      "['-0.00344', '-0.00080', '-0.01314', '-0.00051', '0.00000', '-0.00750', '-0.00750', '0.01853', '-0.52525']\n",
      "['0.16448', '0.03588', '0.90909', '0.02751', '-0.00000', '-0.48947', '-0.48948', '-0.73245', '8.35771']\n",
      "['-0.04322', '-0.01462', '-0.27044', '0.00066', '0.00000', '0.32219', '0.32218', '0.35710', '-0.44135']\n",
      "['0.12023', '0.03510', '0.46424', '0.02075', '-0.00000', '-1.23899', '-1.23907', '-1.52379', '0.73436']\n",
      "['-0.00002', '-0.00000', '-0.00004', '-0.00000', '0.00000', '0.00002', '0.00002', '0.00007', '-0.52631']\n",
      "['-0.00014', '-0.00003', '-0.00030', '-0.00002', '0.00000', '-0.00015', '-0.00015', '0.00044', '-0.52630']\n",
      "['0.15674', '0.04506', '0.98550', '0.09029', '-0.00000', '1.63600', '1.63586', '-0.69130', '1.35303']\n",
      "['-0.02326', '-0.00757', '-0.05810', '-0.00682', '0.00000', '-0.05464', '-0.05464', '0.14281', '-0.51445']\n",
      "['0.06328', '0.01936', '0.26331', '0.04014', '-0.00000', '-1.14576', '-1.14583', '-0.32030', '0.36873']\n",
      "['-0.00063', '-0.00020', '-0.00174', '-0.00019', '0.00000', '0.00075', '0.00075', '0.00326', '-0.52619']\n",
      "['-0.04275', '-0.01498', '-0.30567', '-0.00495', '-0.00000', '0.44136', '0.44135', '0.35952', '-0.40172']\n",
      "['0.07246', '0.01953', '0.35889', '0.01137', '-0.00000', '0.19653', '0.19653', '-0.38562', '9.49473']\n",
      "['-0.02620', '-0.00947', '-0.11981', '0.00960', '0.00000', '-0.80351', '-0.80354', '0.79507', '-0.15513']\n",
      "['-0.00023', '-0.00006', '-0.00075', '-0.00005', '0.00000', '0.00027', '0.00027', '0.00090', '-0.52628']\n",
      "['-0.00405', '-0.00096', '-0.01114', '-0.00117', '0.00000', '-0.00714', '-0.00714', '0.02027', '-0.52518']\n",
      "['0.06384', '0.02165', '0.35490', '0.02304', '0.00000', '1.30616', '1.30608', '-0.51618', '0.42479']\n",
      "['-0.00163', '-0.00042', '-0.00734', '-0.00038', '-0.00000', '0.00298', '0.00298', '0.00785', '-0.52586']\n",
      "['-0.04336', '-0.00575', '-0.24109', '-0.01656', '-0.00000', '-0.29180', '-0.29181', '0.04956', '-0.45729']\n",
      "['-0.00332', '-0.00092', '-0.01642', '-0.00068', '-0.00000', '-0.00875', '-0.00875', '0.02039', '-0.52516']\n",
      "['0.00167', '0.00044', '0.00515', '0.00043', '-0.00000', '-0.00176', '-0.00176', '-0.00786', '9.99523']\n",
      "['0.01956', '0.00368', '0.10770', '0.06925', '0.00000', '1.11732', '1.11726', '0.32205', '0.12200']\n",
      "['0.17780', '0.06305', '0.59479', '-0.10026', '0.00000', '-1.25499', '-1.25507', '-1.24530', '1.12847']\n",
      "['-0.01747', '-0.00473', '-0.06681', '-0.00579', '0.00000', '0.04534', '0.04534', '0.06963', '-0.51698']\n",
      "['-0.00001', '-0.00000', '-0.00002', '-0.00000', '0.00000', '0.00001', '0.00001', '0.00004', '-0.52631']\n",
      "['-0.02241', '-0.00560', '-0.18921', '-0.00356', '-0.00000', '-0.14993', '-0.14993', '0.14370', '-0.50049']\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Training cycle for 27 trials \n",
    "# **** make same values as the matlab code.\n",
    "for i in range(27):\n",
    "    RClickTimes1, LClickTimes1, maxT1, rat_choice1 = trialdata(ratdata, i)\n",
    "    np_Nstep = int(np.ceil(maxT1/dt))\n",
    "    np_empty_tmp = np.zeros((np_Nstep), dtype=None)\n",
    "\n",
    "    [LLi, gradi] = practice_train(RClickTimes1, LClickTimes1, np_empty_tmp, rat_choice1)\n",
    " \n",
    "#     print str(i+1)+ \" - LL : \" + str(LLi) + \", grads : \" + str(gradi) \n",
    "    print [ \"{:0.5f}\".format(x) for x in gradi ]\n",
    "\n",
    "\n",
    "print \"Done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LL, out_grads = logLike_w_manualdiff(params, RightClickTimes, LeftClickTimes, Time_bins, rat_choice)\n",
    "\n",
    "# feed the value to Know Grad\n",
    "grads = T.grad(LL,params, known_grads = {sigma2_a : out_grads[0],\n",
    "                                         sigma2_s : out_grads[1],\n",
    "                                         sigma2_i : out_grads[2],\n",
    "                                         lam : out_grads[3],\n",
    "                                         B : out_grads[4],\n",
    "                                         phi : out_grads[6],\n",
    "                                         tau_phi : out_grads[7]\n",
    "                                        })\n",
    "out_grads = T.stack(*grads)\n",
    "\n",
    "practice_train = theano.function(\n",
    "    inputs = [RightClickTimes, LeftClickTimes, Time_bins, rat_choice],\n",
    "    outputs = [LL, out_grads],\n",
    "    mode = DebugMode(),\n",
    "    on_unused_input = 'ignore'\n",
    ")\n",
    "\n",
    "\n",
    "i = 0\n",
    "RClickTimes1, LClickTimes1, maxT1, rat_choice1 = trialdata(ratdata, i)\n",
    "np_Nstep = int(np.ceil(maxT1/dt))\n",
    "np_empty_tmp = np.zeros((np_Nstep), dtype=None)\n",
    "\n",
    "[LLi, gradi] = practice_train(RClickTimes1, LClickTimes1, np_empty_tmp, rat_choice1)\n",
    "\n",
    "print str(i+1)+ \" - LL : \" + str(LLi) + \", grads : \" + str(gradi) \n",
    "\n",
    "\n",
    "\n",
    "# # Training cycle\n",
    "# for i in range(27):\n",
    "#     RClickTimes1, LClickTimes1, maxT1, rat_choice1 = trialdata(ratdata, i)\n",
    "#     np_Nstep = int(np.ceil(maxT1/dt))\n",
    "#     np_empty_tmp = np.zeros((np_Nstep), dtype=None)\n",
    "\n",
    "#     [LLi, gradi] = practice_train(RClickTimes1, LClickTimes1, np_empty_tmp, rat_choice1)\n",
    " \n",
    "# #     print str(i+1)+ \" - LL : \" + str(LLi) + \", grads : \" + str(gradi) \n",
    "#     print [ \"{:0.5f}\".format(x) for x in gradi ]\n",
    "\n",
    "\n",
    "# print \"Done.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LL,gradss = logLike_w_manualdiff(params, RightClickTimes, LeftClickTimes, Time_bins, rat_choice)\n",
    "\n",
    "# grads = T.grad(LL,params)\n",
    "grads = T.grad(LL,[sigma2_a, sigma2_s, sigma2_i, lam, B, bias, lapse])\n",
    "out_grads = T.stack(*grads)\n",
    "\n",
    "practice_train = theano.function(\n",
    "    inputs = [RightClickTimes, LeftClickTimes, Time_bins, rat_choice],\n",
    "    outputs = [LL, out_grads],\n",
    "    on_unused_input = 'ignore'\n",
    ")\n",
    "\n",
    "i = 0\n",
    "RClickTimes1, LClickTimes1, maxT1, rat_choice1 = trialdata(ratdata, i)\n",
    "np_Nstep = int(np.ceil(maxT1/dt))\n",
    "np_empty_tmp = np.zeros((np_Nstep), dtype=None)\n",
    "\n",
    "[LLi, gradi] = practice_train(RClickTimes1, LClickTimes1, np_empty_tmp, rat_choice1)\n",
    "\n",
    "print str(i+1)+ \" - LL : \" + str(LLi) + \", grads : \" + str(gradi) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano.config.allow_gc = False\n",
    "theano.config.optimizer = 'None'\n",
    "theano.config.NanGuardMode.action='warn'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(gradi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print [ \"{:0.5f}\".format(x) for x in gradi ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradi[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradi[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theano.config.exception_verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_Nstep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.arange(10)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(sum(np.ones((10,10))*np.ones((10,10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
