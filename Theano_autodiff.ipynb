{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "import scipy.io\n",
    "ratdata = scipy.io.loadmat('chrono_B069_rawdata.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trial index starts from 0 \n",
    "\n",
    "def trialdata(ratdata,trial):\n",
    "    if ratdata['rawdata']['pokedR'][0][trial] > 0 :\n",
    "        rat_choice = 1 # \"R\"\n",
    "    else : \n",
    "        rat_choice = -1 # \"L\"\n",
    "        \n",
    "    return np.require(ratdata['rawdata']['rightbups'][0][trial][0],requirements='A'), \\\n",
    "np.require(ratdata['rawdata']['leftbups'][0][trial][0],requirements='A'), \\\n",
    "ratdata['rawdata']['T'][0][trial][0][0], rat_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       0.19235  0.34361]\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "# trial index starts from 0 \n",
    "RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata, 0) \n",
    "print LeftClickTimes\n",
    "print rat_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global variables \n",
    "epsilon = 10.0**(-10) \n",
    "dx = 0.25\n",
    "dt = 0.02\n",
    "\n",
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bin_centers = make_bins(B, dx, binN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### make_bins (Theano version)\n",
    "def make_bins(B, dx, binN):\n",
    "    bins = (T.arange(binN)+1)*B\n",
    "    bins = dx*bins/B\n",
    "\n",
    "    tmp = T.scalar()\n",
    "    \n",
    "    bins = T.switch(T.eq(bins[-1],B),\n",
    "                    T.set_subtensor(bins[-1], B+dx),\n",
    "                    T.set_subtensor(bins[-1], 2*B - bins[-2]))\n",
    "    \n",
    "    bins = T.concatenate((-bins[::-1], T.zeros(1), bins))\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F = Fmatrix([sigma, lambda, c], bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Fmatrix(params, bin_centers):\n",
    "    global dt,dx\n",
    "    sigma2 = params[0]\n",
    "    lam = params[1]\n",
    "    c = params[2]\n",
    "    \n",
    "    sigma2_sbin = sigma2\n",
    "    \n",
    "    F = np.zeros((bin_centers.size,bin_centers.size))\n",
    "    \n",
    "    if lam == 0:  # for Fi\n",
    "        mus = bin_centers*np.exp(lam*dt)\n",
    "    else:        \n",
    "        mus = np.exp(lam*dt)*(bin_centers + c/lam) - c/lam\n",
    "\n",
    "        \n",
    "# modified it according to gaussbins.m -amyoon\n",
    "#     sbinsize = 0.1*sigma_sbin\n",
    "#     swidth = 4*sigma_sbin\n",
    "#     sbins = np.arange(-swidth,swidth+epsilon,sbinsize)\n",
    "    n_sbins = max(70, np.ceil(10*np.sqrt(sigma2_sbin)/dx))\n",
    "\n",
    "    swidth = 5*np.sqrt(sigma2_sbin)\n",
    "    sbins = np.linspace(-swidth,swidth,n_sbins*2+1)\n",
    "    sbinsize = sbins[1]-sbins[0]\n",
    "\n",
    "    ps = np.exp(-sbins**2/(2*sigma2)) \n",
    "    ps = ps/sum(ps)\n",
    "            \n",
    "    base_sbins = sbins\n",
    "        \n",
    "    for j in np.arange(bin_centers.size-1)+1:\n",
    "        sbins = base_sbins + mus[j]\n",
    "        tmp = 1\n",
    "        \n",
    "        for k in range(sbins.size):\n",
    "            if sbins[k] <= bin_centers[0]:\n",
    "                F[0,j] += ps[k]\n",
    "            elif sbins[k] >= bin_centers[-1]:\n",
    "                F[-1,j] += ps[k]\n",
    "            else:\n",
    "                if (sbins[k] > bin_centers[0] and sbins[k] < bin_centers[1]):\n",
    "                    bottom = 0; top = 1;\n",
    "                elif (sbins[k] > bin_centers[-2] and sbins[k] < bin_centers[-1]):\n",
    "                    bottom = bin_centers.size-2; top = bin_centers.size-1;\n",
    "                else :    \n",
    "                    bottom = int(np.floor((sbins[k]-bin_centers[1])/dx) + 1);\n",
    "                    top = int(np.ceil((sbins[k]-bin_centers[1])/dx) + 1);\n",
    "\n",
    "                if bottom < 0: bottom = 0; \n",
    "                if top < 0: top = 0; \n",
    "\n",
    "                if bottom == top:\n",
    "                    F[bottom,j] += ps[k]\n",
    "                else:\n",
    "                    F[top,j] += ps[k]*(sbins[k] - bin_centers[bottom])/(bin_centers[top] - bin_centers[bottom])\n",
    "                    F[bottom,j] += ps[k]*(bin_centers[top] - sbins[k])/(bin_centers[top] - bin_centers[bottom])\n",
    "                        \n",
    "    F[:,0] = 0\n",
    "    F[:,-1] = 0\n",
    "    F[0,0] = 1\n",
    "    F[-1,-1] = 1\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LL = logProbRight(params)\n",
    "\n",
    "params = [sigma_a, sigma_s, sigma_i, lambda, B, bias, phi, tau_phi, lapse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{Cast{int32}}.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a float is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-251e19adf35b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m LL = logLike(sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse, \n\u001b[0;32m--> 202\u001b[0;31m                           RightClickTimes, LeftClickTimes, maxT, rat_choice)\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m train = theano.function(\n",
      "\u001b[0;32m<ipython-input-7-251e19adf35b>\u001b[0m in \u001b[0;36mlogLike\u001b[0;34m(sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse, RightClickTimes, LeftClickTimes, maxT, rat_choice)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtf_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msigma_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau_phi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrat_choice\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# == \"R\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mLP_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogProbRight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRightClickTimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLeftClickTimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#         print \"R : \" + str(LP_right)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mLP_right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-251e19adf35b>\u001b[0m in \u001b[0;36mlogProbRight\u001b[0;34m(params, RightClickTimes, LeftClickTimes, maxT)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLeftClickTimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mlast_L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtau_phi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mLsame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mLsame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mici_L\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlast_L\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtau_phi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a float is required"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================== Model ================================ #\n",
    "\n",
    "def logLike(sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse, RightClickTimes, LeftClickTimes, maxT, rat_choice):\n",
    "    tf_params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]\n",
    "    if T.gt(rat_choice , 0): # == \"R\":\n",
    "        LP_right = logProbRight(tf_params, RightClickTimes, LeftClickTimes, maxT)\n",
    "#         print \"R : \" + str(LP_right)\n",
    "        return LP_right\n",
    "    elif T.lt(rat_choice , 0): # == \"L\":\n",
    "        LP_right = logProbRight(tf_params, RightClickTimes, LeftClickTimes, maxT)\n",
    "#         print \"L : \" + str(np.log(1 - np.exp(LP_right)))\n",
    "        return np.log(1 - np.exp(LP_right))\n",
    "    else:\n",
    "        print -1. # \"Rat did what?? It was neither R nor L\"\n",
    "        \n",
    "def logProbRight(params, RightClickTimes, LeftClickTimes, maxT):\n",
    "#     sigma_a = params['sigma_a']\n",
    "#     sigma_s = params['sigma_s']\n",
    "#     sigma_i = params['sigma_i']\n",
    "#     lam = params['lambda']\n",
    "#     B = params['B']\n",
    "#     bias = params['bias']\n",
    "#     phi = params['phi']\n",
    "#     tau_phi = params['tau_phi']\n",
    "#     lapse = params['lapse']\n",
    "#     params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]  \n",
    "    \n",
    "    sigma2_a = params[0]\n",
    "    sigma2_s = params[1]\n",
    "    sigma2_i = params[2]\n",
    "    lam = params[3]\n",
    "    B = params[4]\n",
    "    bias = params[5]\n",
    "    phi = params[6]\n",
    "    tau_phi = params[7]\n",
    "    lapse = params[8]\n",
    "    \n",
    "    global a, dx, dt, a_trace, c_trace\n",
    "        \n",
    "    Nsteps = T.cast(T.ceil(maxT/dt),'int32')\n",
    "\n",
    "#     if RightClickTimes.size == 0:\n",
    "#         RightClickTimes = np.empty(0)\n",
    "#     if LeftClickTimes.size == 0:\n",
    "#         LeftClickTimes = np.empty(0)\n",
    "\n",
    "    print Nsteps\n",
    "    \n",
    "#     net_input = tf.zeros([1, Nsteps.eval()], tf.float64)\n",
    "#     total_input = tf.zeros([1, Nsteps.eval()], tf.float64)\n",
    "#     NClicks = tf.zeros([1, Nsteps], tf.int32)    \n",
    "#     net_input = tf.placeholder(tf.float64, [1, None],name='net_input')\n",
    "#     total_input = tf.placeholder(tf.float64, [1, None],name='total_input')\n",
    "#     NClicks = tf.placeholder(tf.int32, [1, None], name='Nclicks')    \n",
    "\n",
    "        \n",
    "    # ====== Make adapted clicks\n",
    "    \n",
    "    Lsame = T.ones(T.shape(LeftClickTimes))\n",
    "    Rsame = T.ones(T.shape(RightClickTimes))\n",
    "    # magnitude of stereo clicks set to zero   \n",
    "    Lsame = T.set_subtensor(Lsame[0],0)\n",
    "    Rsame = T.set_subtensor(Rsame[0],0)\n",
    "    \n",
    "    # inter-click-intervals\n",
    "    ici_L = T.extra_ops.diff(LeftClickTimes)\n",
    "    ici_R = T.extra_ops.diff(RightClickTimes)\n",
    "\n",
    "    \n",
    "    for i in np.arange(np.size(LeftClickTimes)-1)+1:\n",
    "        last_L = tau_phi*np.log(1-Lsame[0][i-1]*phi)\n",
    "        Lsame[0][i] = 1 - np.exp((-ici_L[i-1] + last_L)/tau_phi)\n",
    "        \n",
    "    for i in np.arange(np.size(RightClickTimes)-1)+1:\n",
    "        last_R = tau_phi*np.log(1-Rsame[0][i-1]*phi)\n",
    "        Rsame[0][i] = 1 - np.exp((-ici_R[i-1] + last_R)/tau_phi)\n",
    "\n",
    "    Lsame = Lsame.real    \n",
    "    Rsame = Rsame.real   \n",
    "        \n",
    "    # index starts from 0\n",
    "    # net_input / total_input\n",
    "    # Counting number of clicks\n",
    "    cnt = 0\n",
    "    for i in np.ceil((RightClickTimes+epsilon)/dt).astype(int):\n",
    "        NClicks[0][i-1] += 1\n",
    "        net_input[0][i-1] += Rsame[0][cnt]\n",
    "        total_input[0][i-1] += Rsame[0][cnt]\n",
    "        cnt += 1\n",
    "    \n",
    "    cnt = 0 \n",
    "    for i in np.ceil((LeftClickTimes+epsilon)/dt).astype(int):\n",
    "        NClicks[0][i-1] += 1  \n",
    "        net_input[0][i-1] -= Lsame[0][cnt]\n",
    "        total_input[0][i-1] += Lsame[0][cnt]\n",
    "        cnt += 1        \n",
    "       \n",
    "    binN = int(np.ceil(B/dx))\n",
    "    \n",
    "    bin_centers = make_bins(B,dx,binN)\n",
    "        \n",
    "    a_trace = np.zeros((bin_centers.size, Nsteps))\n",
    "    c_trace = np.zeros((1, Nsteps+1))\n",
    "    a0 = np.zeros(bin_centers.size)\n",
    "    a0[binN] = 1-2*lapse; a0[0] = lapse; a0[-1] = lapse;\n",
    "    \n",
    "    Fi = Fmatrix([sigma2_i, 0, 0.0], bin_centers)\n",
    "    \n",
    "    a = np.matmul(Fi,a0)\n",
    "    a_trace[:,0] = a.flatten()\n",
    " \n",
    "    F0 = Fmatrix([sigma2_a*dt, lam, 0.0], bin_centers)\n",
    "    for i in np.arange(Nsteps-1)+1:\n",
    "        if total_input[0][i-1]==0:\n",
    "            a = np.matmul(F0,a)\n",
    "        else:\n",
    "            total_var = sigma2_a*dt + (sigma2_s*total_input[0][i-1])/40\n",
    "            F = Fmatrix([total_var, lam, net_input[0][i-1]/dt], bin_centers)\n",
    "            a = np.matmul(F,a)\n",
    "            \n",
    "        c_trace[0][i] = net_input[0][i-1]\n",
    "        a_trace[:,i] = a.flatten()\n",
    "\n",
    "    bias_bottom = int(np.floor((bias-bin_centers[1])/dx) + 1)\n",
    "    bias_top = int(np.ceil((bias-bin_centers[1])/dx) + 1) # top\n",
    "    \n",
    "    Pd = np.zeros((1, bin_centers.size))\n",
    "    Pd[0][-bias_top+1:] = a[-bias_top+1:]\n",
    "    if bias_bottom == bias_top:\n",
    "        Pd[0][bias_bottom] = a[bias_bottom]/2\n",
    "    else:\n",
    "        dh = bin_centers[bias_top] - bias\n",
    "        dl = bias - bin_centers[bias_bottom]\n",
    "        dd = dh + dl\n",
    "        Pd[0][bias_top] = a[bias_top]*(0.5 + dh/dd/2)\n",
    "        Pd[0][bias_bottom] = a[bias_bottom]*(dh/dd/2)\n",
    "    \n",
    "    pright = sum(Pd[0])\n",
    "    \n",
    "    return np.log(pright)\n",
    "\n",
    "\n",
    "# =========== Declare Theano symbolic variables =========== #\n",
    "\n",
    "## Variables \n",
    "# 1. (can assign the name of each variable later..)\n",
    "# tf_params = tf.Variable(params, name = \"params\")\n",
    "\n",
    "# 2. \n",
    "# tf_params = {\n",
    "#     'sigma_a' : tf.Variable(sigma_a, name=\"sigma_a\"),\n",
    "#     'sigma_s' : tf.Variable(sigma_s, name=\"sigma_s\"),\n",
    "#     'sigma_i' : tf.Variable(sigma_i, name=\"sigma_i\"),\n",
    "#     'lamda' : tf.Variable(lam, name=\"lambda\"),\n",
    "#     'B' : tf.Variable(B, name=\"B\"),\n",
    "#     'bias' : tf.Variable(bias, name=\"bias\"),\n",
    "#     'phi' : tf.Variable(phi, name=\"phi\"),\n",
    "#     'tau_phi' : tf.Variable(tau_phi, name=\"tau_phi\"),\n",
    "#     'lapse' : tf.Variable(lapse, name=\"lapse\")\n",
    "# }\n",
    "\n",
    "# 3.\n",
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05;\n",
    "\n",
    "sigma_a = theano.shared(sigma_a, name=\"sigma_a\")\n",
    "sigma_s = theano.shared(sigma_s, name=\"sigma_s\")\n",
    "sigma_i = theano.shared(sigma_i, name=\"sigma_i\")\n",
    "lam = theano.shared(lam, name=\"lambda\")\n",
    "B = theano.shared(B, name=\"B\")\n",
    "bias = theano.shared(bias, name=\"bias\")\n",
    "phi = theano.shared(phi, name=\"phi\")\n",
    "tau_phi = theano.shared(tau_phi, name=\"tau_phi\")\n",
    "lapse = theano.shared(lapse, name=\"lapse\")\n",
    "# tf_params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]   \n",
    "\n",
    "# ----------tip\n",
    "# values = [1.0, 3.0]\n",
    "# vars_ = [tf.Variable([v], dtype=dtype) for v in values]\n",
    "\n",
    "\n",
    "# =========== Declare Theano symbolic variables =========== #\n",
    "## inputs\n",
    "RightClickTimes = T.dvector()#tf.placeholder(tf.float32, name = 'RightClickTimes') # Right Clicks\n",
    "LeftClickTimes = T.dvector()#tf.placeholder(tf.float32, name = 'LeftClickTimes') # Left Clicks\n",
    "maxT = T.dscalar()#tf.placeholder(tf.float32, name = 'maxT')\n",
    "rat_choice = T.wscalar()#tf.placeholder(tf.float32, name = 'rat_choice')\n",
    "\n",
    "\n",
    "# ==================== Construct Model ========================= #\n",
    "\n",
    "# LL = tf.py_func(logLike, [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse, \n",
    "#                           RightClickTimes, LeftClickTimes, maxT, rat_choice], [tf.float64])\n",
    "\n",
    "\n",
    "LL = logLike(sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse, \n",
    "                          RightClickTimes, LeftClickTimes, maxT, rat_choice)\n",
    "\n",
    "train = theano.function(\n",
    "    inputs = [RightClickTimes, LeftClickTimes, maxT, rat_choice],\n",
    "#     updates = \n",
    "    outputs = [LL]\n",
    ")\n",
    "\n",
    "\n",
    "# opt = tf.train.AdamOptimizer(0.1)\n",
    "# grads_and_vars = opt.compute_gradients(tf.to_float(LL[0]),[sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse])\n",
    "# grads2 = [g for g, _ in grads_and_vars]\n",
    "# vars2 = [v for _, v in grads_and_vars]\n",
    "\n",
    "# var_grad = tf.gradients(LL[0],[sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse])[0]\n",
    "\n",
    "# ==================== Launch the Graph ========================= #\n",
    "\n",
    "# init = tf.initialize_all_variables()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "    \n",
    "total_LL = 0.\n",
    "\n",
    "# Training cycle\n",
    "for i in range(10):\n",
    "    RClickTimes1, LClickTimes1, maxT1, rat_choice1 = trialdata(ratdata, i)\n",
    "\n",
    "    LLi = train(RClickTimes1, LClickTimes1, maxT1, rat_choice1)\n",
    "\n",
    "    total_LL += LLi\n",
    "\n",
    "\n",
    "    print \"Trial :\", '%04d' % (i+1), \"LL = \", \"{:.9f}\".format(total_LL)\n",
    "\n",
    "print \"Done.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.]\n"
     ]
    }
   ],
   "source": [
    "a = T.dvector()\n",
    "out = T.extra_ops.diff(a)\n",
    "f = theano.function([a], out)\n",
    "print(f([0, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = theano.tensor.arange(9).reshape((3,3))\n",
    "t2=T.set_subtensor(t[0],1)\n",
    "a = t2[0].eval()\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join.0\n",
      "Trial : 0001 LL =  2.211745769\n",
      "Trial : 0002 LL =  6.211745769\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def trialdata(ratdata,trial):\n",
    "    if ratdata['rawdata']['pokedR'][0][trial] > 0 :\n",
    "        rat_choice = 1 # \"R\"\n",
    "    else : \n",
    "        rat_choice = -1 # \"L\"\n",
    "        \n",
    "    return np.require(ratdata['rawdata']['rightbups'][0][trial][0],requirements='A'), \\\n",
    "np.require(ratdata['rawdata']['leftbups'][0][trial][0],requirements='A'), \\\n",
    "ratdata['rawdata']['T'][0][trial][0][0], rat_choice\n",
    "\n",
    "def practice_LL(sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse, \n",
    "                          RightClickTimes, LeftClickTimes, Time_bins, rat_choice):\n",
    "    \n",
    "    pright = T.dscalar()\n",
    "    \n",
    "    # ==== inter-click-intervals and Make adapted clicks\n",
    "    \n",
    "    net_input = T.vector(\"net_input\")\n",
    "    total_input = T.vector(\"total_input\")\n",
    "\n",
    "\n",
    "    # :: can be integrated with one function\n",
    "    \n",
    "    # sequences: T.extra_ops.diff(LeftClickTimes) // inter-click-intervals\n",
    "    # prior results: lsame (0) // initial value\n",
    "    # non-sequences: phi, tau_phi // parameters\n",
    "    Lsame, updates = theano.scan(lambda ici, lsame, phi, tau_phi :\n",
    "                                     1-T.exp((tau_phi*T.log(1-lsame*phi)-ici)/tau_phi),\n",
    "                                  outputs_info = T.zeros(1),\n",
    "                                  sequences=[T.extra_ops.diff(LeftClickTimes)],\n",
    "                                  non_sequences=[phi, tau_phi]\n",
    "                                  )\n",
    "    Rsame, updates = theano.scan(lambda ici, rsame, phi, tau_phi : \n",
    "                                 1-T.exp((tau_phi*T.log(1-rsame*phi)-ici)/tau_phi),\n",
    "                                  outputs_info = T.zeros(1),\n",
    "                                  sequences=[T.extra_ops.diff(RightClickTimes)],\n",
    "                                  non_sequences=[phi, tau_phi]\n",
    "                                  )\n",
    "\n",
    "    Lsame = T.concatenate([T.zeros(1, dtype=Lsame.dtype), Lsame[:,0]],axis=0)\n",
    "    Rsame = T.concatenate([T.zeros(1, dtype=Rsame.dtype), Rsame[:,0]],axis=0)\n",
    "\n",
    "    L_here =  T.cast(T.floor((LeftClickTimes+epsilon)/dt),'int32')\n",
    "    R_here =  T.cast(T.floor((RightClickTimes+epsilon)/dt),'int32')\n",
    "\n",
    "    dtype=theano.config.floatX\n",
    "\n",
    "    np_Nstep = int(np.ceil(maxT1/dt))\n",
    "    np_empty_tmp = np.zeros((np_Nstep), dtype=dtype)\n",
    "\n",
    "    template = T.vector('template')\n",
    "\n",
    "    ## ==== Collect the adapted click values\n",
    "    # index starts from 0\n",
    "    # net_input / total_input\n",
    "\n",
    "    # sequences: T.floor((LeftClickTimes+epsilon)/dt) // location\n",
    "    # prior results: zeros // initial value\n",
    "    # non-sequences: Lsame // parameters\n",
    "    net_input_l, updates = theano.scan(lambda lhere,lsame, tmp :\n",
    "                                     T.set_subtensor(tmp[lhere],tmp[lhere]+lsame),\n",
    "                                  outputs_info = T.zeros_like(Time_bins),\n",
    "                                  sequences = [L_here, Lsame]\n",
    "                                  )\n",
    "    net_input_r, updates = theano.scan(lambda rhere,rsame, tmp :\n",
    "                                     T.set_subtensor(tmp[rhere],tmp[rhere]+rsame),\n",
    "                                  outputs_info = T.zeros_like(Time_bins),\n",
    "                                  sequences = [R_here, Rsame]\n",
    "                                  )\n",
    "\n",
    "    net_input = net_input_r[-1] - net_input_l[-1]\n",
    "    total_input = net_input_r[-1] + net_input_l[-1]\n",
    "    \n",
    "    ## ==== make bins\n",
    "    binN = T.cast(T.ceil(B/dx),'int32')\n",
    "    bin_centers = make_bins(B,dx,binN)\n",
    "        \n",
    "    ## ==== make P init\n",
    "    a0 = T.zeros_like(bin_centers)\n",
    "    a0 = T.set_subtensor(a0[binN],1-2*lapse)\n",
    "    a0 = T.set_subtensor(a0[0],lapse)\n",
    "    a0 = T.set_subtensor(a0[-1],lapse)\n",
    "    \n",
    "#     a_trace = np.zeros((bin_centers.size, Nsteps))\n",
    "#     c_trace = np.zeros((1, Nsteps+1))\n",
    "\n",
    "    ## ==== Fi\n",
    "    Fi = Fmatrix_i([sigma2_i, 0, 0.0], bin_centers)\n",
    "    \n",
    "    a = T.dot(Fi,a0)\n",
    "#     a_trace[:,0] = a.flatten()\n",
    " \n",
    "    F0 = Fmatrix([sigma2_a*dt, lam, 0.0], bin_centers)\n",
    "    \n",
    "    \n",
    "    def a_tracing(tot_input,net_input,a,F0,bin_centers,sigma2_a,sigma2_s,lam):\n",
    "        total_var = sigma2_a*dt + (sigma2_s*tot_input)/40\n",
    "        F = Fmatrix([total_var, lam, net_input/dt], bin_centers)\n",
    "        a_rest = T.dot(F,a)\n",
    "        \n",
    "        a = T.switch(T.eq(tot_input,0),\n",
    "                     T.dot(F0,a),\n",
    "                     a_rest\n",
    "                     )\n",
    "        \n",
    "        return a\n",
    "        \n",
    "    # sequences: T.floor((LeftClickTimes+epsilon)/dt) // location\n",
    "    # prior results: zeros // initial value\n",
    "    # non-sequences: Lsame // parameters\n",
    "    res, _ = theano.scan(fn = a_tracing,\n",
    "                             outputs_info = a,\n",
    "                             sequences = [total_input, net_input],\n",
    "                             non_sequences = [F0,bin_centers,sigma2_a,sigma2_s,lam]\n",
    "                        )\n",
    "\n",
    "    \n",
    "#     Pd = np.zeros((1, bin_centers.size))\n",
    "#     Pd[0][-bias_top+1:] = a[-bias_top+1:]\n",
    "#     if bias_bottom == bias_top:\n",
    "#         Pd[0][bias_bottom] = a[bias_bottom]/2\n",
    "#     else:\n",
    "#         dh = bin_centers[bias_top] - bias\n",
    "#         dl = bias - bin_centers[bias_bottom]\n",
    "#         dd = dh + dl\n",
    "#         Pd[0][bias_top] = a[bias_top]*(0.5 + dh/dd/2)\n",
    "#         Pd[0][bias_bottom] = a[bias_bottom]*(dh/dd/2)\n",
    "    \n",
    "#     pright = sum(Pd[0])\n",
    "    \n",
    "    pright = rat_choice + a[0] + res[0][0] + net_input[0] + a0[binN] + Fi[0][0] + F0[0][0] \n",
    "    return pright\n",
    "    \n",
    "# 3.\n",
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05;\n",
    "\n",
    "sigma2_a = theano.shared(sigma_a, name=\"sigma_a\")\n",
    "sigma2_s = theano.shared(sigma_s, name=\"sigma_s\")\n",
    "sigma2_i = theano.shared(sigma_i, name=\"sigma_i\")\n",
    "lam = theano.shared(lam, name=\"lambda\")\n",
    "B = theano.shared(B, name=\"B\")\n",
    "bias = theano.shared(bias, name=\"bias\")\n",
    "phi = theano.shared(phi, name=\"phi\")\n",
    "tau_phi = theano.shared(tau_phi, name=\"tau_phi\")\n",
    "lapse = theano.shared(lapse, name=\"lapse\")\n",
    "    \n",
    "# =========== Declare Theano symbolic variables =========== #\n",
    "## inputs\n",
    "RightClickTimes = T.dvector(\"RightClickTimes\") # Right Clicks\n",
    "LeftClickTimes = T.dvector(\"LeftClickTimes\") # Left Clicks\n",
    "Time_bins = T.vector(\"Time_bins\") # Time_bins\n",
    "rat_choice = T.wscalar(\"rat_choice\") # rat_choice\n",
    "\n",
    "# ==================== Construct Model ========================= #\n",
    "\n",
    "# LL = tf.py_func(logLike, [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse, \n",
    "#                           RightClickTimes, LeftClickTimes, maxT, rat_choice], [tf.float64])\n",
    "\n",
    "\n",
    "LL = practice_LL(sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse, \n",
    "                          RightClickTimes, LeftClickTimes, Time_bins, rat_choice)\n",
    "\n",
    "practice_train = theano.function(\n",
    "    inputs = [RightClickTimes, LeftClickTimes, Time_bins, rat_choice],\n",
    "    outputs = [LL]\n",
    ")\n",
    "\n",
    "    \n",
    "total_LL = 0.\n",
    "\n",
    "# Training cycle\n",
    "for i in range(2):\n",
    "    RClickTimes1, LClickTimes1, maxT1, rat_choice1 = trialdata(ratdata, i)\n",
    "    np_Nstep = int(np.ceil(maxT1/dt))\n",
    "    np_empty_tmp = np.zeros((np_Nstep), dtype=dtype)\n",
    "\n",
    "    LLi = practice_train(RClickTimes1, LClickTimes1, np_empty_tmp, rat_choice1)\n",
    "\n",
    "    total_LL += LLi[0]\n",
    "\n",
    "\n",
    "    print \"Trial :\", '%04d' % (i+1), \"LL = \", \"{:.9f}\".format(total_LL)\n",
    "\n",
    "print \"Done.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.21174577,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.59572769,  0.        ,  0.        ,  0.        , -0.85390527,\n",
       "         0.68879055,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.0679164 , -0.83610755]),\n",
       " array([ 0.21174577,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.59572769,  0.        ,  0.        ,  0.        ,  0.85390527,\n",
       "         0.68879055,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.0679164 ,  0.83610755])]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RightClickTimes = T.dvector(\"RightClickTimes\")# Right Clicks\n",
    "LeftClickTimes = T.dvector(\"LeftClickTimes\")# Left Clicks\n",
    "template = T.vector('template')\n",
    "rat_choice = T.wscalar(\"rat_choice\")\n",
    "\n",
    "# ==== inter-click-intervals and Make adapted clicks\n",
    "net_input = T.vector(\"net_input\")\n",
    "total_input = T.vector(\"total_input\")\n",
    "\n",
    "# sequences: T.extra_ops.diff(LeftClickTimes) // inter-click-intervals\n",
    "# prior results: lsame (0) // initial value\n",
    "# non-sequences: phi, tau_phi // parameters\n",
    "Lsame, updates = theano.scan(lambda ici, lsame, phi, tau_phi :\n",
    "                                 1-T.exp((tau_phi*T.log(1-lsame*phi)-ici)/tau_phi),\n",
    "                              outputs_info = T.zeros(1),\n",
    "                              sequences=[T.extra_ops.diff(LeftClickTimes)],\n",
    "                              non_sequences=[phi, tau_phi]\n",
    "                              )\n",
    "Rsame, updates = theano.scan(lambda ici, rsame, phi, tau_phi : \n",
    "                             1-T.exp((tau_phi*T.log(1-rsame*phi)-ici)/tau_phi),\n",
    "                              outputs_info = T.zeros(1),\n",
    "                              sequences=[T.extra_ops.diff(RightClickTimes)],\n",
    "                              non_sequences=[phi, tau_phi]\n",
    "                              )\n",
    "\n",
    "Lsame = T.concatenate([T.zeros(1, dtype=Lsame.dtype), Lsame[:,0]],axis=0)\n",
    "Rsame = T.concatenate([T.zeros(1, dtype=Rsame.dtype), Rsame[:,0]],axis=0)\n",
    "\n",
    "L_here =  T.cast(T.floor((LeftClickTimes+epsilon)/dt),'int32')\n",
    "R_here =  T.cast(T.floor((RightClickTimes+epsilon)/dt),'int32')\n",
    "\n",
    "# ==== Collect the adapted click values\n",
    "# index starts from 0\n",
    "# net_input / total_input\n",
    "\n",
    "# sequences: T.floor((LeftClickTimes+epsilon)/dt) // location\n",
    "# prior results: zeros // initial value\n",
    "# non-sequences: Lsame // parameters\n",
    "net_input_l, updates = theano.scan(lambda lhere,lsame, tmp :\n",
    "                                 T.set_subtensor(tmp[lhere],tmp[lhere]+lsame),\n",
    "                              outputs_info = T.zeros_like(template),\n",
    "                              sequences = [L_here, Lsame]\n",
    "                              )\n",
    "net_input_r, updates = theano.scan(lambda rhere,rsame, tmp :\n",
    "                                 T.set_subtensor(tmp[rhere],tmp[rhere]+rsame),\n",
    "                              outputs_info = T.zeros_like(template),\n",
    "                              sequences = [R_here, Rsame]\n",
    "                              )\n",
    "\n",
    "net_input = net_input_r[-1] - net_input_l[-1]\n",
    "total_input = net_input_r[-1] + net_input_l[-1]\n",
    "\n",
    "test_func = theano.function(\n",
    "    inputs=[LeftClickTimes,RightClickTimes,template],\n",
    "    outputs=[net_input,total_input]\n",
    ")\n",
    "\n",
    "\n",
    "############ testing with REAL data \n",
    "RClickTimes1, LClickTimes1, maxT1, rat_choice1 = trialdata(ratdata, 0)\n",
    "\n",
    "dtype=theano.config.floatX\n",
    "\n",
    "np_Nstep = int(np.ceil(maxT1/dt))\n",
    "np_empty_tmp = np.zeros((np_Nstep), dtype=dtype)\n",
    "\n",
    "\n",
    "\n",
    "test_func(LClickTimes1,RClickTimes1,np_empty_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_a\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05;\n",
    "\n",
    "sigma_a = theano.shared(sigma_a, name=\"sigma_a\")\n",
    "sigma_s = theano.shared(sigma_s, name=\"sigma_s\")\n",
    "sigma_i = theano.shared(sigma_i, name=\"sigma_i\")\n",
    "lam = theano.shared(lam, name=\"lambda\")\n",
    "B = theano.shared(B, name=\"B\")\n",
    "bias = theano.shared(bias, name=\"bias\")\n",
    "phi = theano.shared(phi, name=\"phi\")\n",
    "tau_phi = theano.shared(tau_phi, name=\"tau_phi\")\n",
    "lapse = theano.shared(lapse, name=\"lapse\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-4.2 , -4.  , -3.75, -3.5 , -3.25, -3.  , -2.75, -2.5 , -2.25,\n",
       "        -2.  , -1.75, -1.5 , -1.25, -1.  , -0.75, -0.5 , -0.25,  0.  ,\n",
       "         0.25,  0.5 ,  0.75,  1.  ,  1.25,  1.5 ,  1.75,  2.  ,  2.25,\n",
       "         2.5 ,  2.75,  3.  ,  3.25,  3.5 ,  3.75,  4.  ,  4.2 ]),\n",
       " array(17, dtype=int32),\n",
       " array(-0.09999999999999964)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### make_bins (Theano version)\n",
    "def make_bins(B, dx, binN):\n",
    "    bins = (T.arange(binN)+1)*B\n",
    "    bins = dx*bins/B\n",
    "\n",
    "    tmp = T.scalar()\n",
    "    \n",
    "    bins = T.switch(T.eq(bins[-1],B),\n",
    "                    T.set_subtensor(bins[-1], B+dx),\n",
    "                    T.set_subtensor(bins[-1], 2*B - bins[-2]))\n",
    "    \n",
    "    bins = T.concatenate((-bins[::-1], T.zeros(1), bins))\n",
    "    return bins\n",
    "\n",
    "binN = T.cast(T.ceil(B/dx),'int32')\n",
    "bin_centers = make_bins(B, dx, binN)\n",
    "\n",
    "test_func = theano.function(\n",
    "    inputs=[],\n",
    "    outputs=[bin_centers, binN, test]\n",
    ")\n",
    "\n",
    "test_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Fmatrix (Theano version)\n",
    "def Fmatrix_i(params, bin_centers):\n",
    "    global dt,dx\n",
    "    sigma2 = params[0]\n",
    "    lam = params[1]\n",
    "    c = params[2]\n",
    "    \n",
    "    sigma2_sbin = sigma2\n",
    "    \n",
    "    F = T.zeros((bin_centers.shape[0],bin_centers.shape[0]),'float32')\n",
    "    \n",
    "    # for Fi (when lambda = 0)\n",
    "    mus = bin_centers*T.exp(lam*dt)\n",
    "\n",
    "#     mus = T.exp(lam*dt)*(bin_centers + c/lam) - c/lam\n",
    "        \n",
    "    tmp = T.ceil(10*T.sqrt(sigma2_sbin)/dx)\n",
    "    n_sbins = T.switch(T.ge(tmp,70),tmp,70)\n",
    "    \n",
    "    swidth = 5*T.sqrt(sigma2_sbin)\n",
    "    sbins = (T.arange(n_sbins)+1)/n_sbins*swidth#np.linspace(-swidth,swidth,n_sbins*2+1)\n",
    "    sbins = T.concatenate((-sbins[::-1], T.zeros(1), sbins))\n",
    "\n",
    "    ps = T.exp(-sbins**2/(2*sigma2)) \n",
    "    ps = ps/T.sum(ps)\n",
    "            \n",
    "    base_sbins = sbins\n",
    "        \n",
    "        \n",
    "    def inner_loop(sbin, p, hp, lp, F, bin_centers,j):\n",
    "        dd = bin_centers[hp] - bin_centers[lp]\n",
    "        \n",
    "        FF = T.set_subtensor(F[hp,j], F[hp,j]+p*(sbin-bin_centers[lp])/dd)\n",
    "        FF = T.set_subtensor(FF[lp,j], FF[lp,j]+p*(bin_centers[hp]-sbin)/dd)\n",
    "        \n",
    "        F_rest = T.switch(T.eq(dd,0),\n",
    "                          T.set_subtensor(F[lp,j], F[lp,j]+p),\n",
    "                          FF)\n",
    "        \n",
    "        F = T.switch(T.le(sbin,bin_centers[0]),\n",
    "                          T.set_subtensor(F[0,j], F[0,j]+p),\n",
    "                          F)\n",
    "        F = T.switch(T.ge(sbin,bin_centers[-1]),\n",
    "                          T.set_subtensor(F[-1,j], F[-1,j]+p),\n",
    "                          F)\n",
    "        F = T.switch(T.gt(sbin,bin_centers[0]) & T.lt(sbin,bin_centers[-1]),\n",
    "                          F_rest,#T.set_subtensor(F[-1,j], -3),#F_rest,\n",
    "                          F)\n",
    "\n",
    "        \n",
    "        return F\n",
    "    \n",
    "    def outer_loop(mu,j, F, base_sbins, ps, bin_centers):\n",
    "        sbins = base_sbins + mu\n",
    "        \n",
    "        n = bin_centers.shape[0]-1\n",
    "        \n",
    "        hps = T.cast(T.ceil( (sbins-bin_centers[1])/dx) +1,'int32')\n",
    "        lps = T.cast(T.floor((sbins-bin_centers[1])/dx) +1,'int32')\n",
    "        \n",
    "        hps = T.set_subtensor(hps[(hps < 0).nonzero()],0)\n",
    "        lps = T.set_subtensor(lps[(lps < 0).nonzero()],0)\n",
    "\n",
    "        hps = T.set_subtensor(hps[(hps > n).nonzero()],n)\n",
    "        lps = T.set_subtensor(lps[(lps > n).nonzero()],n)\n",
    "\n",
    "        hps = T.set_subtensor(hps[T.and_(bin_centers[0]<sbins, sbins<bin_centers[1]).nonzero()],1)\n",
    "        lps = T.set_subtensor(lps[T.and_(bin_centers[-2]<sbins, sbins<bin_centers[-1]).nonzero()],n-1)\n",
    "\n",
    "        hps = T.set_subtensor(hps[(bin_centers[-1]<sbins).nonzero()],n)\n",
    "        lps = T.set_subtensor(lps[(bin_centers[-1]<sbins).nonzero()],n)\n",
    "\n",
    "        hps = T.set_subtensor(hps[(sbins<bin_centers[0]).nonzero()],0)\n",
    "        lps = T.set_subtensor(lps[(sbins<bin_centers[0]).nonzero()],0)\n",
    "\n",
    "        # sequences: sbins, ps, hps, lps // \n",
    "        # prior results: F //\n",
    "        # non-sequences: bin_centers, index j // \n",
    "        results,_ = theano.scan(fn=inner_loop,\n",
    "                               outputs_info = F,\n",
    "                               sequences = [sbins, ps, hps, lps],\n",
    "                               non_sequences = [bin_centers,j]\n",
    "                               )\n",
    "        F = results[-1]\n",
    "        \n",
    "        return F\n",
    "        \n",
    "    # sequences: mus[1:], array(1:binsize) // mus, indices of the outer loop\n",
    "    # prior results: zeros(size(F)) // initialize F as zeros\n",
    "    # non-sequences: base_bins, ps, bin_centers // \n",
    "    res,_ = theano.scan(fn = outer_loop,\n",
    "                      outputs_info = T.zeros_like(F),\n",
    "                      sequences = [mus[1:], T.arange(bin_centers.shape[0]-1)+1],\n",
    "                      non_sequences = [base_sbins, ps, bin_centers]\n",
    "                     )\n",
    "    F = res[-1]\n",
    "    \n",
    "    F = T.set_subtensor(F[:,0], 0)\n",
    "    F = T.set_subtensor(F[:,-1], 0)\n",
    "    F = T.set_subtensor(F[0,0], 1)\n",
    "    F = T.set_subtensor(F[-1,-1], 1)\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Fmatrix (Theano version)\n",
    "def Fmatrix(params, bin_centers):\n",
    "    global dt,dx\n",
    "    sigma2 = params[0]\n",
    "    lam = params[1]\n",
    "    c = params[2]\n",
    "    \n",
    "    sigma2_sbin = sigma2\n",
    "    \n",
    "    F = T.zeros((bin_centers.shape[0],bin_centers.shape[0]),'float32')\n",
    "    \n",
    "#     mus = T.switch(T.eq(lam,0),bin_centers*T.exp(lam*dt),T.exp(lam*dt)*(bin_centers + c/lam) - c/lam)\n",
    "    mus = T.exp(lam*dt)*(bin_centers + c/lam) - c/lam\n",
    "        \n",
    "    tmp = T.ceil(10*T.sqrt(sigma2_sbin)/dx)\n",
    "    n_sbins = T.switch(T.ge(tmp,70),tmp,70)\n",
    "    \n",
    "    swidth = 5*T.sqrt(sigma2_sbin)\n",
    "    sbins = (T.arange(n_sbins)+1)/n_sbins*swidth#np.linspace(-swidth,swidth,n_sbins*2+1)\n",
    "    sbins = T.concatenate((-sbins[::-1], T.zeros(1), sbins))\n",
    "\n",
    "    ps = T.exp(-sbins**2/(2*sigma2)) \n",
    "    ps = ps/T.sum(ps)\n",
    "            \n",
    "    base_sbins = sbins\n",
    "        \n",
    "        \n",
    "    def inner_loop(sbin, p, hp, lp, F, bin_centers,j):\n",
    "        dd = bin_centers[hp] - bin_centers[lp]\n",
    "        \n",
    "        FF = T.set_subtensor(F[hp,j], F[hp,j]+p*(sbin-bin_centers[lp])/dd)\n",
    "        FF = T.set_subtensor(FF[lp,j], FF[lp,j]+p*(bin_centers[hp]-sbin)/dd)\n",
    "        \n",
    "        F_rest = T.switch(T.eq(dd,0),\n",
    "                          T.set_subtensor(F[lp,j], F[lp,j]+p),\n",
    "                          FF)\n",
    "        \n",
    "        F = T.switch(T.le(sbin,bin_centers[0]),\n",
    "                          T.set_subtensor(F[0,j], F[0,j]+p),\n",
    "                          F)\n",
    "        F = T.switch(T.ge(sbin,bin_centers[-1]),\n",
    "                          T.set_subtensor(F[-1,j], F[-1,j]+p),\n",
    "                          F)\n",
    "        F = T.switch(T.gt(sbin,bin_centers[0]) & T.lt(sbin,bin_centers[-1]),\n",
    "                          F_rest,#T.set_subtensor(F[-1,j], -3),#F_rest,\n",
    "                          F)\n",
    "\n",
    "        \n",
    "        return F\n",
    "    \n",
    "    def outer_loop(mu,j, F, base_sbins, ps, bin_centers):\n",
    "        sbins = base_sbins + mu\n",
    "        \n",
    "        n = bin_centers.shape[0]-1\n",
    "        \n",
    "        hps = T.cast(T.ceil( (sbins-bin_centers[1])/dx) +1,'int32')\n",
    "        lps = T.cast(T.floor((sbins-bin_centers[1])/dx) +1,'int32')\n",
    "        \n",
    "        hps = T.set_subtensor(hps[(hps < 0).nonzero()],0)\n",
    "        lps = T.set_subtensor(lps[(lps < 0).nonzero()],0)\n",
    "\n",
    "        hps = T.set_subtensor(hps[(hps > n).nonzero()],n)\n",
    "        lps = T.set_subtensor(lps[(lps > n).nonzero()],n)\n",
    "\n",
    "        hps = T.set_subtensor(hps[T.and_(bin_centers[0]<sbins, sbins<bin_centers[1]).nonzero()],1)\n",
    "        lps = T.set_subtensor(lps[T.and_(bin_centers[-2]<sbins, sbins<bin_centers[-1]).nonzero()],n-1)\n",
    "\n",
    "        hps = T.set_subtensor(hps[(bin_centers[-1]<sbins).nonzero()],n)\n",
    "        lps = T.set_subtensor(lps[(bin_centers[-1]<sbins).nonzero()],n)\n",
    "\n",
    "        hps = T.set_subtensor(hps[(sbins<bin_centers[0]).nonzero()],0)\n",
    "        lps = T.set_subtensor(lps[(sbins<bin_centers[0]).nonzero()],0)\n",
    "\n",
    "        # sequences: sbins, ps, hps, lps // \n",
    "        # prior results: F //\n",
    "        # non-sequences: bin_centers, index j // \n",
    "        results,_ = theano.scan(fn=inner_loop,\n",
    "                               outputs_info = F,\n",
    "                               sequences = [sbins, ps, hps, lps],\n",
    "                               non_sequences = [bin_centers,j]\n",
    "                               )\n",
    "        F = results[-1]\n",
    "        \n",
    "        return F\n",
    "        \n",
    "    # sequences: mus[1:], array(1:binsize) // mus, indices of the outer loop\n",
    "    # prior results: zeros(size(F)) // initialize F as zeros\n",
    "    # non-sequences: base_bins, ps, bin_centers // \n",
    "    res,_ = theano.scan(fn = outer_loop,\n",
    "                      outputs_info = T.zeros_like(F),\n",
    "                      sequences = [mus[1:], T.arange(bin_centers.shape[0]-1)+1],\n",
    "                      non_sequences = [base_sbins, ps, bin_centers]\n",
    "                     )\n",
    "    F = res[-1]\n",
    "    \n",
    "    F = T.set_subtensor(F[:,0], 0)\n",
    "    F = T.set_subtensor(F[:,-1], 0)\n",
    "    F = T.set_subtensor(F[0,0], 1)\n",
    "    F = T.set_subtensor(F[-1,-1], 1)\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.41181999,  0.218907  , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.19714171,  0.1721313 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.18722765,  0.21792339, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.21792339,\n",
       "         0.18722765,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.1721313 ,\n",
       "         0.19714172,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.21890698,\n",
       "         0.41181993,  1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binN = T.cast(T.ceil(B/dx),'int32')\n",
    "bin_centers = make_bins(B, dx, binN)\n",
    "n = bin_centers.shape[0]\n",
    "F = T.zeros((n,n),'float32')\n",
    "\n",
    "Fi= Fmatrix_i([sigma2_i, 0, 0.0], bin_centers)\n",
    " \n",
    "\n",
    "test_func = theano.function(\n",
    "    inputs=[],\n",
    "    outputs=Fi\n",
    ")\n",
    "\n",
    "test_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s __str__ = 2.0\n",
      "r __str__ = 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(2.0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = T.scalar('r') \n",
    "s = T.scalar('s') \n",
    "t = T.scalar('t') \n",
    "r_ = theano.printing.Print('r')(r) \n",
    "s_ = theano.printing.Print('s')(s) \n",
    "\n",
    "\n",
    "u = T.switch(T.eq(t, 0), s_, r_) \n",
    "u.eval({t: 0, r: 1, s: 2}) \n",
    "\n",
    "#  u.eval({t: -1, r: 1, s: 2}) \n",
    "# s __str__ = 2.0 \n",
    "# r __str__ = 1.0 \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.        0.058855  0.22679   0.30516 ]\n",
      "[ 0.058855  0.22679   0.30516 ]\n"
     ]
    }
   ],
   "source": [
    "print LClickTimes1\n",
    "print LClickTimes1[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = np.random\n",
    "\n",
    "N = 10                             # training sample size\n",
    "feats = 20                              # number of input variables\n",
    "\n",
    "# generate a dataset: D = (input_values, target_class)\n",
    "D = (rng.randn(N, feats), rng.randint(size=N, low=0, high=2))\n",
    "D1 = rng.randint(size=N, low=0, high=2)\n",
    "D2 = rng.randint(size=N+10, low=0, high=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(D[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "coefficients = theano.tensor.vector(\"coefficients\")\n",
    "x = T.scalar(\"x\")\n",
    "\n",
    "max_coefficients_supported = 10000\n",
    "\n",
    "# Generate the components of the polynomial\n",
    "components, updates = theano.scan(fn=lambda coefficient, power, free_variable: coefficient * (free_variable ** power),\n",
    "                                  outputs_info=None,\n",
    "                                  sequences=[coefficients, theano.tensor.arange(max_coefficients_supported)],\n",
    "                                  non_sequences=x)\n",
    "# Sum them up\n",
    "polynomial = components.sum()\n",
    "\n",
    "# Compile a function\n",
    "calculate_polynomial = theano.function(inputs=[coefficients, x], outputs=polynomial)\n",
    "\n",
    "# Test\n",
    "test_coefficients = numpy.asarray([2, 1], dtype=numpy.float32)\n",
    "test_value = 3\n",
    "print(calculate_polynomial(test_coefficients, test_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "\n",
    "# define tensor variables\n",
    "X = T.vector(\"X\")\n",
    "W = T.matrix(\"W\")\n",
    "b_sym = T.vector(\"b_sym\")\n",
    "U = T.matrix(\"U\")\n",
    "Y = T.matrix(\"Y\")\n",
    "V = T.matrix(\"V\")\n",
    "P = T.matrix(\"P\")\n",
    "\n",
    "results, updates = theano.scan(lambda y, p, x_tm1: T.tanh(T.dot(x_tm1, W) + T.dot(y, U) + T.dot(p, V)),\n",
    "          sequences=[Y, P[::-1]], outputs_info=[X])\n",
    "compute_seq = theano.function(inputs=[X, W, Y, U, P, V], outputs=results)\n",
    "\n",
    "# test values\n",
    "x = np.zeros((2), dtype=theano.config.floatX)\n",
    "x[1] = 1\n",
    "w = np.ones((2, 2), dtype=theano.config.floatX)\n",
    "y = np.ones((5, 2), dtype=theano.config.floatX)\n",
    "y[0, :] = -3\n",
    "u = np.ones((2, 2), dtype=theano.config.floatX)\n",
    "p = np.ones((5, 2), dtype=theano.config.floatX)\n",
    "p[0, :] = 3\n",
    "v = np.ones((2, 2), dtype=theano.config.floatX)\n",
    "\n",
    "print(compute_seq(x, w, y, u, p, v))\n",
    "\n",
    "# comparison with numpy\n",
    "x_res = np.zeros((5, 2), dtype=theano.config.floatX)\n",
    "x_res[0] = np.tanh(x.dot(w) + y[0].dot(u) + p[4].dot(v))\n",
    "for i in range(1, 5):\n",
    "    x_res[i] = np.tanh(x_res[i - 1].dot(w) + y[i].dot(u) + p[4-i].dot(v))\n",
    "print(x_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "k = T.iscalar(\"k\")\n",
    "init = T.scalar('init')\n",
    "A = T.vector(\"A\")\n",
    "\n",
    "# Symbolic description of the result\n",
    "result, updates = theano.scan(fn=lambda prior_result, A: prior_result + A,\n",
    "                              outputs_info=[init],\n",
    "                              sequences=[A])\n",
    "\n",
    "# We only care about A**k, but scan has provided us with A**1 through A**k.\n",
    "# Discard the values that we don't care about. Scan is smart enough to\n",
    "# notice this and not waste memory saving them.\n",
    "final_result = result[-1]\n",
    "\n",
    "# compiled function that returns A**k\n",
    "power = theano.function(inputs=[A,init], outputs=result, updates=updates)\n",
    "\n",
    "print(power([1,2,3],0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Example (Structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "dtype=theano.config.floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import reberGrammar\n",
    "n_in  = 7 \n",
    "n_hid = 10\n",
    "n_out = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first dimension is time\n",
    "v = T.matrix(dtype=dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale_weights(values, factor=1.):\n",
    "    factor = np.cast[dtype](factor)\n",
    "    _,svs,_ = np.linalg.svd(values)\n",
    "    #svs[0] is the largest singular value                      \n",
    "    values = values / svs[0]\n",
    "    return values\n",
    "\n",
    "def sample_weights(sizeX, sizeY):\n",
    "    values = np.ndarray([sizeX, sizeY], dtype=dtype)\n",
    "    for dx in xrange(sizeX):\n",
    "        vals = np.random.uniform(low=-1., high=1.,  size=(sizeY,))\n",
    "        #vals_norm = np.sqrt((vals**2).sum())\n",
    "        #vals = vals / vals_norm\n",
    "        values[dx,:] = vals\n",
    "    _,svs,_ = np.linalg.svd(values)\n",
    "    #svs[0] is the largest singular value                      \n",
    "    values = values / svs[0]\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters of the rnn as shared variables\n",
    "def get_parameter(n_in, n_out, n_hid):\n",
    "    b_h = theano.shared(np.zeros(n_hid, dtype=dtype)) \n",
    "    h0 = theano.shared(np.zeros(n_hid, dtype=dtype))\n",
    "    W_ih = theano.shared(sample_weights(n_in, n_hid))\n",
    "    W_hh = theano.shared(sample_weights(n_hid, n_hid))\n",
    "    W_ho = theano.shared(sample_weights(n_hid, n_out))\n",
    "    b_o = theano.shared(np.zeros(n_out, dtype=dtype)) \n",
    "    return W_ih, W_hh, b_h, W_ho, b_o, h0\n",
    "\n",
    "W_ih, W_hh, b_h, W_ho, b_o, h0 = get_parameter(n_in, n_out, n_hid)   \n",
    "params = [W_ih, W_hh, b_h, W_ho, b_o, h0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we could use the fact that maximaly two outputs are on, \n",
    "# but for simplicity we assume independent outputs:\n",
    "def logistic_function(x):\n",
    "    return 1./(1 + T.exp(-x))\n",
    "\n",
    "# sequences: x_t\n",
    "# prior results: h_tm1\n",
    "# non-sequences: W_ih, W_hh, W_ho, b_h\n",
    "def one_step(x_t, h_tm1, W_ih, W_hh, b_h, W_ho, b_o):\n",
    "    h_t = T.tanh(theano.dot(x_t, W_ih) + theano.dot(h_tm1, W_hh) + b_h)\n",
    "    y_t = theano.dot(h_t, W_ho) + b_o \n",
    "    y_t = logistic_function(y_t) \n",
    "    return [h_t, y_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hidden and outputs of the entire sequence\n",
    "[h_vals, o_vals], _ = theano.scan(fn=one_step, \n",
    "                                  sequences = dict(input=v, taps=[0]), \n",
    "                                  outputs_info = [h0, None], # corresponds to return type of fn\n",
    "                                  non_sequences = [W_ih, W_hh, b_h, W_ho, b_o] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target values\n",
    "target = T.matrix(dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learning rate\n",
    "lr = np.cast[dtype](0.2)\n",
    "learning_rate = theano.shared(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = -T.mean(target * T.log(o_vals) + (1.- target) * T.log(1. - o_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_train_functions(cost, v, target):\n",
    "    gparams = []\n",
    "    for param in params:\n",
    "        gparam = T.grad(cost, param)\n",
    "        gparams.append(gparam)\n",
    "\n",
    "    updates=[]\n",
    "    for param, gparam in zip(params, gparams):\n",
    "        updates.append((param, param - gparam * learning_rate))\n",
    "    learn_rnn_fn = theano.function(inputs = [v, target],\n",
    "                                   outputs = cost,\n",
    "                                   updates = updates)\n",
    "    return learn_rnn_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn_rnn_fn = get_train_functions(cost, v, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
