{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PBupsModelmusc with Algorithmic Differentiation in Julia\n",
    "3 additional parameters were added to Bing’s accumulator model.  \n",
    "To analyze the strong bias induced by unilateral FOF inactivation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isless (generic function with 40 methods)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import packages..\n",
    "import ForwardDiff\n",
    "using ForwardDiff\n",
    "using PyPlot\n",
    "import Base.convert\n",
    "import Optim\n",
    "using Optim\n",
    "\n",
    "# === Upgrading from ForwardDiff v0.1 to v0.2\n",
    "# instead of ForwardDiff.GradientNumber and ForwardDiff.HessianNumber, \n",
    "# we will use ForwardDiff.Dual\n",
    "\n",
    "convert(::Type{Float64}, x::ForwardDiff.Dual) = Float64(x.value)\n",
    "function convert(::Array{Float64}, x::Array{ForwardDiff.Dual}) \n",
    "    y = zeros(size(x)); \n",
    "    for i in 1:prod(size(x)) \n",
    "        y[i] = convert(Float64, x[i]) \n",
    "    end\n",
    "    return y\n",
    "end\n",
    "\n",
    "immutable NumericPair{X,Y} <: Number\n",
    "  x::X\n",
    "  y::Y\n",
    "end\n",
    "Base.isless(a::NumericPair, b::NumericPair) = (a.x<b.x) || (a.x==b.x && a.y<b.y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate how well a particular set of parameter values $\\theta$ fits the behavioral data, we compute the probability of oberving the data given the model.\n",
    "\n",
    "For each trial $i$, we will compute the likelihood of seeing the data under the model assuming that trials are independent. \n",
    "\n",
    "$P(D|\\theta) = \\prod_{i}P(d_i|t_{i,R},t_{i,L},\\theta)$\n",
    "\n",
    "$t_{i,R},t_{i,L}$ : the right and left click times on trial $i$\n",
    "\n",
    "$d_i$ : the subject's decision on trial $i$\n",
    "\n",
    "The best-fit parameter values are the parameters $\\theta$ that maximize the likelihood (Maximum likelihood values)\n",
    "\n",
    "To help maximize the likelihood(or log likelihood), we will compute the derivative $\\partial P(d_i|t_{i,R},t_{i,L},\\theta) / \\partial\\theta$ for each of the parameters in the set $\\theta$.\n",
    "\n",
    "After we get these gradients of 9 model parameters, we will apply them for optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{ASCIIString,Any} with 2 entries:\n",
       "  \"rawdata\"      => Dict{ASCIIString,Any}(\"is_probe\"=>1x3836 Array{Any,2}:…\n",
       "  \"orig_rawdata\" => Dict{ASCIIString,Any}(\"is_probe\"=>1x3836 Array{Any,2}:…"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MAT\n",
    "ratdata = matread(\"chrono_fof_rawdata.mat\")\n",
    "# ratdata = matread(\"testdata.mat\")\n",
    "# ratdata = matread(\"chrono_B069_rawdata.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trialdata (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function trialdata(rawdata, trial::Int)\n",
    "    if rawdata[\"pokedR\"][trial] > 0\n",
    "        rat_choice = 1;  # \"R\"\n",
    "    else\n",
    "        rat_choice = -1; # \"L\"\n",
    "    end;\n",
    "    \n",
    "    if typeof(rawdata[\"rightbups\"][trial]) <: Array\n",
    "        rvec = vec(rawdata[\"rightbups\"][trial])::Array{Float64,1};\n",
    "    else\n",
    "        rvec = Float64[]\n",
    "    end\n",
    "    if typeof(rawdata[\"leftbups\"][trial]) <: Array\n",
    "        lvec = vec(rawdata[\"leftbups\"][trial])::Array{Float64,1};\n",
    "    else\n",
    "        lvec = Float64[]\n",
    "    end\n",
    "    \n",
    "    return rvec, lvec, \n",
    "    rawdata[\"T\"][trial]::Float64, rat_choice\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.158944 seconds (29.25 k allocations: 1.270 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0,0.012634999999999999],[0.0,0.028775000000000002,0.046955,0.07099,0.10994,0.12017,0.21356,0.21445,0.230355,0.26368,0.266795],0.2796896469572883,-1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata[\"rawdata\"], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bin_centers = make_bins(B, dx, binN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function bin_centers = make_bins(B, dx, binN)\n",
    "\n",
    "Makes a series of points that will indicate bin centers. The first and\n",
    "last points will indicate sticky bins. No \"bin edges\" are made-- the edge\n",
    "between two bins is always implicity at the halfway point between their\n",
    "corresponding centers. The center bin is always at x=0; bin spacing\n",
    "(except for last and first bins) is always dx; and the position\n",
    "of the first and last bins is chosen so that |B| lies exactly at the\n",
    "midpoint between 1st (sticky) and 2nd (first real) bins, as well as\n",
    "exactly at the midpoint between last but one (last real) and last\n",
    "(sticky) bins.\n",
    "\n",
    "Playing nice with ForwardDiff means that the *number* of bins must be predetermined.\n",
    "So this function will not actually set the number of bins; what it'll do is determine their\n",
    "locations. To accomplish this separation, the function uses as a third parameter binN,\n",
    "which should be equal to the number of bins with bin centers > 0, as follows: \n",
    "   binN = ceil(B/dx)\n",
    "and then the total number of bins will be 2*binN+1, with the center one always corresponding\n",
    "to position zero. Use non-differentiable types for B and dx for this to work.\n",
    "\"\"\"\n",
    "\n",
    "function make_bins{T}(bins::Vector{T}, B, dx::T, binN)\n",
    "    cnt = 1\n",
    "    for i=-binN:binN\n",
    "        bins[cnt] = i*dx\n",
    "        cnt = cnt+1\n",
    "    end\n",
    "    \n",
    "    if binN*dx == B\n",
    "        bins[end] = B + dx\n",
    "        bins[1] = -B - dx\n",
    "    else\n",
    "        bins[end] = 2*B - (binN-1)*dx\n",
    "        bins[1] = -2*B + (binN-1)*dx\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.214431 seconds (63.29 k allocations: 2.510 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35-element Array{Float64,1}:\n",
       " -4.2 \n",
       " -4.0 \n",
       " -3.75\n",
       " -3.5 \n",
       " -3.25\n",
       " -3.0 \n",
       " -2.75\n",
       " -2.5 \n",
       " -2.25\n",
       " -2.0 \n",
       " -1.75\n",
       " -1.5 \n",
       " -1.25\n",
       "  ⋮   \n",
       "  1.5 \n",
       "  1.75\n",
       "  2.0 \n",
       "  2.25\n",
       "  2.5 \n",
       "  2.75\n",
       "  3.0 \n",
       "  3.25\n",
       "  3.5 \n",
       "  3.75\n",
       "  4.0 \n",
       "  4.2 "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binN = ceil(4.1/0.25)\n",
    "bins = zeros(typeof(binN), Int(binN*2+1))\n",
    "@time make_bins(bins,4.1,0.25,binN)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 task.jl; anonymous; line: 447\n",
      " 1 ...4/IJulia/src/IJulia.jl; eventloop; line: 138\n",
      "  1 ...src/execute_request.jl; execute_request; line: 164\n",
      "   1 loading.jl; include_string; line: 282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35-element Array{Float64,1}:\n",
       " -4.2 \n",
       " -4.0 \n",
       " -3.75\n",
       " -3.5 \n",
       " -3.25\n",
       " -3.0 \n",
       " -2.75\n",
       " -2.5 \n",
       " -2.25\n",
       " -2.0 \n",
       " -1.75\n",
       " -1.5 \n",
       " -1.25\n",
       "  ⋮   \n",
       "  1.5 \n",
       "  1.75\n",
       "  2.0 \n",
       "  2.25\n",
       "  2.5 \n",
       "  2.75\n",
       "  3.0 \n",
       "  3.25\n",
       "  3.5 \n",
       "  3.75\n",
       "  4.0 \n",
       "  4.2 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 4.1\n",
    "dx_test = 0.25\n",
    "binN = ceil(B/dx_test)\n",
    "bins = zeros(typeof(binN), Int(binN*2+1))\n",
    "@profile make_bins(bins,B,dx_test,binN)\n",
    "Profile.print()\n",
    "Profile.clear_malloc_data() \n",
    "bin_centers = bins\n",
    "bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Global variables \n",
    "const epsilon = 10.0^(-10);\n",
    "const dx = 0.25;\n",
    "const dt = 0.02;\n",
    "const total_rate = 40;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "a : decision variable, memory accumulator\n",
    "\n",
    "$$ da =\n",
    "  \\begin{cases}\n",
    "    0       & \\quad \\text{if, } |a| \\geq B \\\\\n",
    "    \\sigma_adW + (\\delta_{t,t_R} \\cdot \\eta C(t) - \\delta_{t,t_L} \\cdot \\eta C(t))dt + \\lambda adt  & \\quad \\text{otherwise, }\\\\\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "The impact of each click (C) is affected by sensory adaptation that depends on clicks from both right and left sides:\n",
    "\n",
    "$$ \n",
    "\\frac{\\mathrm d C}{\\mathrm d t} = \\frac{1-C}{\\tau_\\phi} + (1-\\phi)C(\\delta_{t,t_R}+\\delta_{t,t_L}) \n",
    "$$\n",
    "\n",
    "\n",
    "sigma2_a ($\\sigma_a^2$) : a diffusion constant, parameterizing noise in a.\n",
    "\n",
    "sigma2_s_R ($\\sigma_{s,R}^2$) : parameterizing noise when adding evidence from a right pulse. (incoming sensory evidence)\n",
    "\n",
    "sigma2_s_L ($\\sigma_{s,L}^2$) : parameterizing noise when adding evidence from a left pulse. (incoming sensory evidence)\n",
    "\n",
    "sigma2_i ($\\sigma_i^2$) : initial condition for the dynamical equation at $t=0$\n",
    "\n",
    "lam ($\\lambda$) : consistent drift in the memory a ($\\lambda<0$ : leaky or forgetful case, $\\lambda>0$ : unstable or impulsive case)\n",
    "\n",
    "B : decision bound\n",
    "\n",
    "bias : bias parameter determines the position of the threshold in a (which a Rightward decision is made) accumulation shift\n",
    "\n",
    "phi ($\\phi$) : parameterize sensory adaptation (by defining the dynamics of C ($\\phi>1$ : Facilitation, $\\phi<1$ : Depression, $\\phi=1$ : absense of sensory adaptation)\n",
    "\n",
    "tau_phi ($\\tau_\\phi$) : recovery time constant for C. C recovers toward an unadapted value of 1 with time constant $\\tau_\\phi$\n",
    "\n",
    "lapse_R($\\kappa_R$) : The lapse rate parameterizes the probability of making a random response as right choice. (L->R)\n",
    "\n",
    "lapse_L($\\kappa_L$) : The lapse rate parameterizes the probability of making a random response as left choice. (R->L)\n",
    "\n",
    "biased_input : unbalanced input gain (sensory neglect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05*2;\n",
    "biased_sigma2_s = 0.1; biased_input = 0.1; biased_lapse = 0.1;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse, biased_sigma2_s, biased_input, biased_lapse]   \n",
    "\n",
    "sigma = params[1];\n",
    "lam   = params[2];\n",
    "c     = params[3];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F = Fmatrix([sigma, lambda, c], bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fmatrix (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "function F = Fmatrix([sigma, lambda, c], bin_centers)\n",
    "\n",
    "Uses globals\n",
    "    dt\n",
    "    dx\n",
    "    epsilon       (=10.0^-10)\n",
    "\n",
    "Returns a square Markov matrix of transition probabilities. \n",
    "Plays nice with ForwardDiff-- that is why bin_centers is a global vector (so that the rem\n",
    "operations that go into defining the bins, which ForwardDiff doesn't know how to deal with,\n",
    "stay outside of this differentiable function)\n",
    "\n",
    "sigma  should be in (accumulator units) per (second^(1/2))\n",
    "lambda should be in s^-1\n",
    "c      should be in accumulator units per second\n",
    "bin_centers should be a vector of the centers of all the bins. Edges will be at midpoints\n",
    "       between the centers, and the first and last bin will be sticky.\n",
    "\n",
    "dx is not used inside Fmatrix, because bin_centers specifies all we need to know.\n",
    "dt *is* used inside Fmatrix, to convert sigma, lambda, and c into timestep units\n",
    "\"\"\"\n",
    "function Fmatrix{T}(F::AbstractArray{T,2},params::Vector, bin_centers)\n",
    "    sigma2 = params[1];\n",
    "    lam   = params[2];\n",
    "    c     = params[3];\n",
    "\n",
    "    sigma2_sbin = convert(Float64, sigma2)\n",
    "\n",
    "    n_sbins = max(70, ceil(10*sqrt(sigma2_sbin)/dx))\n",
    "\n",
    "    F[1,1] = 1;\n",
    "    F[end,end] = 1;\n",
    "\n",
    "    swidth = 5*sqrt(sigma2_sbin)\n",
    "    sbinsize = swidth/n_sbins;#sbins[2] - sbins[1]\n",
    "    base_sbins    = collect(-swidth:sbinsize:swidth)\n",
    "\n",
    "    ps       = exp(-base_sbins.^2/(2*sigma2))\n",
    "    ps       = ps/sum(ps);\n",
    "\n",
    "    sbin_length = length(base_sbins)\n",
    "    binN = length(bin_centers)\n",
    "\n",
    "    mu = 0.\n",
    "    for j in 2:binN-1\n",
    "        if abs(lam) < epsilon \n",
    "            mu = bin_centers[j] + c*dt#(exp(lam*dt))\n",
    "        else\n",
    "            mu = (bin_centers[j] + c/lam)*exp(lam*dt) - c/lam\n",
    "        end\n",
    "\n",
    "        for k in 1:sbin_length\n",
    "            sbin = mu + base_sbins[k]#(k-1)*sbinsize + mu - swidth\n",
    "\n",
    "            if sbin <= bin_centers[1] #(bin_centers[1] + bin_centers[2])/2\n",
    "                F[1,j] = F[1,j] + ps[k]\n",
    "            elseif bin_centers[end] <= sbin#(bin_centers[end]+bin_centers[end-1])/2 <= sbins[k]\n",
    "                F[end,j] = F[end,j] + ps[k]\n",
    "            else # more condition\n",
    "                if (sbin > bin_centers[1] && sbin < bin_centers[2])\n",
    "                    lp = 1; hp = 2;\n",
    "                elseif (sbin > bin_centers[end-1] && sbin < bin_centers[end])\n",
    "                    lp = binN-1; hp = binN;\n",
    "                else\n",
    "                    lp = floor(Int,((sbin-bin_centers[2])/dx)) + 2#find(bin_centers .<= sbins[k])[end]\n",
    "                    hp = ceil(Int,((sbin-bin_centers[2])/dx)) + 2#lp+1#Int(ceil((sbins[k]-bin_centers[2])/dx) + 1);\n",
    "                end\n",
    "\n",
    "                # if lp < 1\n",
    "                #     lp = 1;\n",
    "                # end\n",
    "                # if hp > binN-1\n",
    "                #     hp = binN-1;\n",
    "                # end\n",
    "\n",
    "                if lp == hp\n",
    "                    F[lp,j] = F[lp,j] + ps[k]\n",
    "                else\n",
    "                    F[hp,j] = F[hp,j] + ps[k]*(sbin - bin_centers[lp])/(bin_centers[hp] - bin_centers[lp])\n",
    "                    F[lp,j] = F[lp,j] + ps[k]*(bin_centers[hp] - sbin)/(bin_centers[hp] - bin_centers[lp])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    # F[:,1] = 0; F[:,end] = 0; F[1,1] = 1; F[end,end] = 1;\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.312143 seconds (95.74 k allocations: 4.238 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35x35 Array{Float64,2}:\n",
       " 1.0  0.41182      0.218907     0.0917964    …  0.0          0.0          0.0\n",
       " 0.0  0.197142     0.172131     0.112014        0.0          0.0          0.0\n",
       " 0.0  0.187228     0.217923     0.187228        0.0          0.0          0.0\n",
       " 0.0  0.119939     0.187228     0.217923        0.0          0.0          0.0\n",
       " 0.0  0.0571377    0.119939     0.187228        0.0          0.0          0.0\n",
       " 0.0  0.0202246    0.0571377    0.119939     …  0.0          0.0          0.0\n",
       " 0.0  0.00531176   0.0202246    0.0571377       0.0          0.0          0.0\n",
       " 0.0  0.00103206   0.00531176   0.0202246       0.0          0.0          0.0\n",
       " 0.0  0.000148294  0.00103206   0.00531176      0.0          0.0          0.0\n",
       " 0.0  1.59548e-5   0.000148294  0.00103206      0.0          0.0          0.0\n",
       " 0.0  1.11105e-6   1.59548e-5   0.000148294  …  0.0          0.0          0.0\n",
       " 0.0  0.0          1.11105e-6   1.59548e-5      0.0          0.0          0.0\n",
       " 0.0  0.0          0.0          1.11105e-6      0.0          0.0          0.0\n",
       " ⋮                                           ⋱                               \n",
       " 0.0  0.0          0.0          0.0             1.11105e-6   0.0          0.0\n",
       " 0.0  0.0          0.0          0.0             1.59548e-5   1.11105e-6   0.0\n",
       " 0.0  0.0          0.0          0.0          …  0.000148294  1.59548e-5   0.0\n",
       " 0.0  0.0          0.0          0.0             0.00103206   0.000148294  0.0\n",
       " 0.0  0.0          0.0          0.0             0.00531176   0.00103206   0.0\n",
       " 0.0  0.0          0.0          0.0             0.0202246    0.00531176   0.0\n",
       " 0.0  0.0          0.0          0.0             0.0571377    0.0202246    0.0\n",
       " 0.0  0.0          0.0          0.0          …  0.119939     0.0571377    0.0\n",
       " 0.0  0.0          0.0          0.0             0.187228     0.119939     0.0\n",
       " 0.0  0.0          0.0          0.0             0.217923     0.187228     0.0\n",
       " 0.0  0.0          0.0          0.0             0.172131     0.197142     0.0\n",
       " 0.0  0.0          0.0          0.0             0.218907     0.41182      1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = zeros(typeof(0.2),length(bin_centers),length(bin_centers))\n",
    "@time Fmatrix(F,[0.2, 0., 0.0],bin_centers) # Fi\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000155 seconds (11 allocations: 7.516 KB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35x35 Array{Float64,2}:\n",
       " 1.0  0.461125    0.365007    0.274946    …  0.0         0.0         0.0\n",
       " 0.0  0.0908452   0.0859592   0.0811359      0.0         0.0         0.0\n",
       " 0.0  0.0945948   0.100835    0.0946575      0.0         0.0         0.0\n",
       " 0.0  0.0888839   0.0945533   0.100892       0.0         0.0         0.0\n",
       " 0.0  0.0737024   0.0889555   0.0945117      0.0         0.0         0.0\n",
       " 0.0  0.0612142   0.0736883   0.0890271   …  0.0         0.0         0.0\n",
       " 0.0  0.044833    0.0612781   0.0736743      0.0         0.0         0.0\n",
       " 0.0  0.0329193   0.0448354   0.0613421      0.0         0.0         0.0\n",
       " 0.0  0.0212918   0.0329616   0.0448377      0.0         0.0         0.0\n",
       " 0.0  0.0138235   0.021298    0.0330038      0.0         0.0         0.0\n",
       " 0.0  0.0078944   0.0138445   0.0213041   …  0.0         0.0         0.0\n",
       " 0.0  0.00453257  0.0078985   0.0138655      0.0         0.0         0.0\n",
       " 0.0  0.00228512  0.00454054  0.00790261     3.13941e-7  0.0         0.0\n",
       " ⋮                                        ⋱                             \n",
       " 0.0  0.0         0.0         3.40328e-7     0.00783279  0.00440511  0.0\n",
       " 0.0  0.0         0.0         0.0            0.0135081   0.00782868  0.0\n",
       " 0.0  0.0         0.0         0.0         …  0.0211994   0.0134871   0.0\n",
       " 0.0  0.0         0.0         0.0            0.0322857   0.0211932   0.0\n",
       " 0.0  0.0         0.0         0.0            0.0447976   0.0322435   0.0\n",
       " 0.0  0.0         0.0         0.0            0.0602548   0.0447953   0.0\n",
       " 0.0  0.0         0.0         0.0            0.0739127   0.0601908   0.0\n",
       " 0.0  0.0         0.0         0.0         …  0.0878095   0.0739267   0.0\n",
       " 0.0  0.0         0.0         0.0            0.0952181   0.0877379   0.0\n",
       " 0.0  0.0         0.0         0.0            0.0999224   0.0952597   0.0\n",
       " 0.0  0.0         0.0         0.0            0.0863713   0.0901428   0.0\n",
       " 0.0  0.0         0.0         0.0            0.368213    0.464534    1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = zeros(typeof(params[1]),length(bin_centers),length(bin_centers))\n",
    "@time Fmatrix(F,params,bin_centers)\n",
    "F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logProbRight \n",
    "### (params::Vector, RightClickTimes::Vector, LeftClickTimes::Vector, Nsteps::Int)\n",
    "\n",
    "* params = [sigma_a, sigma_s, sigma_i, lambda, B, bias, phi, tau_phi, lapse]\n",
    "* RightClickTimes vector with elements indicating times of right clicks\n",
    "* LeftClickTimes vector with elements indicating times of left clicks\n",
    "* Nsteps number of timesteps to simulate \n",
    "\n",
    "a (column vector representing distribution of values of accumulator a)\n",
    "\n",
    "a_trace (length(bin_centers)-by-Nsteps+1), a trace of the distribution of a as \n",
    "    a function of time\n",
    "    \n",
    "c_trace (row vector Nsteps+1 long, effective value of c as \n",
    "    a function of time after adaptation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logLike (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "version with inter-click interval(ici) for c_eff_net / c_eff_tot (followed the matlab code) \n",
    "(which was using dt for c_eff)\n",
    "\n",
    "function logProbRight(params::Vector, RightClickTimes::Vector, LeftClickTimes::Vector, Nsteps::Int)\n",
    "\n",
    "    Nsteps            number of timesteps to simulate\n",
    "    RightClickTimes   vector with elements indicating times of right clicks\n",
    "    LeftClickTimes    vector with elements indicating times of left clicks\n",
    "\n",
    "    a      (column vector representing distribution of values of accumulator a)\n",
    "\n",
    "    a_trace (length(bin_centers)-by-Nsteps+1), a trace of the distribution of a as \n",
    "            a function of time\n",
    "    c_trace (row vector Nsteps+1 long, effective value of c as \n",
    "            a function of time after adaptation)\n",
    "\n",
    "Takes params (including biased params)\n",
    "    sigma_a = params[1]; sigma_s_R = params[2]; sigma_s_L = params[3];\n",
    "    sigma_i = params[4]; lambda = params[5]; B = params[6]; bias = params[7]; \n",
    "    phi = params[8]; tau_phi = params[9]; lapse_R = params[10]; lapse_L = params[11];\n",
    "    input_gain_weight = params[12];\n",
    "\n",
    "Returns the log of the probability that the agent chose Right. \n",
    "\"\"\"\n",
    "\n",
    "function logProbRight(params::Vector, RightClickTimes::Array{Float64,1}, LeftClickTimes::Array{Float64,1}, Nsteps::Int)\n",
    "#     sigma_a = params[1]; sigma_s = params[2]; sigma_i = params[3];\n",
    "#     lambda = params[4]; B = params[5]; bias = params[6];\n",
    "#     phi = params[7]; tau_phi = params[8]; lapse = params[9]\n",
    "#     biased_sigma2_s = params[10]; biased_input = params[11]; biased_lapse = params[12];\n",
    "    sigma_a = params[1]; sigma_s_R = params[2]; sigma_s_L = params[3];\n",
    "    sigma_i = params[4]; lambda = params[5]; B = params[6]; bias = params[7];\n",
    "    phi = params[8]; tau_phi = params[9]; lapse_R = params[10]; lapse_L = params[11];\n",
    "    input_gain_weight = params[12];\n",
    "\n",
    "    if isempty(RightClickTimes) RightClickTimes = zeros(0) end;\n",
    "    if isempty(LeftClickTimes ) LeftClickTimes  = zeros(0) end;\n",
    "\n",
    "    NClicks = zeros(Int, Nsteps);\n",
    "    Lhere  = zeros(Int, length(LeftClickTimes));\n",
    "    Rhere = zeros(Int, length(RightClickTimes));\n",
    "\n",
    "    for i in 1:length(LeftClickTimes)\n",
    "        Lhere[i] = ceil((LeftClickTimes[i]+epsilon)/dt)\n",
    "    end\n",
    "    for i in 1:length(RightClickTimes)\n",
    "        Rhere[i] = ceil((RightClickTimes[i]+epsilon)/dt)\n",
    "    end\n",
    "\n",
    "    for i in Lhere\n",
    "        NClicks[Int(i)] = NClicks[Int(i)]  + 1\n",
    "    end\n",
    "    for i in Rhere\n",
    "        NClicks[Int(i)] = NClicks[Int(i)]  + 1\n",
    "    end\n",
    "\n",
    "    # === Upgrading from ForwardDiff v0.1 to v0.2\n",
    "    # instead of using convert we can use floor(Int, ForwardDiff.Dual) and\n",
    "    # ceil(Int, ForwardDiff.Dual)\n",
    "\n",
    "    binN = ceil(Int, B/dx)#Int(ceil(my_B/dx))\n",
    "    binBias = floor(Int, bias/dx) + binN+1\n",
    "    binBias_hp = ceil(Int, bias/dx) + binN+1\n",
    "\n",
    "    if binBias<1 binBias = 1; end\n",
    "    if binBias>binN*2+1 binBias = binN*2+1; end\n",
    "\n",
    "    if binBias_hp<1 binBias_hp = 1; end\n",
    "    if binBias_hp>binN*2+1 binBias_hp = binN*2+1; end\n",
    "\n",
    "    bin_centers = zeros(typeof(dx), binN*2+1)\n",
    "    make_bins(bin_centers, B, dx, binN)\n",
    "\n",
    "    # Visualization\n",
    "    a_trace = zeros(length(bin_centers), Nsteps)\n",
    "    c_trace = zeros(1, Nsteps)\n",
    "\n",
    "    ## biased lapse rate (lapse_R, lapse_L)\n",
    "    a0 = zeros(typeof(sigma_a),length(bin_centers))\n",
    "    a0[1] = lapse_L/2;\n",
    "    a0[end] = lapse_R/2;\n",
    "    a0[binN+1] = 1-lapse_L/2-lapse_R/2;\n",
    "\n",
    "    temp_l = [NumericPair(LeftClickTimes[i],-1) for i=1:length(LeftClickTimes)]\n",
    "    temp_r = [NumericPair(RightClickTimes[i],1) for i=1:length(RightClickTimes)]\n",
    "    allbups = sort!([temp_l; temp_r])\n",
    "\n",
    "    if phi == 1\n",
    "      c_eff = 1.\n",
    "    else\n",
    "      c_eff = 0.\n",
    "    end\n",
    "    cnt = 0\n",
    "\n",
    "    Fi = zeros(typeof(sigma_i),length(bin_centers),length(bin_centers))\n",
    "    Fmatrix(Fi,[sigma_i, 0., 0.0], bin_centers)\n",
    "    a = Fi*a0;\n",
    "\n",
    "    a_trace[:,1] = a;\n",
    "\n",
    "    F0 = zeros(typeof(sigma_a),length(bin_centers),length(bin_centers))\n",
    "    Fmatrix(F0,[sigma_a*dt, lambda, 0.0], bin_centers)\n",
    "    for i in 2:Nsteps\n",
    "        net_input = 0.\n",
    "        c_eff_tot = 0.\n",
    "        c_eff_net = 0.\n",
    "        net_i_input = 0.\n",
    "        net_c_input = 0.\n",
    "\n",
    "        if NClicks[i-1]==0\n",
    "            c_eff_tot = 0.\n",
    "            c_eff_net = 0.\n",
    "            a = F0*a\n",
    "        else\n",
    "            for j in 1:NClicks[i-1]\n",
    "                if cnt != 0 || j != 1\n",
    "                    ici = allbups[cnt+j].x - allbups[cnt+j-1].x\n",
    "\n",
    "                    c_eff = 1 + (c_eff*phi - 1)*exp(-ici/tau_phi)\n",
    "                    c_eff_tot = c_eff_tot + c_eff\n",
    "                    c_eff_net = c_eff_net + c_eff*allbups[cnt+j].y\n",
    "\n",
    "                    ## (input_gain_weight) 0 to 1 : 0-left, 1-right\n",
    "                    net_c_input = (c_eff_tot+c_eff_net)/2 # right\n",
    "                    net_i_input = c_eff_tot-net_c_input # left\n",
    "\n",
    "                    # net_input = 2*input_gain_weight*net_c_input - 2*(1-input_gain_weight)*net_i_input\n",
    "                    net_input = input_gain_weight*net_c_input - net_i_input\n",
    "                elseif cnt==0 && j==1\n",
    "                    ici = 0.\n",
    "                    c_eff = 1 + (c_eff*phi - 1)*exp(-ici/tau_phi)\n",
    "\n",
    "                    c_eff_tot = c_eff_tot + c_eff\n",
    "                    c_eff_net = c_eff_net + c_eff*allbups[cnt+j].y\n",
    "\n",
    "                    ## (input_gain_weight) 0 to 1 : 0-left, 1-right\n",
    "                    net_c_input = (c_eff_tot+c_eff_net)/2 # right\n",
    "                    net_i_input = c_eff_tot-net_c_input # left\n",
    "\n",
    "                    # net_input = 2*input_gain_weight*net_c_input - 2*(1-input_gain_weight)*net_i_input\n",
    "                    net_input = input_gain_weight*net_c_input - net_i_input\n",
    "                end\n",
    "                if j == NClicks[i-1]\n",
    "                    cnt = cnt+j\n",
    "                end\n",
    "            end\n",
    "\n",
    "            ## biased params added\n",
    "            net_sigma = sigma_a*dt + (sigma_s_R*net_i_input)/total_rate + (sigma_s_L*net_c_input)/total_rate\n",
    "            F = zeros(typeof(net_sigma),length(bin_centers),length(bin_centers))\n",
    "            Fmatrix(F,[net_sigma, lambda, net_input/dt], bin_centers)\n",
    "            a = F*a\n",
    "            # println(\"step \",i, \" : \", net_sigma,\" , \",c_eff_net,\" , \",c_eff_tot,\" , \",net_c_input,\" , \",net_i_input,\" , \",net_input)\n",
    "            # println(\"step \",i, \" : net_sigma = \", net_sigma,\" = \",sigma_a*dt,\" + \",sigma_s_L,\"*\",net_i_input,\"/\",total_rate,\" + \",(sigma_s_R*net_c_input)/total_rate)\n",
    "\n",
    "        end\n",
    "        # println(\"step \",i,\" : \",a)\n",
    "\n",
    "        a_trace[:,i] = a\n",
    "        c_trace[i] = c_eff*exp(lambda*dt)\n",
    "    end\n",
    "\n",
    "\n",
    "    # likelihood of poking right\n",
    "    if binBias == binBias_hp\n",
    "      pright = sum(a[binBias+1:end])+a[binBias]/2\n",
    "    else\n",
    "      pright = sum(a[binBias+2:end]) +\n",
    "      a[binBias]*((bin_centers[binBias+1] - bias)/dx/2) +\n",
    "      a[binBias+1]*(0.5 + (bin_centers[binBias+1] - bias)/dx/2)\n",
    "    end\n",
    "    if pright-1 < epsilon && pright > 1\n",
    "        pright = 1\n",
    "    end\n",
    "    if pright < epsilon && pright > 0\n",
    "        pright = 0\n",
    "    end\n",
    "\n",
    "    a_trace[binBias,:]=a_trace[binBias,:]*((bin_centers[binBias+1] - bias)/dx/2)\n",
    "    a_trace[binBias+1,:]=a_trace[binBias,:]*(0.5 + (bin_centers[binBias+1] - bias)/dx/2)\n",
    "\n",
    "#     # visualize\n",
    "#     subplot(211)\n",
    "#     plt = plot((0:(Nsteps-1))*dt,c_trace[:])\n",
    "# #     print(maximum(a_trace,1))\n",
    "# #     plt = plot((0:(Nsteps-1))*dt,maximum(a_trace,1)[:])\n",
    "\n",
    "#     subplot(212)\n",
    "\n",
    "#     imshow(a_trace, interpolation=\"none\", cmap=ColorMap(\"hot\"),\n",
    "#     extent=[0,(Nsteps-1)*dt,bin_centers[1],bin_centers[end]], aspect=\"auto\")\n",
    "#     xticks((0:(Nsteps-1))*dt)\n",
    "#     yticks(bin_centers)\n",
    "\n",
    "\n",
    "    return log(pright)\n",
    "end\n",
    "\n",
    "function logLike(params::Vector, RightClickTimes::Array{Float64,1}, LeftClickTimes::Array{Float64,1}, Nsteps::Int, rat_choice::Int)\n",
    "    # likelihood of poking the same way the data did\n",
    "    if rat_choice > 0\n",
    "        # println(\"Right\")\n",
    "        return logProbRight(params, RightClickTimes, LeftClickTimes, Nsteps)\n",
    "    elseif rat_choice < 0\n",
    "        # println(\"Left\")\n",
    "        return log(1 - exp(logProbRight(params, RightClickTimes, LeftClickTimes, Nsteps)))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single_trial\n",
    "### (params::Vector, RightClickTimes::Vector, LeftClickTimes::Vector, Nsteps::Int, rat_choice::Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "single_trial (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "function (LL, LLgrad) = \n",
    "    single_trial(params::Vector, RightClickTimes::Vector, LeftClickTimes::Vector, Nsteps::Int, rat_choice::Int)\n",
    "\n",
    "Computes the log likelihood according to Bing's model, and returns log likelihood, gradient\n",
    "\n",
    "params is a vector whose elements, in order, are\n",
    "    sigma_a    square root of accumulator variance per unit time sqrt(click units^2 per second)\n",
    "    sigma_s    standard deviation introduced with each click (will get scaled by click adaptation)\n",
    "    sigma_i    square root of initial accumulator variance sqrt(click units^2)\n",
    "    lambda     1/accumulator time constant (sec^-1). Positive means unstable, neg means stable\n",
    "    B          sticky bound height (click units)\n",
    "    bias       where the decision boundary lies (click units)\n",
    "    phi        click adaptation/facilitation multiplication parameter\n",
    "    tau_phi    time constant for recovery from click adaptation (sec)\n",
    "    lapse      2*lapse fraction of trials are decided randomly\n",
    "\n",
    "rat_choice     should be either \"R\" or \"L\"\n",
    "\n",
    "\n",
    "RETURNS:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# === Upgrading from ForwardDiff v0.1 to v0.2\n",
    "# for Retrieving Lower-Order Results\n",
    "#     # old way\n",
    "#     answer, results = ForwardDiff.hessian(f, x, AllResults)\n",
    "#     v = ForwardDiff.value(results)\n",
    "#     g = ForwardDiff.gradient(results)\n",
    "#     h = ForwardDiff.hessian(results) # == answer\n",
    "\n",
    "#     # new way\n",
    "#     out = HessianResult(x)\n",
    "#     ForwardDiff.hessian!(out, f, x)\n",
    "#     v = ForwardDiff.value(out)\n",
    "#     g = ForwardDiff.gradient(out)\n",
    "#     h = ForwardDiff.hessian(out)\n",
    "\n",
    "function single_trial(params::Vector, RightClickTimes::Array{Float64,1}, LeftClickTimes::Array{Float64,1}, Nsteps::Int, rat_choice::Int)\n",
    "    function llikey(params::Vector)\n",
    "        logLike(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "    end\n",
    "\n",
    "    result =  GradientResult(params)\n",
    "    \n",
    "    ForwardDiff.gradient!(result, llikey, params);\n",
    "    \n",
    "    LL     = ForwardDiff.value(result)\n",
    "    LLgrad = ForwardDiff.gradient(result)\n",
    "   \n",
    "    return LL, LLgrad\n",
    "end\n",
    "\n",
    "# function single_trial(params::Vector, RightClickTimes::Vector, LeftClickTimes::Vector, Nsteps::Int, rat_choice::Int)\n",
    "#     function llikey(params::Vector)\n",
    "#         logLike(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "#     end\n",
    "\n",
    "#     result =  HessianResult(params) \n",
    "#     ForwardDiff.hessian!(result, llikey, params);\n",
    "    \n",
    "#     LL     = ForwardDiff.value(result)\n",
    "#     LLgrad = ForwardDiff.gradient(result)\n",
    "#     LLhessian = ForwardDiff.hessian(result)\n",
    "   \n",
    "#     return LL, LLgrad, LLhessian\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.641335 seconds (185.88 k allocations: 9.873 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.052233844862698206"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### =============== testing 1 ================= ####\n",
    "\n",
    "# Parameters\n",
    "sigma_a = 1; sigma_s_R = 0.1; sigma_s_L = 0.1; sigma_i = 0.2; \n",
    "lam = -0.5; B = 10.; bias = .2; \n",
    "phi = 0.3; tau_phi = 0.1; lapse_R = 0.05*2; lapse_L = 0.1;\n",
    "input_gain_weight = 0.5; \n",
    "\n",
    "params = [sigma_a, sigma_s_R, sigma_s_L, sigma_i, lam, B, bias, phi, tau_phi, lapse_R, lapse_L, input_gain_weight]   \n",
    "\n",
    "\n",
    "RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata[\"rawdata\"], 1)\n",
    "Nsteps = Int(cld(maxT,dt))\n",
    "\n",
    "@time logLike(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "### =========================================== #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.582793 seconds (389.05 k allocations: 24.654 MB, 17.74% gc time)\n",
      "-0.052233844862698206\n",
      "[-0.002097286726694895,-0.00046040041743545217,-2.111552427493129e-5,-0.006998724210286463,-0.0005052759591115179,-0.0,0.005616932141251665,0.009095339919944863,-0.06443041056820667,-0.5262882750604839,0.0005227738508069007,-0.0004523516957455874]\n"
     ]
    }
   ],
   "source": [
    "### =============== testing 2 ================= ####\n",
    "@time LL, LLgrad = single_trial(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "println(LL)\n",
    "println(LLgrad)\n",
    "### =========================================== ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Array{Float64,1}:\n",
       " -0.000428993\n",
       " -6.93329e-5 \n",
       " -5.95655e-5 \n",
       " -0.00126152 \n",
       " -9.08727e-5 \n",
       " -0.0        \n",
       "  0.000785662\n",
       "  0.00303933 \n",
       " -0.0137955  \n",
       " -0.526312   \n",
       "  7.56502e-5 \n",
       " -0.00495832 "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.05142945554068131\n",
    "[-0.00042899336292765306,-6.933289173521957e-5,-5.956546833135365e-5,-0.0012615164543306363,-9.08726954078407e-5,-0.0,0.0007856615969410698,0.0030393293166007807,-0.013795529098181146,-0.5263118078823543,7.565023526742202e-5,-0.004958318007655772]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.052233844862698206"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Array{Float64,1}:\n",
       " -0.00209729 \n",
       " -0.0004604  \n",
       " -2.11155e-5 \n",
       " -0.00699872 \n",
       " -0.000505276\n",
       " -0.0        \n",
       "  0.00561693 \n",
       "  0.00909534 \n",
       " -0.0644304  \n",
       " -0.526288   \n",
       "  0.000522774\n",
       " -0.000452352"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Maximize LL over parameter space\n",
    "### Optimization with Optim.jl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function ComputeLL(params::Vector, ratdata, ntrials::Int)\n",
    "    LL        = 0.\n",
    "        \n",
    "    for i in 1:ntrials\n",
    "        RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata, i)\n",
    "        Nsteps = Int(ceil(maxT/dt))\n",
    "\n",
    "        LLi = logLike(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "        LL        = LL + LLi;\n",
    "    end\n",
    "    \n",
    "    LL = -LL\n",
    "    return LL\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function ComputeGrad(params::Vector, ratdata, ntrials::Int)\n",
    "    function WrapperLL(params::Vector)\n",
    "        LL        = 0.\n",
    "\n",
    "        for i in 1:ntrials\n",
    "            RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata, i)\n",
    "            Nsteps = Int(ceil(maxT/dt))\n",
    "\n",
    "            LLi = logLike(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "            LL        = LL + LLi;\n",
    "        end\n",
    "\n",
    "        LL = -LL\n",
    "        return LL\n",
    "    end\n",
    "\n",
    "    result =  GradientResult(params)\n",
    "    \n",
    "    ForwardDiff.gradient!(result, WrapperLL, params);\n",
    "    \n",
    "    LL     = ForwardDiff.value(result)\n",
    "    LLgrad = ForwardDiff.gradient(result)\n",
    "   \n",
    "    return LL, LLgrad\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@profile ComputeLL(params,ratdata[\"rawdata\"],300)\n",
    "Profile.print()\n",
    "Profile.clear_malloc_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ComputeLL(params,ratdata[\"rawdata\"],300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time ComputeGrad(params,ratdata[\"rawdata\"],300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function ComputeHess(params::Vector, ratdata, ntrials::Int)\n",
    "    function WrapperLL(params::Vector)\n",
    "        LL        = 0.\n",
    "\n",
    "        for i in 1:ntrials\n",
    "            RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata[\"rawdata\"], i)\n",
    "            Nsteps = Int(ceil(maxT/dt))\n",
    "\n",
    "            LLi = logLike(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "            LL        = LL + LLi;\n",
    "        end\n",
    "\n",
    "        LL = -LL\n",
    "        return LL\n",
    "    end\n",
    "\n",
    "    result =  HessianResult(params)\n",
    "    \n",
    "    ForwardDiff.hessian!(result, WrapperLL, params);\n",
    "    \n",
    "    LL     = ForwardDiff.value(result)\n",
    "    LLgrad = ForwardDiff.gradient(result)\n",
    "    LLHess = ForwardDiff.hessian(result)\n",
    "   \n",
    "    return LL, LLgrad, LLHess\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time ComputeHess(params,ratdata,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function Likely_all_trials{T}(LL::AbstractArray{T,1},params::Vector, ratdata, ntrials::Int)     \n",
    "    for i in 1:ntrials\n",
    "        RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata, i)\n",
    "        Nsteps = Int(ceil(maxT/dt))\n",
    "\n",
    "        LL[i] = logLike(params, RightClickTimes, LeftClickTimes, Nsteps, rat_choice)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntrials = 27;\n",
    "likely_all = zeros(ntrials)\n",
    "@time Likely_all_trials(likely_all, params, ratdata[\"rawdata\"], ntrials)\n",
    "likely_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sigma_a = 1; sigma_s_R = 0.1; sigma_s_L = 0.1; sigma_i = 0.2; \n",
    "lam = -0.0005; B = 10.; bias = .2; \n",
    "phi = 0.3; tau_phi = 0.1; lapse_R = 0.05*2; lapse_L = 0.1;\n",
    "input_gain_weight = 0.1; \n",
    "\n",
    "params = [sigma_a, sigma_s_R, sigma_s_L, sigma_i, lam, B, bias, phi, tau_phi, lapse_R, lapse_L, input_gain_weight]   \n",
    "\n",
    "\n",
    "ntrials = 10#3836\n",
    "\n",
    "function LL_f(params::Vector)\n",
    "    return ComputeLL(params, ratdata[\"rawdata\"], ntrials)\n",
    "end\n",
    "\n",
    "function LL_g!(params::Vector, grads::Vector)\n",
    "#     LL, LLgrad, LLhess = llikey(params)\n",
    "    LL, LLgrad = ComputeGrad(params, ratdata[\"rawdata\"], ntrials)\n",
    "    for i=1:length(params)\n",
    "        grads[i] = LLgrad[i]\n",
    "    end\n",
    "end\n",
    "\n",
    "function LL_fg!(params::Vector, grads)\n",
    "    LL, LLgrad = ComputeGrad(params, ratdata[\"rawdata\"], ntrials)\n",
    "    for i=1:length(params)\n",
    "        grads[i] = LLgrad[i]\n",
    "    end\n",
    "    return LL\n",
    "end\n",
    "\n",
    "d4 = DifferentiableFunction(LL_f,\n",
    "                            LL_g!,\n",
    "                            LL_fg!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sigma_a = 1; sigma_s_R = 0.1; sigma_s_L = 0.1; sigma_i = 0.2; \n",
    "lam = -0.0005; B = 10.; bias = .2; \n",
    "phi = 0.3; tau_phi = 0.1; lapse_R = 0.05*2; lapse_L = 0.1;\n",
    "input_gain_weight = 0.1; \n",
    "\n",
    "params = [sigma_a, sigma_s_R, sigma_s_L, sigma_i, lam, B, bias, phi, tau_phi, lapse_R, lapse_L, input_gain_weight]   \n",
    "params = [2.63352, 0.287501, 0.201707, 0.501707, -0.21113, 6.23087, 1.487071, 0.537924, 0.69, 0.140861, \n",
    "    0.22412, 0.99205]\n",
    "\n",
    "\n",
    "l = [0, 0, 0,        0, -5, 5,  -5, 0.01, 0.005, 0., 0., 0.]\n",
    "u = [200, 200, 200, 30, +5, 25, +5, 1.2,    0.7, 1., 1., 1.]\n",
    "\n",
    "res = optimize(d4, params, l, u, Fminbox(); \n",
    "         optimizer = GradientDescent, optimizer_o = OptimizationOptions(g_tol = 1e-12,\n",
    "                                                                        x_tol = 1e-10,\n",
    "                                                                        f_tol = 1e-6,                                                                        \n",
    "                                                                        iterations = 200,\n",
    "                                                                        store_trace = true,\n",
    "                                                                        show_trace = true,\n",
    "                                                                        extended_trace = true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_bf = res.f_minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res.minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time LL, LLgrad, LLhess = ComputeHess(params,ratdata,ntrials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function main()\n",
    "    \n",
    "    ratname = \"fof\"\n",
    "    # data import\n",
    "    ratdata = matread(*(\"chrono_\",ratname,\"_rawdata.mat\"))\n",
    "    println(\"rawdata of \", ratname, \" imported\" )\n",
    "\n",
    "    # number of trials\n",
    "    ntrials = 2#length(ratdata[\"rawdata\"][\"rightbups\"]) \n",
    "\n",
    "    # Parameters\n",
    "    sigma_a = 1; sigma_s_R = 0.1; sigma_s_L = 0.1; sigma_i = 0.2; \n",
    "    lam = -0.0005; B = 10.; bias = .2; \n",
    "    phi = 0.3; tau_phi = 0.1; lapse_R = 0.05*2; lapse_L = 0.1;\n",
    "    input_gain_weight = 0.1; \n",
    "\n",
    "    params = [sigma_a, sigma_s_R, sigma_s_L, sigma_i, lam, B, bias, phi, tau_phi, lapse_R, lapse_L, input_gain_weight]   \n",
    "\n",
    "    l = [0, 0, 0,        0, -5, 5,  -5, 0.01, 0.005, 0., 0., 0.]\n",
    "    u = [200, 200, 200, 30, +5, 25, +5, 1.2,    0.7, 1., 1., 1.]\n",
    "\n",
    "\n",
    "    function LL_f(params::Vector)\n",
    "        return ComputeLL(params, ratdata[\"rawdata\"], ntrials)\n",
    "    end\n",
    "\n",
    "    function LL_g!(params::Vector, grads::Vector)\n",
    "    #     LL, LLgrad, LLhess = llikey(params)\n",
    "        LL, LLgrad = ComputeGrad(params, ratdata[\"rawdata\"], ntrials)\n",
    "        for i=1:length(params)\n",
    "            grads[i] = LLgrad[i]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    function LL_fg!(params::Vector, grads)\n",
    "        LL, LLgrad = ComputeGrad(params, ratdata[\"rawdata\"], ntrials)\n",
    "        for i=1:length(params)\n",
    "            grads[i] = LLgrad[i]\n",
    "        end\n",
    "        return LL\n",
    "    end\n",
    "    \n",
    "    d4 = DifferentiableFunction(LL_f,\n",
    "                                LL_g!,\n",
    "                                LL_fg!)\n",
    "\n",
    "    tic()\n",
    "    history = optimize(d4, params, l, u, Fminbox(); \n",
    "             optimizer = GradientDescent, optimizer_o = OptimizationOptions(g_tol = 1e-12,\n",
    "                                                                            x_tol = 1e-10,\n",
    "                                                                            f_tol = 1e-6,\n",
    "                                                                            iterations = 200,\n",
    "                                                                            store_trace = true,\n",
    "                                                                            ))\n",
    "    fit_time = toc()\n",
    "    println(history.minimum)\n",
    "    println(history)\n",
    "\n",
    "    ## do a single functional evaluation at best fit parameters and save likely for each trial\n",
    "    likely_all = zeros(typeof(sigma_i),ntrials)\n",
    "    x_bf = history.minimum\n",
    "    Likely_all_trials(likely_all, x_bf, ratdata[\"rawdata\"], ntrials)\n",
    "    LL, LLgrad, LLhess = ComputeHess(x_bf, ratdata, ntrials)\n",
    "\n",
    "#     matwrite(saveto_filename, Dict([(\"ratname\",ratname),\n",
    "#                                     (\"x_init\",params),\n",
    "#                                     (\"trials\",ntrials),\n",
    "#                                     #(\"history\",history),\n",
    "#                                     (\"f\",history.f_minimum), \n",
    "#                                     (\"x_converged\",history.x_converged),\n",
    "#                                     (\"f_converged\",history.f_converged),\n",
    "#                                     (\"g_converged\",history.g_converged),                                    \n",
    "#                                     (\"fit_time\",fit_time),\n",
    "#                                     (\"x_bf\",history.minimum),\n",
    "#                                     (\"myfval\", history.f_minimum),\n",
    "#                                     (\"hessian\", LLhess),\n",
    "#                                     (\"likely\",likely_all)\n",
    "#                                     ]))\n",
    "\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make grid of params. get likelihood with laplace approximation -> likelihood landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## with hessian matrix\n",
    "using PyPlot\n",
    "imshow(log(abs(LLhess)), interpolation=\"none\")\n",
    "\n",
    "history = res\n",
    "print(history.f_minimum)\n",
    "X = history.minimum\n",
    "tt = history.f_minimum * exp((-1/2)*transpose(X-history.minimum)*LLhess*(X-history.minimum))\n",
    "print(tt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Simulation \n",
    "### generate synthetic data, test the model with several parameter sets\n",
    "1. Generate Click trials\n",
    "2. Run Virtual rats\n",
    "3. Fit the synthetic data\n",
    "4. compare the best-fit parameters with the parameters that we used to generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to make clicks.\n",
    "\n",
    "function make_clicks_trains(difficulty, T, ntrials)\n",
    "\n",
    "    # difficulty : 0.025 (39:1) / 0.075 (37:3) / 0.225 (31:9) / 0.35 (26:14)\n",
    "    # T - max time (sec) : 0.5\n",
    "    # ntrials : 1000\n",
    "\n",
    "    R = 40\n",
    "\n",
    "    # difficulty = r1:r2\n",
    "    r1 = R*(1.0-difficulty);\n",
    "    r2 = R-r1;\n",
    "\n",
    "    # data = Array(Dict,ntrials)\n",
    "    Ls = Array(Any,1,ntrials)\n",
    "    Rs = Array(Any,1,ntrials)\n",
    "    As = Array(Any,ntrials)\n",
    "    Gams = Array(Any,ntrials)\n",
    "\n",
    "    for t=1:ntrials\n",
    "\n",
    "    if rand()<0.5\n",
    "        gamma = log(r1/r2) # log of click rate ratio\n",
    "    else\n",
    "        gamma = -log(r1/r2)\n",
    "    end\n",
    "#     T = 0.5\n",
    "\n",
    "    rrate = R/(exp(-gamma)+1)\n",
    "    lrate = R - rrate\n",
    "\n",
    "    srate = R*1000\n",
    "    bup_width = 3\n",
    "    lT2 = ceil(Int, T * 1000 / bup_width)\n",
    "    tp1 = find(rand(lT2) .< lrate/(1000/bup_width))\n",
    "    tp2 = find(rand(lT2) .< rrate/(1000/bup_width))\n",
    "\n",
    "    prepend!(tp1,[0])\n",
    "    prepend!(tp2,[0])\n",
    "\n",
    "    leftbups = tp1 * (srate / (1000 / bup_width))/srate\n",
    "    rightbups = tp2 * (srate / (1000 / bup_width))/srate\n",
    "\n",
    "    answer = gamma > 0?1:-1\n",
    "\n",
    "    Ls[t] = leftbups\n",
    "    Rs[t] = rightbups\n",
    "    As[t] = answer\n",
    "    Gams[t] = gamma\n",
    "\n",
    "    end\n",
    "\n",
    "    data = Dict([(\"leftbups\",Ls),\n",
    "        (\"gammas\",Gams),\n",
    "        (\"rightbups\",Rs),\n",
    "        (\"answer\",As)])\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time data = make_clicks_trains(0.075,0.8,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function clicks_from_data(data, ntrials)\n",
    "    \n",
    "    data_len = length(data[\"rightbups\"]) \n",
    "    \n",
    "    Ls = Array(Any,1,ntrials)\n",
    "    Rs = Array(Any,1,ntrials)\n",
    "    As = Array(Any,ntrials)\n",
    "    Gams = Array(Any,ntrials)\n",
    "\n",
    "    for t=1:ntrials\n",
    "        i = mod(t, data_len)\n",
    "        if i==0\n",
    "            i = data_len;\n",
    "        end\n",
    "        Ls[t] = data[\"leftbups\"][i]\n",
    "        Rs[t] = data[\"rightbups\"][i]\n",
    "        As[t] = (data[\"hit\"][i] == true) == (data[\"pokedR\"][i] == true) ? 1 : -1\n",
    "        Gams[t] = data[\"gamma\"][i]\n",
    "    end\n",
    "\n",
    "    data = Dict([(\"leftbups\",Ls),\n",
    "        (\"gamma\",Gams),\n",
    "        (\"rightbups\",Rs),\n",
    "        (\"answer\",As)])\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = clicks_from_data(ratdata[\"rawdata\"], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run simulation : get virtual rat choice\n",
    "\n",
    "# rats with different bias params.\n",
    "# 1. strong post categorization (biased_lapse)\n",
    "# 2. strong biased gain input (biased_input) 1~0 : >0.5 right bias, <0.5 left bias\n",
    "# 3. accumulation shift (bias)\n",
    "# 4. biased sensory noise (biased_noise)\n",
    "\n",
    "# virtual rat\n",
    "# # sigma_a / sigma_s_R / sigma_s_L / sigma_i / lambda / B / bias / phi / tau_phi / \n",
    "# # lapse_R / lapse_L / input_gain_weight\n",
    "\n",
    "# params =[1.3  0.  0.   0. 0.06 10 0    0.33 0.39 0.03 0.5  0.5; # Strong Post Categorization\n",
    "#          1.3  0.  0.   0. 0.06 10 0    0.33 0.39 0.03 0.03 0.1; # Strong biased gain input\n",
    "#          1.3  0.  200. 0. 0.06 10 0    0.33 0.39 0.03 0.03 0.5; # Biased Sensory Noise\n",
    "#          1.3  0.  0.   0. 0.06 10 -6.5 0.33 0.39 0.03 0.03 0.5; # Accumulation shift (bias)\n",
    "#         ];\n",
    "\n",
    "function run_virtual_rat(data, param, T)\n",
    "\n",
    "    ntrials = length(data[\"leftbups\"])\n",
    "    Rs = Array(Any,1,ntrials)\n",
    "    Ts = Array(Any,1,ntrials)\n",
    "    Delta = Array(Int,1,ntrials)\n",
    "\n",
    "    sigma_a = sqrt(param[1]); sigma_s_R = sqrt(param[2]); sigma_s_L = sqrt(param[3]);\n",
    "    sigma_i = param[4]; lambda = param[5]; B = param[6]; bias = param[7]; \n",
    "    phi = param[8]; tau_phi = param[9]; lapse_R = param[10]; lapse_L = param[11];\n",
    "    input_gain_weight = param[12];\n",
    "    \n",
    "    Flip = rand(ntrials) \n",
    "    Flip_RtoL = Flip .< lapse_L\n",
    "    Flip_LtoR = Flip .> 1-lapse_R\n",
    "    \n",
    "    for i=1:ntrials\n",
    "        leftbups = data[\"leftbups\"][i]\n",
    "        rightbups = data[\"rightbups\"][i]\n",
    "#         answer = data[\"answer\"][i]\n",
    "\n",
    "        rat_choice = 0;\n",
    "\n",
    "        dt = 0.0001\n",
    "\n",
    "        time = dt:dt:T\n",
    "        lC = zeros(time)\n",
    "        rC = zeros(time)\n",
    "        dC = zeros(time)\n",
    "\n",
    "        adap_c = zeros(time)\n",
    "        adap_c[1] = 1.\n",
    "\n",
    "        dd = exp(dt*lambda)\n",
    "        eta = sigma_a*sqrt(dt)\n",
    "\n",
    "#             figure()\n",
    "        for t = 1:length(time)-1\n",
    "\n",
    "            if isempty(find(time[t] .< leftbups .<= time[t+1])) & isempty(find(time[t] .< rightbups .<= time[t+1]))\n",
    "                adap_c[t+1] = adap_c[t] + ((1-adap_c[t])/tau_phi + (phi-1)*adap_c[t])*dt\n",
    "            else\n",
    "                adap_c[t+1] = adap_c[t] + (1-adap_c[t])/tau_phi*dt\n",
    "            end\n",
    "\n",
    "            # sigma_i ?\n",
    "#             if t==1\n",
    "#                 lC[1] = sigma_i\n",
    "#                 rc[1] = sigma_i\n",
    "#             end\n",
    "            \n",
    "            if ~isempty(find(time[t] .< leftbups .<= time[t+1]))\n",
    "                lC[t+1] = lC[t] + adap_c[t+1] + (randn()*sigma_s_L)\n",
    "            else\n",
    "                lC[t+1] = lC[t]*dd + randn()*eta\n",
    "\n",
    "            end\n",
    "\n",
    "            if ~isempty(find(time[t] .< rightbups .<= time[t+1]))\n",
    "                rC[t+1] = rC[t] + adap_c[t+1] + (randn()*sigma_s_R)\n",
    "            else\n",
    "                rC[t+1] = rC[t]*dd + randn()*eta\n",
    "            end\n",
    "\n",
    "            lC[t+1] = max(0,lC[t+1])\n",
    "            rC[t+1] = max(0,rC[t+1])\n",
    "            \n",
    "            dC[t+1] = (2*input_gain_weight*rC[t+1] - 2*(1-input_gain_weight)*lC[t+1]) + bias #rC[t+1] - lC[t+1]\n",
    "\n",
    "            if dC[t+1] >= B\n",
    "                dC[t+1:end] = dC[t+1]\n",
    "                rat_choice = 1;\n",
    "                break;\n",
    "            elseif dC[t+1] <= -B\n",
    "                dC[t+1:end] = dC[t+1]\n",
    "                rat_choice = 0;\n",
    "                break;\n",
    "            end\n",
    "        end\n",
    "\n",
    "#             plot(time,dC,color=\"black\")\n",
    "#             plot(reshape(leftbups,(1,size(leftbups,1))),-B+0.25,color=\"blue\",linestyle=\"none\",marker=\"^\",markeredgecolor=\"none\")\n",
    "#             plot(reshape(rightbups,(1,size(rightbups,1))),B-0.25,color=\"red\",linestyle=\"none\",marker=\"v\",markeredgecolor=\"none\")\n",
    "\n",
    "#             new_position = [0.06,0.06,0.91,0.27] # Position Method 2\n",
    "#             ax = gca()\n",
    "#             ax[:set_position](new_position)\n",
    "#             yticks(-B:1:B)\n",
    "#             grid()\n",
    "\n",
    "        if rat_choice == 0\n",
    "            rat_choice = dC[end] > 0?1:0\n",
    "        end\n",
    "\n",
    "        if Flip_RtoL[i]\n",
    "            rat_choice = rat_choice == 1?0:0\n",
    "        elseif Flip_LtoR[i]\n",
    "            rat_choice = rat_choice == 0?1:1\n",
    "        end\n",
    "        \n",
    "        Rs[i] = rat_choice\n",
    "        if size(leftbups,1) > 1 || size(rightbups,1) > 1\n",
    "            Ts[i] = maximum([leftbups; rightbups]) + 0.1\n",
    "        else\n",
    "            Ts[i] = maximum([leftbups rightbups]) + 0.1\n",
    "        end\n",
    "        Delta[i] = length(rightbups) - length(leftbups);\n",
    "\n",
    "    end\n",
    "    results =  Dict([(\"leftbups\", data[\"leftbups\"]),\n",
    "        (\"rightbups\", data[\"rightbups\"]),\n",
    "#         (\"answer\", data[\"answer\"]),\n",
    "        (\"pokedR\", Rs),\n",
    "        (\"params\", param),\n",
    "        (\"Delta\", Delta),\n",
    "        (\"T\",Ts)\n",
    "        ])\n",
    "    return results\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sigma_a / sigma_s_R / sigma_s_L / sigma_i / lambda / B / bias / phi / tau_phi / \n",
    "# lapse_R / lapse_L / input_gain_weight\n",
    "\n",
    "params =[1.3  0.  0.   0. 0.06 10 0    0.33 0.39 0.03 0.5  0.5; # Strong Post Categorization\n",
    "         1.3  0.  0.   0. 0.06 10 0    0.33 0.39 0.03 0.03 0.1; # Strong biased gain input\n",
    "         1.3  0.  200. 0. 0.06 10 0    0.33 0.39 0.03 0.03 0.5; # Biased Sensory Noise\n",
    "         1.3  0.  0.   0. 0.06 10 -6.5 0.33 0.39 0.03 0.03 0.5; # Accumulation shift (bias)\n",
    "        ];\n",
    "ntrials = 10000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## run virtual rat with 4 different parameter set.\n",
    "tic()\n",
    "results1 = run_virtual_rat(data,params[1,:],0.5)\n",
    "C1 = sort(unique(results1[\"Delta\"]))\n",
    "prob_right1 = zeros(length(C1))\n",
    "for i=1:length(C1)\n",
    "    ci = C1[i]\n",
    "    idd = find(ci.==results1[\"Delta\"])\n",
    "    prob_right1[i] = sum(results1[\"pokedR\"][idd])/length(idd)\n",
    "end\n",
    "println(\"set1 done\")\n",
    "println(toc())\n",
    "\n",
    "results2 = run_virtual_rat(data,params[2,:],0.5)\n",
    "C2 = sort(unique(results2[\"Delta\"]))\n",
    "prob_right2 = zeros(length(C2))\n",
    "for i=1:length(C2)\n",
    "    ci = C2[i]\n",
    "    idd = find(ci.==results2[\"Delta\"])\n",
    "    prob_right2[i] = sum(results2[\"pokedR\"][idd])/length(idd)\n",
    "end\n",
    "println(\"set2 done\")\n",
    "\n",
    "results3 = run_virtual_rat(data,params[3,:],0.5)\n",
    "C3 = sort(unique(results3[\"Delta\"]))\n",
    "prob_right3 = zeros(length(C3))\n",
    "for i=1:length(C3)\n",
    "    ci = C3[i]\n",
    "    idd = find(ci.==results3[\"Delta\"])\n",
    "    prob_right3[i] = sum(results3[\"pokedR\"][idd])/length(idd)\n",
    "end\n",
    "println(\"set3 done\")\n",
    "\n",
    "results4 = run_virtual_rat(data,params[4,:],0.5)\n",
    "C4 = sort(unique(results4[\"Delta\"]))\n",
    "prob_right4 = zeros(length(C4))\n",
    "for i=1:length(C4)\n",
    "    ci = C4[i]\n",
    "    idd = find(ci.==results4[\"Delta\"])\n",
    "    prob_right4[i] = sum(results4[\"pokedR\"][idd])/length(idd)\n",
    "end\n",
    "println(\"set4 done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure; \n",
    "subplot(221); plot(C1,prob_right1,linestyle=\"none\",marker=\".\")\n",
    "subplot(222); plot(C2,prob_right2,linestyle=\"none\",marker=\".\")\n",
    "subplot(223); plot(C3,prob_right3,linestyle=\"none\",marker=\".\")\n",
    "subplot(224); plot(C4,prob_right4,linestyle=\"none\",marker=\".\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using LsqFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sig4(x, p) = p[1] + p[2]./(1 + exp(-(x-p[3]) ./ p[4]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure; \n",
    "subplot(221); plot(C1,prob_right1,linestyle=\"none\",marker=\".\")\n",
    "fit = curve_fit(sig4, C1, prob_right1, [0.1, 0.2, 0.5, 0.2])\n",
    "x = minimum(C1):0.1:maximum(C1)\n",
    "y = sig4(x,fit.param)\n",
    "plot(x,y)\n",
    "ylim(0,1)\n",
    "# xlabel(\"#(right) - #(left)\")\n",
    "ylabel(\"prob. of right poke\")\n",
    "title(\"Strong Post Categorization\")\n",
    "println(\"1: lapse : \", fit.param[1], \", bias  : \", fit.param[3])\n",
    "\n",
    "subplot(222); plot(C2,prob_right2,linestyle=\"none\",marker=\".\")\n",
    "fit = curve_fit(sig4, C2, prob_right2, [0.1, 0.2, 0.5, 0.2])\n",
    "x = minimum(C2):0.1:maximum(C2)\n",
    "y = sig4(x,fit.param)\n",
    "plot(x,y)\n",
    "ylim(0,1)\n",
    "# xlabel(\"#(right) - #(left)\")\n",
    "ylabel(\"prob. of right poke\")\n",
    "title(\"Strong biased gain input\")\n",
    "println(\"2: lapse : \", fit.param[1], \", bias  : \", fit.param[3])\n",
    "\n",
    "subplot(223); plot(C3,prob_right3,linestyle=\"none\",marker=\".\")\n",
    "fit = curve_fit(sig4, C3, prob_right3, [0.1, 0.2, 0.5, 0.2])\n",
    "x = minimum(C3):0.1:maximum(C3)\n",
    "y = sig4(x,fit.param)\n",
    "plot(x,y)\n",
    "ylim(0,1)\n",
    "xlabel(\"#(right) - #(left)\")\n",
    "ylabel(\"prob. of right poke\")\n",
    "title(\"Biased Sensory Noise\")\n",
    "println(\"3: lapse : \", fit.param[1], \", bias  : \", fit.param[3])\n",
    "\n",
    "subplot(224); plot(C4,prob_right4,linestyle=\"none\",marker=\".\")\n",
    "fit = curve_fit(sig4, C4, prob_right4, [0.1, 0.2, 0.5, 0.2])\n",
    "x = minimum(C4):0.1:maximum(C4)\n",
    "y = sig4(x,fit.param)\n",
    "plot(x,y)\n",
    "ylim(0,1)\n",
    "xlabel(\"#(right) - #(left)\")\n",
    "ylabel(\"prob. of right poke\")\n",
    "title(\"Accumulation shift (bias)\")\n",
    "println(\"4: lapse : \", fit.param[1], \", bias  : \", fit.param[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = 2;\n",
    "println(\"set\",p, \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "*(\"set\",string(p), \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure; subplot(5,2,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.5",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
