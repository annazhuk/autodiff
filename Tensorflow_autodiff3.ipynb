{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow(using Pyfunc for model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# data import\n",
    "import scipy.io\n",
    "ratdata = scipy.io.loadmat('chrono_B069_rawdata.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trial index starts from 0 \n",
    "\n",
    "def trialdata(ratdata,trial):\n",
    "    if ratdata['rawdata']['pokedR'][0][trial] > 0 :\n",
    "        rat_choice = 1 # \"R\"\n",
    "    else : \n",
    "        rat_choice = -1 # \"L\"\n",
    "        \n",
    "    return ratdata['rawdata']['rightbups'][0][trial][0], \\\n",
    "ratdata['rawdata']['leftbups'][0][trial][0], \\\n",
    "ratdata['rawdata']['T'][0][trial], rat_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       0.19235  0.34361]\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "# trial index starts from 0 \n",
    "RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata, 0) \n",
    "print LeftClickTimes\n",
    "print rat_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Global variables \n",
    "epsilon = 10.0**(-10) \n",
    "dx = 0.25\n",
    "dt = 0.02\n",
    "\n",
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bin_centers = make_bins(B, dx, binN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bins(B, dx, binN):\n",
    "    '''\n",
    "    inputs:\n",
    "    -------\n",
    "    - B is the value of the accumulator's sticky bound\n",
    "    - dx is the spacing between all bins, except the first and last \n",
    "    - binN is the number of bins with bin centers > 0\n",
    "    \n",
    "    outputs:\n",
    "    --------\n",
    "    - bin_centers array of bin_centers\n",
    "    '''\n",
    "    bins = (np.arange(binN)+1)*B\n",
    "    bins = dx*bins/B\n",
    "    \n",
    "    if bins[-1] == B:\n",
    "        bins[-1] = B+dx\n",
    "    else:\n",
    "        bins[-1] = 2*B - bins[-2]\n",
    "    \n",
    "    bins = np.hstack((-bins[::-1], np.array([0]), bins))\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F = Fmatrix([sigma, lambda, c], bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Fmatrix(params, bin_centers):\n",
    "    global dt,dx\n",
    "    sigma2 = params[0]\n",
    "    lam = params[1]\n",
    "    c = params[2]\n",
    "    \n",
    "    sigma2_sbin = sigma2\n",
    "    \n",
    "    F = np.zeros((bin_centers.size,bin_centers.size))\n",
    "    \n",
    "    if lam == 0:  # for Fi\n",
    "        mus = bin_centers*np.exp(lam*dt)\n",
    "    else:        \n",
    "        mus = np.exp(lam*dt)*(bin_centers + c/lam) - c/lam\n",
    "\n",
    "        \n",
    "# modified it according to gaussbins.m -amyoon\n",
    "#     sbinsize = 0.1*sigma_sbin\n",
    "#     swidth = 4*sigma_sbin\n",
    "#     sbins = np.arange(-swidth,swidth+epsilon,sbinsize)\n",
    "    n_sbins = max(70, np.ceil(10*np.sqrt(sigma2_sbin)/dx))\n",
    "\n",
    "    swidth = 5*np.sqrt(sigma2_sbin)\n",
    "    sbins = np.linspace(-swidth,swidth,n_sbins*2+1)\n",
    "    sbinsize = sbins[1]-sbins[0]\n",
    "\n",
    "    ps = np.exp(-sbins**2/(2*sigma2)) \n",
    "    ps = ps/sum(ps)\n",
    "            \n",
    "    base_sbins = sbins\n",
    "        \n",
    "    for j in np.arange(bin_centers.size-1)+1:\n",
    "        sbins = base_sbins + mus[j]\n",
    "        tmp = 1\n",
    "        \n",
    "        for k in range(sbins.size):\n",
    "            if sbins[k] <= bin_centers[0]:\n",
    "                F[0,j] += ps[k]\n",
    "            elif sbins[k] >= bin_centers[-1]:\n",
    "                F[-1,j] += ps[k]\n",
    "            else:\n",
    "                if (sbins[k] > bin_centers[0] and sbins[k] < bin_centers[1]):\n",
    "                    bottom = 0; top = 1;\n",
    "                elif (sbins[k] > bin_centers[-2] and sbins[k] < bin_centers[-1]):\n",
    "                    bottom = bin_centers.size-2; top = bin_centers.size-1;\n",
    "                else :    \n",
    "                    bottom = int(np.floor((sbins[k]-bin_centers[1])/dx) + 1);\n",
    "                    top = int(np.ceil((sbins[k]-bin_centers[1])/dx) + 1);\n",
    "\n",
    "                if bottom < 0: bottom = 0; \n",
    "                if top < 0: top = 0; \n",
    "\n",
    "                if bottom == top:\n",
    "                    F[bottom,j] += ps[k]\n",
    "                else:\n",
    "                    F[top,j] += ps[k]*(sbins[k] - bin_centers[bottom])/(bin_centers[top] - bin_centers[bottom])\n",
    "                    F[bottom,j] += ps[k]*(bin_centers[top] - sbins[k])/(bin_centers[top] - bin_centers[bottom])\n",
    "                        \n",
    "    F[:,0] = 0\n",
    "    F[:,-1] = 0\n",
    "    F[0,0] = 1\n",
    "    F[-1,-1] = 1\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##################### so..........."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LL = logProbRight(params)\n",
    "\n",
    "params = [sigma_a, sigma_s, sigma_i, lambda, B, bias, phi, tau_phi, lapse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial : 0001 LL =  -2.535253892\n",
      "Trial : 0002 LL =  -0.240068729\n",
      "Trial : 0003 LL =  -0.053111613\n",
      "Trial : 0004 LL =  -2.835791595\n",
      "Trial : 0005 LL =  -0.186951994\n",
      "Trial : 0006 LL =  -1.200522806\n",
      "Trial : 0007 LL =  -0.051297237\n",
      "Trial : 0008 LL =  -0.051327458\n",
      "Trial : 0009 LL =  -1.489630181\n",
      "Trial : 0010 LL =  -0.071373653\n",
      "Trial : 0011 LL =  -0.979718816\n",
      "Trial : 0012 LL =  -0.051501203\n",
      "Trial : 0013 LL =  -0.244441988\n",
      "Trial : 0014 LL =  -2.949191683\n",
      "Trial : 0015 LL =  -0.542772727\n",
      "Trial : 0016 LL =  -0.051361191\n",
      "Trial : 0017 LL =  -0.053230288\n",
      "Trial : 0018 LL =  -1.016906091\n",
      "Trial : 0019 LL =  -0.052075662\n",
      "Trial : 0020 LL =  -0.162860514\n",
      "Trial : 0021 LL =  -0.053274167\n",
      "Trial : 0022 LL =  -2.995303232\n",
      "Trial : 0023 LL =  -0.797323782\n",
      "Trial : 0024 LL =  -1.394077035\n",
      "Trial : 0025 LL =  -0.067127882\n",
      "Trial : 0026 LL =  -0.051295122\n",
      "Trial : 0027 LL =  -0.094515498\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# =========================== Model ================================ #\n",
    "\n",
    "def logLike(sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse, RightClickTimes, LeftClickTimes, maxT, rat_choice):\n",
    "    tf_params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]\n",
    "    if rat_choice > 0: # == \"R\":\n",
    "        LP_right = logProbRight(tf_params, RightClickTimes, LeftClickTimes, maxT)\n",
    "#         print \"R : \" + str(LP_right)\n",
    "        return LP_right\n",
    "    elif rat_choice < 0: # == \"L\":\n",
    "        LP_right = logProbRight(tf_params, RightClickTimes, LeftClickTimes, maxT)\n",
    "#         print \"L : \" + str(np.log(1 - np.exp(LP_right)))\n",
    "        return np.log(1 - np.exp(LP_right))\n",
    "    else:\n",
    "        print -1. # \"Rat did what?? It was neither R nor L\"\n",
    "        \n",
    "def logProbRight(params, RightClickTimes, LeftClickTimes, maxT):\n",
    "#     sigma_a = params['sigma_a']\n",
    "#     sigma_s = params['sigma_s']\n",
    "#     sigma_i = params['sigma_i']\n",
    "#     lam = params['lambda']\n",
    "#     B = params['B']\n",
    "#     bias = params['bias']\n",
    "#     phi = params['phi']\n",
    "#     tau_phi = params['tau_phi']\n",
    "#     lapse = params['lapse']\n",
    "#     params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]  \n",
    "    \n",
    "    sigma2_a = params[0]\n",
    "    sigma2_s = params[1]\n",
    "    sigma2_i = params[2]\n",
    "    lam = params[3]\n",
    "    B = params[4]\n",
    "    bias = params[5]\n",
    "    phi = params[6]\n",
    "    tau_phi = params[7]\n",
    "    lapse = params[8]\n",
    "    \n",
    "    global a, dx, dt, a_trace, c_trace\n",
    "        \n",
    "    Nsteps = int(np.ceil(maxT/dt))\n",
    "\n",
    "    if RightClickTimes.size == 0:\n",
    "        RightClickTimes = np.empty(0)\n",
    "    if LeftClickTimes.size == 0:\n",
    "        LeftClickTimes = np.empty(0)\n",
    "    \n",
    "    net_input = np.zeros((1, Nsteps))\n",
    "    total_input = np.zeros((1, Nsteps))\n",
    "\n",
    "    NClicks = np.zeros((1, Nsteps))    \n",
    "    \n",
    "        \n",
    "    # ====== Make adapted clicks\n",
    "    \n",
    "    Lsame = np.ones((1,np.size(LeftClickTimes)))\n",
    "    Rsame = np.ones((1,np.size(RightClickTimes)))\n",
    "    # magnitude of stereo clicks set to zero   \n",
    "    Lsame[0] = 0; Rsame[0] = 0;\n",
    "    \n",
    "    # inter-click-intervals\n",
    "    ici_L = np.diff(LeftClickTimes)\n",
    "    ici_R = np.diff(RightClickTimes)\n",
    "    \n",
    "    for i in np.arange(np.size(LeftClickTimes)-1)+1:\n",
    "        last_L = tau_phi*np.log(1-Lsame[0][i-1]*phi)\n",
    "        Lsame[0][i] = 1 - np.exp((-ici_L[i-1] + last_L)/tau_phi)\n",
    "        \n",
    "    for i in np.arange(np.size(RightClickTimes)-1)+1:\n",
    "        last_R = tau_phi*np.log(1-Rsame[0][i-1]*phi)\n",
    "        Rsame[0][i] = 1 - np.exp((-ici_R[i-1] + last_R)/tau_phi)\n",
    "\n",
    "    Lsame = Lsame.real    \n",
    "    Rsame = Rsame.real   \n",
    "        \n",
    "    # index starts from 0\n",
    "    # net_input / total_input\n",
    "    # Counting number of clicks\n",
    "    cnt = 0\n",
    "    for i in np.ceil((RightClickTimes+epsilon)/dt).astype(int):\n",
    "        NClicks[0][i-1] += 1\n",
    "        net_input[0][i-1] += Rsame[0][cnt]\n",
    "        total_input[0][i-1] += Rsame[0][cnt]\n",
    "        cnt += 1\n",
    "    \n",
    "    cnt = 0 \n",
    "    for i in np.ceil((LeftClickTimes+epsilon)/dt).astype(int):\n",
    "        NClicks[0][i-1] += 1  \n",
    "        net_input[0][i-1] -= Lsame[0][cnt]\n",
    "        total_input[0][i-1] += Lsame[0][cnt]\n",
    "        cnt += 1        \n",
    "       \n",
    "    binN = int(np.ceil(B/dx))\n",
    "    \n",
    "    bin_centers = make_bins(B,dx,binN)\n",
    "        \n",
    "    a_trace = np.zeros((bin_centers.size, Nsteps))\n",
    "    c_trace = np.zeros((1, Nsteps+1))\n",
    "    a0 = np.zeros(bin_centers.size)\n",
    "    a0[binN] = 1-2*lapse; a0[0] = lapse; a0[-1] = lapse;\n",
    "\n",
    "    \n",
    "    Fi = Fmatrix([sigma2_i, 0, 0.0], bin_centers)\n",
    "    \n",
    "    a = np.matmul(Fi,a0)\n",
    "    a_trace[:,0] = a.flatten()\n",
    " \n",
    "    F0 = Fmatrix([sigma2_a*dt, lam, 0.0], bin_centers)\n",
    "    for i in np.arange(Nsteps-1)+1:\n",
    "        if total_input[0][i-1]==0:\n",
    "            a = np.matmul(F0,a)\n",
    "        else:\n",
    "            total_var = sigma2_a*dt + (sigma2_s*total_input[0][i-1])/40\n",
    "            F = Fmatrix([total_var, lam, net_input[0][i-1]/dt], bin_centers)\n",
    "            a = np.matmul(F,a)\n",
    "            \n",
    "        c_trace[0][i] = net_input[0][i-1]\n",
    "        a_trace[:,i] = a.flatten()\n",
    "\n",
    "    bias_bottom = int(np.floor((bias-bin_centers[1])/dx) + 1)\n",
    "    bias_top = int(np.ceil((bias-bin_centers[1])/dx) + 1) # top\n",
    "    \n",
    "    Pd = np.zeros((1, bin_centers.size))\n",
    "    Pd[0][-bias_top+1:] = a[-bias_top+1:]\n",
    "    if bias_bottom == bias_top:\n",
    "        Pd[0][bias_bottom] = a[bias_bottom]/2\n",
    "    else:\n",
    "        dh = bin_centers[bias_top] - bias\n",
    "        dl = bias - bin_centers[bias_bottom]\n",
    "        dd = dh + dl\n",
    "        Pd[0][bias_top] = a[bias_top]*(0.5 + dh/dd/2)\n",
    "        Pd[0][bias_bottom] = a[bias_bottom]*(dh/dd/2)\n",
    "    \n",
    "    pright = sum(Pd[0])\n",
    "    \n",
    "    return np.log(pright)\n",
    "\n",
    "\n",
    "# =========== tf Graph Input =========== #\n",
    "\n",
    "## Variables \n",
    "# 1. (can assign the name of each variable later..)\n",
    "# tf_params = tf.Variable(params, name = \"params\")\n",
    "\n",
    "# 2. \n",
    "# tf_params = {\n",
    "#     'sigma_a' : tf.Variable(sigma_a, name=\"sigma_a\"),\n",
    "#     'sigma_s' : tf.Variable(sigma_s, name=\"sigma_s\"),\n",
    "#     'sigma_i' : tf.Variable(sigma_i, name=\"sigma_i\"),\n",
    "#     'lamda' : tf.Variable(lam, name=\"lambda\"),\n",
    "#     'B' : tf.Variable(B, name=\"B\"),\n",
    "#     'bias' : tf.Variable(bias, name=\"bias\"),\n",
    "#     'phi' : tf.Variable(phi, name=\"phi\"),\n",
    "#     'tau_phi' : tf.Variable(tau_phi, name=\"tau_phi\"),\n",
    "#     'lapse' : tf.Variable(lapse, name=\"lapse\")\n",
    "# }\n",
    "\n",
    "# 3.\n",
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05;\n",
    "\n",
    "sigma_a = tf.Variable(sigma_a, name=\"sigma_a\")\n",
    "sigma_s = tf.Variable(sigma_s, name=\"sigma_s\")\n",
    "sigma_i = tf.Variable(sigma_i, name=\"sigma_i\")\n",
    "lam = tf.Variable(lam, name=\"lambda\")\n",
    "B = tf.Variable(B, name=\"B\")\n",
    "bias = tf.Variable(bias, name=\"bias\")\n",
    "phi = tf.Variable(phi, name=\"phi\")\n",
    "tau_phi = tf.Variable(tau_phi, name=\"tau_phi\")\n",
    "lapse = tf.Variable(lapse, name=\"lapse\")\n",
    "# tf_params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]   \n",
    "\n",
    "# ----------tip\n",
    "# values = [1.0, 3.0]\n",
    "# vars_ = [tf.Variable([v], dtype=dtype) for v in values]\n",
    "\n",
    "\n",
    "## inputs\n",
    "RightClickTimes = tf.placeholder(tf.float32, name = 'RightClickTimes') # Right Clicks\n",
    "LeftClickTimes = tf.placeholder(tf.float32, name = 'LeftClickTimes') # Left Clicks\n",
    "maxT = tf.placeholder(tf.float32, name = 'maxT')\n",
    "rat_choice = tf.placeholder(tf.float32, name = 'rat_choice')\n",
    "\n",
    "\n",
    "# ==================== Construct Model ========================= #\n",
    "\n",
    "LL = tf.py_func(logLike, [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse, \n",
    "                          RightClickTimes, LeftClickTimes, maxT, rat_choice], [tf.float64])\n",
    "\n",
    "opt = tf.train.AdamOptimizer(0.1)\n",
    "grads_and_vars = opt.compute_gradients(tf.to_float(LL[0]),[sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse])\n",
    "grads2 = [g for g, _ in grads_and_vars]\n",
    "vars2 = [v for _, v in grads_and_vars]\n",
    "\n",
    "var_grad = tf.gradients(LL[0],[sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse])[0]\n",
    "\n",
    "# ==================== Launch the Graph ========================= #\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Set logs writer into folder /tmp/tensorflow_logs\n",
    "    summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def = sess.graph_def)\n",
    "\n",
    "    total_LL = 0.\n",
    "    \n",
    "    # Training cycle\n",
    "    for i in range(27):\n",
    "        RClickTimes1, LClickTimes1, maxT1, rat_choice1 = trialdata(ratdata, i)\n",
    "        \n",
    "        # Fit training using batch data\n",
    "        LLi = sess.run(LL, feed_dict={RightClickTimes:RClickTimes1, \n",
    "                                      LeftClickTimes: LClickTimes1, \n",
    "                                      maxT:maxT1, \n",
    "                                      rat_choice : rat_choice1})[0]\n",
    "        \n",
    "#         var_grad_val = sess.run(var_grad, feed_dict={RightClickTimes:RClickTimes1, \n",
    "#                                             LeftClickTimes: LClickTimes1, \n",
    "#                                             maxT:maxT1, \n",
    "#                                             rat_choice : rat_choice1})\n",
    "\n",
    "#         var_grad_val = sess.run(grads, feed_dict={RightClickTimes:RClickTimes1, \n",
    "#                                             LeftClickTimes: LClickTimes1, \n",
    "#                                             maxT:maxT1, \n",
    "#                                             rat_choice : rat_choice1})\n",
    "#         grad_vals = sess.run(grads2)\n",
    "\n",
    "\n",
    "        total_LL += LLi\n",
    "        \n",
    "        \n",
    "        print \"Trial :\", '%04d' % (i+1), \"LL = \", \"{:.9f}\".format(LLi)\n",
    "    \n",
    "    print \"Done.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, <tensorflow.python.ops.variables.Variable at 0x117b44590>),\n",
       " (None, <tensorflow.python.ops.variables.Variable at 0x117455590>),\n",
       " (None, <tensorflow.python.ops.variables.Variable at 0x117455450>),\n",
       " (None, <tensorflow.python.ops.variables.Variable at 0x117b44610>),\n",
       " (None, <tensorflow.python.ops.variables.Variable at 0x117b60bd0>),\n",
       " (None, <tensorflow.python.ops.variables.Variable at 0x117b60b10>),\n",
       " (None, <tensorflow.python.ops.variables.Variable at 0x117bc2790>),\n",
       " (None, <tensorflow.python.ops.variables.Variable at 0x117b72d50>),\n",
       " (None, <tensorflow.python.ops.variables.Variable at 0x117455850>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_and_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interactive debugging\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "# Btmp = log_likelihood(tf_params, \"R\", RightPulseTimes=np.array([0.2, 0.4]))\n",
    "# bb = tf.equal(rat_choice.eval(),'R')\n",
    "Btmp = tf_params\n",
    "sess.run(Btmp)\n",
    "print(Btmp.eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "logLike() takes exactly 13 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-26d1def6db27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mLL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogLike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrat_choice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: logLike() takes exactly 13 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "\n",
    "LL = logLike(params,rat_choice)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.1).minimize(LL, var_list=tf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf_params = tf.convert_to_tensor(params)\n",
    "# tf_params = params\n",
    "tf_params = tf.Variable(params)\n",
    "\n",
    "# Construct model\n",
    "LL = tf.py_func(logLike, [tf_params], [tf.float32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_params = tf.Variable(params)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "loss = logLike(tf_params)\n",
    "opt = tf.train.AdamOptimizer(0.1)\n",
    "grads = opt.compute_gradients(loss)\n",
    "\n",
    "grad_placeholder = [tf.float32]\n",
    "apply_placeholder_op = opt.apply_gradients(grad_placeholder)\n",
    "transform_grads = [(function1(grad[0]), grad[1]) for grad in grads]\n",
    "apply_transform_op = opt.apply_gradients(transform_grads)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    RClickTimes, LClickTimes, maxT, rat_choice = trialdata(ratdata, 10)\n",
    "    tt = session.run(grads)\n",
    "    print(tt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    global a, dx, dt, Nsteps, LeftClickTimes, RightClickTimes, a_trace, c_trace, bin_centers\n",
    "\n",
    "    RClickTimes, LClickTimes, maxT, rat_choice = trialdata(ratdata, 10)\n",
    "#     X = session.run(LL, feed_dict={tf_params: params})\n",
    "    tt = session.run(LL, feed_dict={tf_params: tf_params})[0]\n",
    "    print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adam Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(LL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(15):\n",
    "        avg_LL = 0.\n",
    "        # Loop over trials\n",
    "\n",
    "        for i in range(10):\n",
    "            RClickTimes, LClickTimes, maxT, rat_choice = trialdata(ratdata, i)\n",
    "\n",
    "            # Fit training using batch data\n",
    "            sess.run(LL, feed_dict={Rc:RClickTimes, Lc: LClickTimes, T:maxT, rat_choice:rat_choice})\n",
    "            # Compute average loss\n",
    "            avg_LL += sess.run(LL, feed_dict={x:batch_xs,y:batch_ys})/total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step ==0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "    print \"Optimization Done.\"\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "    print \"Accuracy:\", accuracy.eval({x:mnist.test.images, y: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TensorFlow Variables\n",
    "\n",
    "tf_params = {\n",
    "    'sigma_a' : tf.Variable(sigma_a, name=\"sigma_a\"),\n",
    "    'sigma_s' : tf.Variable(sigma_s, name=\"sigma_s\"),\n",
    "    'sigma_i' : tf.Variable(sigma_i, name=\"sigma_i\"),\n",
    "    'lambda' : tf.Variable(lam, name=\"lambda\"),\n",
    "    'B' : tf.Variable(B, name=\"B\"),\n",
    "    'bias' : tf.Variable(bias, name=\"bias\"),\n",
    "    'phi' : tf.Variable(phi, name=\"phi\"),\n",
    "    'tau_phi' : tf.Variable(tau_phi, name=\"tau_phi\"),\n",
    "    'lapse' : tf.Variable(lapse, name=\"lapse\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "B = 2.3\n",
    "dx = 1\n",
    "binN = np.ceil(B/dx)\n",
    "\n",
    "bin_centers = make_bins(B,dx,binN)\n",
    "bin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F = Fmatrix(params,bin_centers)\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logProbRight(params):\n",
    "    print(params['sigma_a'].eval())\n",
    "    sigma_a = params['sigma_a'].eval()\n",
    "    sigma_s = params['sigma_s'].eval()\n",
    "    sigma_i = params['sigma_i'].eval()\n",
    "    lam = params['lambda'].eval()\n",
    "    B = params['B'].eval()\n",
    "    bias = params['bias'].eval()\n",
    "    phi = params['phi'].eval()\n",
    "    tau_phi = params['tau_phi'].eval()\n",
    "    lapse = params['lapse'].eval()\n",
    "    \n",
    "    global a, dx, dt, Nsteps, LeftClickTimes, RightClickTimes, a_trace, c_trace, bin_centers\n",
    "        \n",
    "    LeftClicks = np.zeros((1, Nsteps))\n",
    "    RightClicks = np.zeros((1, Nsteps))\n",
    "\n",
    "    if RightClickTimes.size == 0:\n",
    "        RightClickTimes = np.empty(0)\n",
    "    if LeftClickTimes.size == 0:\n",
    "        LeftClickTimes = np.empty(0)\n",
    "    \n",
    "    # index starts from 0\n",
    "    for i in np.ceil((RightClickTimes+epsilon)/dt).astype(int):\n",
    "        RightClicks[0][i-1] = 1\n",
    "    for i in np.ceil((LeftClickTimes+epsilon)/dt).astype(int):\n",
    "        LeftClicks[0][i-1] = 1   \n",
    "\n",
    "    binN = int(np.ceil(B/dx))\n",
    "    binBias = int(np.floor(bias/dx)) + binN + 1\n",
    "    bin_centers = make_bins(B,dx,binN)\n",
    "    \n",
    "    a_trace = np.zeros((bin_centers.size, Nsteps+1))\n",
    "    c_trace = np.zeros((1, Nsteps+1))\n",
    "    a = np.zeros(bin_centers.size)#*sigma_a*0.0; \n",
    "    a[binN] = 1-2*lapse; a[0] = lapse; a[-1] = lapse;\n",
    "    c_eff   = 1\n",
    "    \n",
    "    Fi = Fmatrix([sigma_i/np.sqrt(dt), lam, 0.0], bin_centers)\n",
    "    a = np.matmul(Fi,a)\n",
    "    a_trace[:,0] = a.flatten()\n",
    "    \n",
    "    F0 = Fmatrix([sigma_a, lam, 0.0], bin_centers)\n",
    "    for i in range(Nsteps):\n",
    "        c_eff = 1 + (c_eff - 1)*np.exp(-dt/tau_phi)\n",
    "        if (RightClicks[0][i]==0) & (LeftClicks[0][i]==0):\n",
    "            a = np.matmul(F0,a)\n",
    "        elif (RightClicks[0][i]==1) & (LeftClicks[0][i]==1):\n",
    "            c_eff = 0\n",
    "            a = np.matmul(F0,a)\n",
    "        else:\n",
    "            net_sigma = np.sqrt(sigma_a**2 + (sigma_s*c_eff)**2/dt)\n",
    "            F = Fmatrix([net_sigma, lam, (RightClicks[0][i] - LeftClicks[0][i])*c_eff/dt], bin_centers)\n",
    "            a = np.matmul(F,a)\n",
    "            c_eff = c_eff*phi\n",
    "        \n",
    "        c_trace[0][i+1] = c_eff\n",
    "        a_trace[:,i+1] = a.flatten()\n",
    "\n",
    "    pright = sum(a[-binBias+1:]) + a[binBias-1]*0.5*(dx/2 - (bias - bin_centers[binBias-1]))/(dx/2)\n",
    "\n",
    "    return np.log(pright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "LL = logProbRight(params)\n",
    "\n",
    "im = plt.imshow(a_trace)\n",
    "plt.colorbar()\n",
    "im.set_extent([0,maxT*20,bin_centers[0], bin_centers[-1]])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(bin_centers,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logLike(params):\n",
    "    if rat_choice == \"R\":\n",
    "        LP_right = logProbRight(params)\n",
    "        return LP_right, a_trace\n",
    "    elif rat_choice == \"L\":\n",
    "        LP_right = logProbRight(params)\n",
    "        return np.log(1 - np.exp(LP_right))\n",
    "    else:\n",
    "        print \"Rat did what?? It was neither R nor L\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logLike(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def llikey(params, rat_choice, maxT=1, RightPulseTimes=np.array([]), LeftPulseTimes=np.array([]), dx=0.25, dt=0.02):\n",
    "\n",
    "    global RightClickTimes, LeftClickTimes, Nsteps\n",
    "    \n",
    "    RightClickTimes = RightPulseTimes.compress((RightPulseTimes <= maxT).flat)\n",
    "    LeftClickTimes  = LeftPulseTimes.compress((LeftPulseTimes <= maxT).flat)\n",
    "    Nsteps = int(np.ceil(maxT/dt))\n",
    "    \n",
    "    B = params[4].eval()\n",
    "    binN = int(np.ceil(B/dx))\n",
    "    bin_centers = make_bins(B, dx, binN); \n",
    "    bin_times = dt*np.arange(Nsteps+1);\n",
    "    \n",
    "    LL = logLike(params)\n",
    "#     LLgrad = tf.gradients(LL, params)[0]\n",
    "#     hess = tf.map_fn(lambda grid: tf.gradients(grad,))\n",
    "    \n",
    "    return LL\n",
    "#     return LL,LLgrad\n",
    "#     return LL,LLgrad, LLhessian, length(params) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### =============== testing 1 ================= ####\n",
    "\n",
    "# Global variables \n",
    "epsilon = 10.0**(-10) \n",
    "dx = 0.125 \n",
    "dt = 0.02\n",
    "Nsteps = int(np.ceil(1.0/dt))\n",
    "\n",
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]   \n",
    "\n",
    "# trial index starts from 0 \n",
    "RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata, 0) \n",
    "\n",
    "logLike(params)\n",
    "\n",
    "### =========================================== ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### =============== testing 2 ================= ####\n",
    "\n",
    "# Global variables \n",
    "epsilon = 10.0**(-10) \n",
    "dx = 0.125 \n",
    "dt = 0.02\n",
    "Nsteps = int(np.ceil(1.0/dt))\n",
    "\n",
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]   \n",
    "\n",
    "LL = llikey(params, \"R\", RightPulseTimes=np.array([0.2, 0.4]))\n",
    "LL\n",
    "### =========================================== ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "RightClickTimes, LeftClickTimes, maxT, rat_choice = trialdata(ratdata, 9) \n",
    "\n",
    "LL = logProbRight(params)\n",
    "\n",
    "plt.imshow(a_trace)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "np.shape(bin_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiLL(ratdata, params, ntrials):\n",
    "    LL = 0\n",
    "    LLgrad = np.zeros((np.shape(params)[0]))\n",
    "    LLhessian = np.zeros((np.shape(params)[0],np.shape(params)[0]))\n",
    "    \n",
    "    for i in range(ntrials):\n",
    "        RClickTimes, LClickTimes, maxT, rat_choice = trialdata(ratdata, i)\n",
    "#         LLi, LLgradi, LLhessiani = llikey(params, rat_choice, maxT=maxT, RightPulseTimes=RClickTimes,\n",
    "        LLi = llikey(params, rat_choice, maxT=maxT, RightPulseTimes=RClickTimes, LeftPulseTimes = LClickTimes, dx=0.25, dt = 0.02)\n",
    "\n",
    "        LL        = LL + LLi;\n",
    "#         LLgrad    = LLgrad + LLgradi;\n",
    "#         LLhessian = LLhessian + LLhessiani;\n",
    "\n",
    "        print(str(i+1)+ \" - LL : \" + str(LL))\n",
    "        \n",
    "    return LL, LLgrad, LLhessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilon = 10.0**(-10); dx = 0.125; dt = 0.02; Nsteps = int(np.ceil(1.0/dt))\n",
    "\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]   \n",
    "\n",
    "multiLL(ratdata, params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_params = tf.Variable(params, name = \"params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "sigma_a = 1; sigma_s = 0.1; sigma_i = 0.2; \n",
    "sigma_a_sbin = sigma_a  # remember we need this copy for Fmatrix\n",
    "lam = -0.0005; B = 4.1; bias = 0.1; \n",
    "phi = 0.3; tau_phi = 0.1; lapse = 0.05;\n",
    "params = [sigma_a, sigma_s, sigma_i, lam, B, bias, phi, tau_phi, lapse]   \n",
    "\n",
    "# tf_params = tf.Variable(params, name = \"params\")\n",
    "tf_params = {\n",
    "    'sigma_a' : tf.Variable(sigma_a, name=\"sigma_a\"),\n",
    "    'sigma_s' : tf.Variable(sigma_s, name=\"sigma_s\"),\n",
    "    'sigma_i' : tf.Variable(sigma_i, name=\"sigma_i\"),\n",
    "    'lambda' : tf.Variable(lam, name=\"lambda\"),\n",
    "    'B' : tf.Variable(B, name=\"B\"),\n",
    "    'bias' : tf.Variable(bias, name=\"bias\"),\n",
    "    'phi' : tf.Variable(phi, name=\"phi\"),\n",
    "    'tau_phi' : tf.Variable(tau_phi, name=\"tau_phi\"),\n",
    "    'lapse' : tf.Variable(lapse, name=\"lapse\")\n",
    "}\n",
    "\n",
    "loss = logLike(tf_params)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(0.1)\n",
    "grads = opt.compute_gradients(loss)\n",
    "\n",
    "grad_placeholder = [tf.float32]\n",
    "apply_placeholder_op = opt.apply_gradients(grad_placeholder)\n",
    "transform_grads = [(function1(grad[0]), grad[1]) for grad in grads]\n",
    "apply_transform_op = opt.apply_gradients(transform_grads)\n",
    "\n",
    "# Initialize\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "grad_vals = sess.run(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat1 = tf.constant([[3., 3.]])\n",
    "mat2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "product = tf.matmul(mat1,mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "print result\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run([product])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.Variable([1.0, 2.0])\n",
    "a = tf.constant([3.0, 3.0])\n",
    "\n",
    "x.initializer.run()\n",
    "\n",
    "sub = tf.sub(x, a)\n",
    "print(sub.eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "#     print(sess.run(state))\n",
    "    \n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.mul(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([mul, intermed])\n",
    "    print(result)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.mul(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "shape = (50, 50)\n",
    "initial_board = tf.random_uniform(shape, minval=0, maxval=2, dtype=tf.int32)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    X = session.run(initial_board)\n",
    "\n",
    "fig = plt.figure()\n",
    "plot = plt.imshow(X, cmap='Greys',  interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "def update_board(X):\n",
    "    # Check out the details at: https://jakevdp.github.io/blog/2013/08/07/conways-game-of-life/\n",
    "    # Compute number of neighbours,\n",
    "    N = convolve2d(X, np.ones((3, 3)), mode='same', boundary='wrap') - X\n",
    "    # Apply rules of the game\n",
    "    X = (N == 3) | (X & (N == 2))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "board = tf.placeholder(tf.int32, shape=shape, name='board')\n",
    "board_update = tf.py_func(update_board, [board], [tf.int32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    initial_board_values = session.run(initial_board)\n",
    "    X = session.run(board_update, feed_dict={board: initial_board_values})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "def game_of_life(*args):\n",
    "    X = session.run(board_update, feed_dict={board: X})[0]\n",
    "    plot.set_array(X)\n",
    "    return plot,\n",
    "\n",
    "fig = plt.figure()\n",
    "ani = animation.FuncAnimation(fig, game_of_life, interval=200, blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# Try to find values for W and b that compute y_data = W * x_data + b\n",
    "# (We know that W should be 0.1 and b 0.3, but Tensorflow will\n",
    "# figure that out for us.)\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W * x_data + b\n",
    "\n",
    "# Minimize the mean squared errors.\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "\n",
    "grads_and_vars = optimizer.compute_gradients(loss,[W, b])\n",
    "grads2 = [g for g, _ in grads_and_vars]\n",
    "vars2 = [v for _, v in grads_and_vars]\n",
    "\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# Before starting, initialize the variables.  We will 'run' this first.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph.\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Fit the line.\n",
    "for step in xrange(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(W), sess.run(b))\n",
    "        print sess.run(grads2)\n",
    "\n",
    "# Learns best fit is W: [0.1], b: [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grads2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vars2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
